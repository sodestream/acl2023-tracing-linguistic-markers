{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import tldextract\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import email.header\n",
    "import email.utils\n",
    "import string\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from ietfdata.datatracker import *\n",
    "from ietfdata.mailarchive import *\n",
    "import ietfdata.mailarchive as ma\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import json\n",
    "import tldextract\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statistical-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "square-bolivia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.4 (default, Apr  9 2021, 09:32:38) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-investigator",
   "metadata": {},
   "source": [
    "To generate the data structures used in this work: emailID_pid_dict.json, pid_emailID_dict.json, name_pid_dict.json, role_based_emailIDs_newData.txt , automated_email_IDs_newData.txt please refer to https://github.com/sodestream/imc2021-submission/blob/main/scripts/emails/email-messages-year.py and https://github.com/sodestream/imc2021-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuffed-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "ren = r'(?:\\.?)([\\w\\-_+#~!$&\\'\\.]+(?<!\\.)(@|[ ]?\\(?[ ]?(at|AT)[ ]?\\)?[ ]?)(?<!\\.)[\\w]+[\\w\\-\\.]*\\.[a-zA-Z-]{2,3})(?:[^\\w])'\n",
    "ren2 = r'([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "essential-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "emailID_pid_dict = json.load(open('../analysis_revision3/emailID_pid_dict.json'))\n",
    "pid_emailID_dict = json.load(open('../analysis_revision3/pid_emailID_dict.json'))\n",
    "name_pid_dict = json.load(open('../analysis_revision3/name_pid_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "square-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n"
     ]
    }
   ],
   "source": [
    "role_based_emailIDs = set()\n",
    "with open('../analysis_revision3/role_based_emailIDs_newData.txt') as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines:\n",
    "        line = line.strip()\n",
    "        role_based_emailIDs.add(line)\n",
    "        #print(line)\n",
    "print(len(role_based_emailIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "black-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "#role_based_emailIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685\n"
     ]
    }
   ],
   "source": [
    "automated_list = set()\n",
    "with open('../analysis_revision3/automated_email_IDs_newData.txt') as f2:\n",
    "    Lines2 = f2.readlines()\n",
    "    for line in Lines2:\n",
    "        line = line.strip()\n",
    "        automated_list.add(line)\n",
    "        #print(line)\n",
    "print(len(automated_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-differential",
   "metadata": {},
   "source": [
    "To generate interaction mappings please refer to https://github.com/sodestream/icwsm22/blob/master/V2-generate_personID_personID_mappings.py and https://github.com/sodestream/icwsm22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "successful-moderator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_PersonID_From</th>\n",
       "      <th>B_PersonID_To</th>\n",
       "      <th>Type</th>\n",
       "      <th>Time_since_1st_mail_A</th>\n",
       "      <th>Time_since_1st_mail_B</th>\n",
       "      <th>Max_Time_A</th>\n",
       "      <th>Max_Time_B</th>\n",
       "      <th>Interaction_timestamp</th>\n",
       "      <th>MessageID_A</th>\n",
       "      <th>MessageID_B</th>\n",
       "      <th>Mailing_list</th>\n",
       "      <th>Mailinglist_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100005</td>\n",
       "      <td>100001</td>\n",
       "      <td>reply_to</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>&lt;CAKFu26gHc2mutnyNhRMz9YekRb60angmBiWgz5Z6sUDC...</td>\n",
       "      <td>&lt;1262915113.716847.1510540285719@mail.yahoo.com&gt;</td>\n",
       "      <td>100-newcomers</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>100001</td>\n",
       "      <td>reply_self</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>&lt;277920060.1462457.1510625963022@mail.yahoo.com&gt;</td>\n",
       "      <td>&lt;1262915113.716847.1510540285719@mail.yahoo.com&gt;</td>\n",
       "      <td>100-newcomers</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100006</td>\n",
       "      <td>100002</td>\n",
       "      <td>reply_to</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>&lt;CADVGGb9CHep2dQY9P+E7ODaOEkhm7bTjk7OWKDQz0VWK...</td>\n",
       "      <td>&lt;5FE99815-6CC8-4FF2-B7FB-709D0BEEEF5E@amsl.com&gt;</td>\n",
       "      <td>100-newcomers</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_PersonID_From  B_PersonID_To        Type  Time_since_1st_mail_A  \\\n",
       "0           100005         100001    reply_to                    0.0   \n",
       "1           100001         100001  reply_self                    6.5   \n",
       "2           100006         100002    reply_to                    0.0   \n",
       "\n",
       "   Time_since_1st_mail_B  Max_Time_A  Max_Time_B Interaction_timestamp  \\\n",
       "0                    6.5         0.0         9.5            2017-11-13   \n",
       "1                    6.5         9.5         9.5            2017-11-14   \n",
       "2                   15.0         1.5        18.5            2017-11-16   \n",
       "\n",
       "                                         MessageID_A  \\\n",
       "0  <CAKFu26gHc2mutnyNhRMz9YekRb60angmBiWgz5Z6sUDC...   \n",
       "1   <277920060.1462457.1510625963022@mail.yahoo.com>   \n",
       "2  <CADVGGb9CHep2dQY9P+E7ODaOEkhm7bTjk7OWKDQz0VWK...   \n",
       "\n",
       "                                        MessageID_B   Mailing_list  \\\n",
       "0  <1262915113.716847.1510540285719@mail.yahoo.com>  100-newcomers   \n",
       "1  <1262915113.716847.1510540285719@mail.yahoo.com>  100-newcomers   \n",
       "2   <5FE99815-6CC8-4FF2-B7FB-709D0BEEEF5E@amsl.com>  100-newcomers   \n",
       "\n",
       "  Mailinglist_type  \n",
       "0            other  \n",
       "1            other  \n",
       "2            other  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if the file is compressed and zipped, please unzip\n",
    "df_mappings = pd.read_csv('../analysis_revision3/personID_to_personID_graph_new_with_mlisttype.csv',delimiter='\\t',header=0)\n",
    "\n",
    "df_mappings['Interaction_timestamp'] = pd.to_datetime(df_mappings['Interaction_timestamp'], format='%Y-%m-%d').dt.date\n",
    "df_mappings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-spectacular",
   "metadata": {},
   "source": [
    "For a reference to spam messages scoring please contact Mladen Karan: m.karan at qmul (dot) ac (dot) uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slim.csv 3\n",
      "rohc.csv 8\n",
      "datatracker-rqmts.csv 8\n",
      "it-test.csv 8\n",
      "lemonade.csv 13\n",
      "tsv-area.csv 14\n",
      "rescap.csv 24\n",
      "ieprep.csv 27\n",
      "websec.csv 35\n",
      "108all.csv 35\n",
      "perc.csv 35\n",
      "sshmgmt.csv 35\n",
      "mobopts.csv 35\n",
      "ospf-wireless-design.csv 35\n",
      "ccamp.csv 907\n",
      "nsis.csv 946\n",
      "hybi.csv 952\n",
      "svt.csv 952\n",
      "secretariat-2012.csv 952\n",
      "tzdist.csv 952\n",
      "ipdvb.csv 961\n",
      "69attendees.csv 964\n",
      "96attendees.csv 964\n",
      "100-newcomers.csv 964\n",
      "tip.csv 967\n",
      "llc-consultation.csv 967\n",
      "opsec.csv 973\n",
      "104all.csv 973\n",
      "stox.csv 973\n",
      "91attendees.csv 974\n",
      "dcrouting.csv 974\n",
      "certid.csv 974\n",
      "new-wg-docs.csv 974\n",
      "mib-doctors.csv 974\n",
      "channel-binding.csv 974\n",
      "bmwg.csv 1021\n",
      "art.csv 1022\n",
      "v3.csv 1022\n",
      "ipae.csv 1022\n",
      "sami.csv 1025\n",
      "ietf-meetings.csv 1025\n",
      "nasreq.csv 1031\n",
      "nmlrg.csv 1031\n",
      "endymail.csv 1032\n",
      "oda.csv 1032\n",
      "geojson.csv 1032\n",
      "84attendees.csv 1034\n",
      "l2cp.csv 1034\n",
      "collation.csv 1034\n",
      "dhcp.csv 1034\n",
      "hostmib.csv 1034\n",
      "multipathtcp.csv 1038\n",
      "rsn.csv 1038\n",
      "104-newcomers.csv 1038\n",
      "isn.csv 1041\n",
      "mcic.csv 1041\n",
      "rfcplusplus.csv 1041\n",
      "spud.csv 1041\n",
      "laminar.csv 1041\n",
      "regext.csv 1060\n",
      "cose.csv 1066\n",
      "last-call.csv 1069\n",
      "iccrg.csv 1069\n",
      "mtgvenue.csv 1074\n",
      "rtg-open-source.csv 1074\n",
      "pwot.csv 1074\n",
      "ucp.csv 1074\n",
      "csky-idsubmit.csv 1074\n",
      "banana.csv 1075\n",
      "mtudisc.csv 1075\n",
      "sandbox-mailoutput.csv 1077\n",
      "ietf-62.csv 1077\n",
      "webfinger.csv 1078\n",
      "mipshop.csv 1095\n",
      "http-state.csv 1098\n",
      "patient.csv 1098\n",
      "idr.csv 1283\n",
      "sip-ops.csv 1283\n",
      "clue.csv 1292\n",
      "msgway.csv 1292\n",
      "109attendees.csv 1293\n",
      "tofoo.csv 1299\n",
      "problem.csv 1307\n",
      "aqm.csv 1307\n",
      "ldapext.csv 1317\n",
      "lucid.csv 1317\n",
      "ans-research.csv 1322\n",
      "iotops.csv 1322\n",
      "radir.csv 1322\n",
      "mif.csv 1323\n",
      "smime.csv 1667\n",
      "dcpel.csv 1667\n",
      "tsvwg.csv 1707\n",
      "internetgovtech.csv 1721\n",
      "96companions.csv 1721\n",
      "frame.csv 1721\n",
      "userglos.csv 1721\n",
      "httpbisa.csv 1897\n",
      "92all.csv 1898\n",
      "cbor.csv 1899\n",
      "discuss.csv 1905\n",
      "disi.csv 1905\n",
      "btns.csv 1911\n",
      "hostreq.csv 1912\n",
      "smartobjectdir.csv 1912\n",
      "tzdist-bis.csv 1914\n",
      "80all.csv 1914\n",
      "92companions.csv 1914\n",
      "anima.csv 1934\n",
      "ietf-ack.csv 1934\n",
      "ids.csv 1934\n",
      "netmod-ver-dt.csv 1935\n",
      "uri-review.csv 1939\n",
      "speermint.csv 1940\n",
      "pppext.csv 1940\n",
      "babel.csv 1941\n",
      "mimemhs.csv 1941\n",
      "mpls-review.csv 1944\n",
      "pier.csv 1944\n",
      "tm-rid.csv 1944\n",
      "lwip.csv 1946\n",
      "roll-bier-dt.csv 1946\n",
      "morg.csv 1947\n",
      "teas.csv 2002\n",
      "l1vpn.csv 2002\n",
      "rip.csv 2002\n",
      "tram.csv 2002\n",
      "secdispatch.csv 2002\n",
      "ietf-dkim.csv 2148\n",
      "irtf-mobility-charter.csv 2148\n",
      "casm.csv 2148\n",
      "edm.csv 2148\n",
      "rtg-dir.csv 2269\n",
      "lurk.csv 2269\n",
      "poised95.csv 2269\n",
      "http-issues.csv 2269\n",
      "avtext.csv 2269\n",
      "dtn-interest.csv 2271\n",
      "ethermib.csv 2271\n",
      "trigtran.csv 2275\n",
      "95companions.csv 2275\n",
      "ledger.csv 2275\n",
      "edu-discuss.csv 2275\n",
      "tls-implementers.csv 2275\n",
      "82attendees.csv 2276\n",
      "rpsec.csv 2280\n",
      "storm.csv 2281\n",
      "l3sm.csv 2306\n",
      "nat66.csv 2354\n",
      "sop.csv 2357\n",
      "6lo-fragmentation-dt.csv 2357\n",
      "85attendees.csv 2357\n",
      "ops-area.csv 2359\n",
      "sam.csv 2359\n",
      "yaco-nomcom-tool.csv 2359\n",
      "coman.csv 2359\n",
      "tsig.csv 2359\n",
      "httpapi.csv 2359\n",
      "therightkey.csv 2360\n",
      "driu.csv 2360\n",
      "l3vpn.csv 2368\n",
      "maprg.csv 2368\n",
      "irtf-discuss.csv 2368\n",
      "abnf-discuss.csv 2368\n",
      "82all.csv 2368\n",
      "appleip.csv 2368\n",
      "obscurity-interest.csv 2368\n",
      "secsh.csv 2377\n",
      "detnet-dp-dt.csv 2377\n",
      "ianaplan.csv 2394\n",
      "manet-dt.csv 2395\n",
      "90attendees.csv 2396\n",
      "rps.csv 2413\n",
      "videomgmt.csv 2413\n",
      "http-well-known.csv 2413\n",
      "ips.csv 2649\n",
      "idpr.csv 2649\n",
      "97attendees.csv 2649\n",
      "68attendees.csv 2649\n",
      "90all.csv 2649\n",
      "megaco.csv 2697\n",
      "payload.csv 2698\n",
      "kink.csv 2736\n",
      "capwap.csv 2785\n",
      "91companions.csv 2797\n",
      "snmpv2.csv 2802\n",
      "noop.csv 2802\n",
      "trade.csv 2818\n",
      "bimi.csv 2818\n",
      "recipe.csv 2818\n",
      "core.csv 2829\n",
      "dart.csv 2829\n",
      "xcon.csv 2833\n",
      "106all.csv 2833\n",
      "nvo3.csv 2834\n",
      "routing-discussion.csv 2837\n",
      "dtn-users.csv 2864\n",
      "e2md.csv 2864\n",
      "imap.csv 2883\n",
      "eppext.csv 2884\n",
      "pop3.csv 2884\n",
      "accord.csv 2885\n",
      "mipshop-mih-dt.csv 2885\n",
      "rt-media-ng.csv 2885\n",
      "re-ecn.csv 2885\n",
      "trunkmib.csv 2885\n",
      "103-newcomers.csv 2885\n",
      "hops.csv 2885\n",
      "asap.csv 2885\n",
      "xrblock.csv 2885\n",
      "kaml.csv 2885\n",
      "nfvcon.csv 2885\n",
      "cmp-id.csv 2885\n",
      "iptel.csv 2931\n",
      "lager.csv 2931\n",
      "cdi.csv 2932\n",
      "tsv-art.csv 2939\n",
      "upsmib.csv 2943\n",
      "vgmib.csv 2943\n",
      "doh.csv 2943\n",
      "cin.csv 2943\n",
      "apn.csv 2945\n",
      "siprec.csv 2945\n",
      "iotsi.csv 2947\n",
      "fud.csv 2947\n",
      "aft.csv 2947\n",
      "tcppep.csv 2947\n",
      "tig-diagnostics.csv 2947\n",
      "zeroconf.csv 3685\n",
      "rreq.csv 3685\n",
      "lime-oam-model.csv 3685\n",
      "dns-dir.csv 3685\n",
      "posh.csv 3685\n",
      "dbound.csv 3689\n",
      "ietf-mentoring-discuss.csv 3689\n",
      "hrpc.csv 3695\n",
      "i2nsf.csv 3719\n",
      "pip.csv 3719\n",
      "coin.csv 3719\n",
      "110-newcomers.csv 3719\n",
      "tools-arch.csv 3719\n",
      "v4v6interim.csv 3719\n",
      "nbs.csv 3721\n",
      "rsvp.csv 4023\n",
      "send.csv 4195\n",
      "network-tokens.csv 4195\n",
      "netlmm.csv 4199\n",
      "companions.csv 4199\n",
      "ipp.csv 5148\n",
      "bgmp.csv 5148\n",
      "108attendees.csv 5148\n",
      "drinks.csv 5148\n",
      "hr-rt.csv 5148\n",
      "bliss.csv 5149\n",
      "snmpv3.csv 5156\n",
      "proto-team.csv 5156\n",
      "100companions.csv 5156\n",
      "orad.csv 5156\n",
      "imss.csv 5156\n",
      "ietf-sow.csv 5156\n",
      "pint.csv 5156\n",
      "rai.csv 5157\n",
      "wnils.csv 5157\n",
      "bess.csv 5171\n",
      "coma.csv 5171\n",
      "urn.csv 5179\n",
      "rgchairs.csv 5186\n",
      "ngo.csv 5188\n",
      "status.csv 5188\n",
      "chassis.csv 5188\n",
      "id-event.csv 5190\n",
      "softwires.csv 5204\n",
      "solace.csv 5204\n",
      "tools-implementation.csv 5204\n",
      "94all.csv 5204\n",
      "smartobject-interest.csv 5204\n",
      "aaa-doctors.csv 5206\n",
      "102attendees.csv 5206\n",
      "mdnsext.csv 5206\n",
      "98all.csv 5206\n",
      "vpn-dir.csv 5206\n",
      "mpls.csv 5261\n",
      "marnew-pc.csv 5261\n",
      "widex.csv 5261\n",
      "revampers.csv 5261\n",
      "monami6.csv 5261\n",
      "dix.csv 5261\n",
      "105attendees.csv 5261\n",
      "fddi.csv 5261\n",
      "netconf.csv 5483\n",
      "rserpool.csv 5511\n",
      "ietf-hub-boston.csv 5511\n",
      "86all.csv 5511\n",
      "sasl.csv 5522\n",
      "ggie.csv 5522\n",
      "wgguide.csv 5522\n",
      "pmtud.csv 5526\n",
      "stevetest.csv 5526\n",
      "shutup.csv 5526\n",
      "yang.csv 5530\n",
      "gendispatch.csv 5530\n",
      "cat.csv 5533\n",
      "vipr.csv 5533\n",
      "ftpext.csv 5558\n",
      "homesec-dt.csv 5558\n",
      "din.csv 5558\n",
      "acct.csv 5558\n",
      "dc.csv 5558\n",
      "atompub.csv 5589\n",
      "raven.csv 5589\n",
      "scsn.csv 5589\n",
      "iprp.csv 5589\n",
      "cicm.csv 5589\n",
      "6lo.csv 5592\n",
      "aaa.csv 5644\n",
      "tls-reg-review.csv 5644\n",
      "smartpowerdir.csv 5644\n",
      "crisp.csv 5644\n",
      "multimobsec-api.csv 5644\n",
      "plasma.csv 5644\n",
      "media-feature-tags-archive.csv 5644\n",
      "ssm.csv 5645\n",
      "nir.csv 5645\n",
      "netext.csv 5704\n",
      "swmp.csv 5704\n",
      "masque.csv 5704\n",
      "ietf-nomcom.csv 5704\n",
      "evolving-documents.csv 5704\n",
      "110attendees.csv 5704\n",
      "opstat.csv 5704\n",
      "rum.csv 5704\n",
      "ntdp.csv 5704\n",
      "sip-clf.csv 5704\n",
      "ncrg.csv 5704\n",
      "ntpwg.csv 5704\n",
      "vcarddav.csv 5712\n",
      "npp.csv 5712\n",
      "109-newcomers.csv 5712\n",
      "bier.csv 5719\n",
      "ecm.csv 5738\n",
      "simple.csv 5746\n",
      "bundled-domain-names.csv 5746\n",
      "chirp.csv 5746\n",
      "mmox.csv 5794\n",
      "pwg.csv 5794\n",
      "ietfmibs.csv 5795\n",
      "teas-3272bis-design-team.csv 5795\n",
      "seamoby.csv 5963\n",
      "nethistory.csv 5963\n",
      "75all.csv 5963\n",
      "dmarc-report.csv 5963\n",
      "madinas.csv 5963\n",
      "i18ndir.csv 5963\n",
      "tuba.csv 5963\n",
      "eap.csv 5963\n",
      "salud.csv 5963\n",
      "ietf-message-headers.csv 5963\n",
      "dcon.csv 5963\n",
      "ietf-types.csv 5989\n",
      "gaia.csv 6008\n",
      "snmp.csv 6008\n",
      "hiccup.csv 6008\n",
      "nscp.csv 6008\n",
      "peppermint.csv 6008\n",
      "yang-doctors.csv 6021\n",
      "apps-discuss.csv 6094\n",
      "find.csv 6094\n",
      "i18n-discuss.csv 6094\n",
      "httpstreaming.csv 6095\n",
      "domainrep.csv 6095\n",
      "disman.csv 6100\n",
      "mpowr.csv 6100\n",
      "25years.csv 6100\n",
      "txauth.csv 6100\n",
      "yc-announce.csv 6100\n",
      "shara.csv 6100\n",
      "reap.csv 6100\n",
      "irtf-announce.csv 6101\n",
      "i18nrp.csv 6102\n",
      "issll.csv 6102\n",
      "sieve.csv 6118\n",
      "mile.csv 6120\n",
      "detnet.csv 6123\n",
      "cuss.csv 6123\n",
      "iola-conversion-tool.csv 6123\n",
      "ippm.csv 6154\n",
      "aac.csv 6154\n",
      "lp-wan.csv 6156\n",
      "earlywarning.csv 6156\n",
      "multi6.csv 6156\n",
      "xml2rfc-dev.csv 6156\n",
      "79all.csv 6156\n",
      "ipr-wg.csv 6163\n",
      "ospf-manet.csv 6163\n",
      "imapext.csv 6184\n",
      "fecframe-proto.csv 6184\n",
      "97-mentors.csv 6184\n",
      "middisc.csv 6184\n",
      "6lowapp.csv 6211\n",
      "ietf-community-india.csv 6211\n",
      "110all.csv 6211\n",
      "qirg.csv 6211\n",
      "lln-futures.csv 6211\n",
      "mtg-guests.csv 6211\n",
      "mixer.csv 6211\n",
      "mcast-wifi.csv 6211\n",
      "nfsv4.csv 6226\n",
      "jose-reg-review.csv 6226\n",
      "oam.csv 6226\n",
      "calsch.csv 6318\n",
      "rwhois.csv 6318\n",
      "privacydir.csv 6318\n",
      "decade.csv 6318\n",
      "dyncast.csv 6318\n",
      "isms.csv 6324\n",
      "102all.csv 6324\n",
      "70attendees.csv 6324\n",
      "gen-art.csv 6345\n",
      "fddimib.csv 6345\n",
      "spfbis.csv 6345\n",
      "run.csv 6345\n",
      "xmpp.csv 6345\n",
      "calsify.csv 6362\n",
      "98-newcomers.csv 6362\n",
      "dclc.csv 6365\n",
      "77attendees.csv 6365\n",
      "storagesync.csv 6376\n",
      "88attendees.csv 6376\n",
      "idwg.csv 6388\n",
      "eme.csv 6389\n",
      "meta-model.csv 6389\n",
      "qosr.csv 6389\n",
      "dnsop.csv 6435\n",
      "edu-team.csv 6439\n",
      "unbearable.csv 6441\n",
      "armd.csv 6441\n",
      "yaco-liaison-tool.csv 6441\n",
      "model-t.csv 6441\n",
      "irs-discuss.csv 6441\n",
      "bridge-mib.csv 6444\n",
      "nea.csv 6448\n",
      "pkng.csv 6450\n",
      "pce.csv 6457\n",
      "ops-nm.csv 6457\n",
      "opsarea-chairs.csv 6457\n",
      "panrg.csv 6457\n",
      "tcpinc.csv 6461\n",
      "blockchain-interop.csv 6461\n",
      "ipoverib.csv 6479\n",
      "httpmail.csv 6479\n",
      "smartpower-interest.csv 6479\n",
      "modern.csv 6481\n",
      "svrloc.csv 6482\n",
      "77all.csv 6482\n",
      "netmod.csv 6533\n",
      "lake.csv 6534\n",
      "98companions.csv 6534\n",
      "pals.csv 6544\n",
      "3gpp-ietf-coord.csv 6544\n",
      "irnss.csv 6544\n",
      "quic-issues.csv 6544\n",
      "altoext.csv 6544\n",
      "malloc.csv 6545\n",
      "radext.csv 6643\n",
      "mathmesh.csv 6644\n",
      "100all.csv 6644\n",
      "emserv-discuss.csv 6644\n",
      "fecframe.csv 6645\n",
      "tcpm.csv 6654\n",
      "nvo3-dt-encap.csv 6654\n",
      "ipv6-dir.csv 6655\n",
      "asrg.csv 6721\n",
      "justfont.csv 6721\n",
      "ssw-agenda-tool.csv 6721\n",
      "pm-dir.csv 6722\n",
      "atlas.csv 6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opsawg.csv 6759\n",
      "ml_testlist.csv 6759\n",
      "video-codec.csv 6759\n",
      "web.csv 6761\n",
      "uri.csv 6763\n",
      "104attendees.csv 6763\n",
      "eat.csv 6763\n",
      "cidrd.csv 6764\n",
      "remoteui.csv 6764\n",
      "perpass.csv 6765\n",
      "imrg.csv 6766\n",
      "103attendees.csv 6766\n",
      "l2sm.csv 6766\n",
      "pwe3.csv 6769\n",
      "mhtml.csv 6769\n",
      "conneg.csv 6774\n",
      "emu.csv 6779\n",
      "rai-discuss.csv 6779\n",
      "ietf108planning.csv 6779\n",
      "84all.csv 6779\n",
      "entmib.csv 6784\n",
      "mavs.csv 6784\n",
      "ieee-ietf-coord.csv 6784\n",
      "bgp.csv 6784\n",
      "arcing.csv 6786\n",
      "mpvdapi.csv 6790\n",
      "precis.csv 6790\n",
      "testlist.csv 6791\n",
      "siesta.csv 6791\n",
      "vpn4dc.csv 6791\n",
      "marnew.csv 6791\n",
      "njm.csv 6791\n",
      "rats.csv 6793\n",
      "big-internet.csv 6793\n",
      "ident.csv 6793\n",
      "ipsra.csv 6959\n",
      "iesg-agenda-dist.csv 6959\n",
      "vot.csv 6959\n",
      "hip.csv 6959\n",
      "ipsp.csv 7351\n",
      "96all.csv 7351\n",
      "ibnemo.csv 7352\n",
      "actn.csv 7355\n",
      "3gv6.csv 7364\n",
      "89attendees.csv 7370\n",
      "resolverless-dns.csv 7370\n",
      "76attendees.csv 7370\n",
      "diffserv.csv 7380\n",
      "sip.csv 7469\n",
      "sipping-emergency.csv 7469\n",
      "stackevo-discuss.csv 7469\n",
      "yaco-wgchair-tracker.csv 7469\n",
      "822ext.csv 7469\n",
      "jwt-reg-review.csv 7469\n",
      "lsvr.csv 7469\n",
      "wgchairs.csv 7509\n",
      "71attendees.csv 7509\n",
      "88all.csv 7509\n",
      "dnsoverhttp.csv 7509\n",
      "dfs.csv 7509\n",
      "syslog.csv 7517\n",
      "idna-update.csv 7527\n",
      "forces.csv 7637\n",
      "dcrup.csv 7637\n",
      "i2rs.csv 7645\n",
      "notifications.csv 7645\n",
      "cnrp.csv 7645\n",
      "acvp.csv 7645\n",
      "mmusic.csv 7814\n",
      "iot-directorate.csv 7814\n",
      "ipvbi.csv 7815\n",
      "t2trg.csv 7816\n",
      "admin-discuss.csv 7816\n",
      "iot-onboarding.csv 7816\n",
      "mif-arch-dt.csv 7817\n",
      "ssh.csv 7817\n",
      "gsmp.csv 7818\n",
      "pcp.csv 7822\n",
      "midcom.csv 7853\n",
      "6tisch-security.csv 7855\n",
      "humanresolvers.csv 7855\n",
      "thinosi.csv 7855\n",
      "ice.csv 7855\n",
      "http-auth.csv 7857\n",
      "agentx.csv 7875\n",
      "igmp-mld-bis.csv 7875\n",
      "ram.csv 7877\n",
      "mhsds.csv 7877\n",
      "cosmogol.csv 7877\n",
      "webdav.csv 8113\n",
      "trans.csv 8129\n",
      "ietf-and-github.csv 8131\n",
      "roll.csv 8176\n",
      "iafa.csv 8176\n",
      "rmt.csv 8189\n",
      "teas-ns-dt.csv 8190\n",
      "aeon.csv 8190\n",
      "raw.csv 8192\n",
      "dhcpv6bis.csv 8192\n",
      "etosat.csv 8192\n",
      "keyprov.csv 8192\n",
      "rfid.csv 8192\n",
      "weirds.csv 8192\n",
      "bec.csv 8192\n",
      "extra.csv 8192\n",
      "dir-coord.csv 8192\n",
      "spb-isis.csv 8192\n",
      "93-1st-timers.csv 8192\n",
      "86-1st-timers.csv 8192\n",
      "proxies.csv 8192\n",
      "93all.csv 8193\n",
      "i2rs-proto-dt.csv 8193\n",
      "sip-overload.csv 8193\n",
      "safe.csv 8193\n",
      "yaco-idsubmit-tool.csv 8193\n",
      "vpim.csv 8193\n",
      "jcardcal.csv 8193\n",
      "fdt.csv 8193\n",
      "osigen.csv 8193\n",
      "hipsec.csv 8203\n",
      "idnet.csv 8203\n",
      "iplpdn.csv 8203\n",
      "secdir.csv 8211\n",
      "ietf109-team.csv 8211\n",
      "nwcrg.csv 8211\n",
      "81all.csv 8211\n",
      "stir.csv 8218\n",
      "mpsnmp.csv 8218\n",
      "tap.csv 8218\n",
      "101attendees.csv 8218\n",
      "95-mentees.csv 8218\n",
      "omcast.csv 8218\n",
      "urlreg.csv 8218\n",
      "99companions.csv 8218\n",
      "panic.csv 8218\n",
      "pso-discuss.csv 8218\n",
      "ietf-surveys.csv 8218\n",
      "flexip.csv 8218\n",
      "p2prg.csv 8268\n",
      "106attendees.csv 8269\n",
      "dtn-security.csv 8269\n",
      "efficientnd-dt.csv 8269\n",
      "ripv2.csv 8269\n",
      "ranger.csv 8269\n",
      "explicit-meas.csv 8269\n",
      "2000.csv 8269\n",
      "ippcp.csv 8271\n",
      "i-d-announce.csv 8271\n",
      "sidr.csv 8283\n",
      "mobileip.csv 8293\n",
      "autoconf.csv 8293\n",
      "tcmtf.csv 8293\n",
      "rmon.csv 8293\n",
      "nntpext.csv 8388\n",
      "harts.csv 8388\n",
      "arcmedia.csv 8388\n",
      "core-parameters.csv 8388\n",
      "p2psip.csv 8766\n",
      "x400ops.csv 8766\n",
      "ssphwg.csv 8766\n",
      "cga-ext.csv 8772\n",
      "hackathon.csv 8783\n",
      "pilc.csv 8785\n",
      "splices.csv 8785\n",
      "newprep.csv 8785\n",
      "teaching.csv 8785\n",
      "6band.csv 8785\n",
      "msec.csv 8789\n",
      "criteria.csv 8789\n",
      "teep.csv 8791\n",
      "clouds.csv 8791\n",
      "off-path-bof.csv 8791\n",
      "73attendees.csv 8791\n",
      "pop3ext.csv 8830\n",
      "81-1st-timers.csv 8830\n",
      "94-1st-timers.csv 8830\n",
      "oauth.csv 8945\n",
      "95-mentors.csv 8946\n",
      "xml-sg-cmt.csv 8946\n",
      "ternli.csv 8946\n",
      "http-srv.csv 8946\n",
      "ietf74-1st-timers.csv 8946\n",
      "ediint.csv 10303\n",
      "74attendees.csv 10303\n",
      "inip-discuss.csv 10307\n",
      "aaa-implementers.csv 10307\n",
      "tmrg.csv 10327\n",
      "radius.csv 10327\n",
      "rtg-ooam-dt.csv 10327\n",
      "cnit.csv 10327\n",
      "bnbsg.csv 10328\n",
      "avt.csv 10405\n",
      "charmib.csv 10405\n",
      "architecture-discuss.csv 10410\n",
      "spasm.csv 10410\n",
      "sunset4.csv 10410\n",
      "tae.csv 10410\n",
      "martini.csv 10410\n",
      "pilots-ag.csv 10410\n",
      "codestand-develop.csv 10411\n",
      "wellknown-uri-review.csv 10411\n",
      "forces-protocol.csv 10413\n",
      "cellar.csv 10417\n",
      "pana.csv 10424\n",
      "jsonpath.csv 10424\n",
      "mib2rdml.csv 10424\n",
      "nfvrg.csv 10428\n",
      "sdn.csv 10437\n",
      "bridge.csv 10438\n",
      "asdf.csv 10438\n",
      "rfc-markdown.csv 10438\n",
      "rrg-reboot.csv 10438\n",
      "icalendar.csv 10438\n",
      "vrrp.csv 10450\n",
      "109all.csv 10450\n",
      "ospf.csv 10511\n",
      "dime.csv 10531\n",
      "99attendees.csv 10531\n",
      "terminology.csv 10531\n",
      "105all.csv 10531\n",
      "behave.csv 10609\n",
      "ietf-822.csv 10652\n",
      "paw.csv 10652\n",
      "ischedule.csv 10652\n",
      "ima.csv 10655\n",
      "icnrg-harmonization.csv 10655\n",
      "enum.csv 10706\n",
      "lisp.csv 10717\n",
      "jmap.csv 10717\n",
      "tcpimpl.csv 10720\n",
      "codematch-develop.csv 10722\n",
      "qos_inband.csv 10722\n",
      "rolc.csv 10722\n",
      "medup.csv 10722\n",
      "spirits.csv 10880\n",
      "provreg.csv 10970\n",
      "receipt.csv 10970\n",
      "rtgwg.csv 10989\n",
      "6tisch.csv 11034\n",
      "sipp.csv 11035\n",
      "96newcomers.csv 11035\n",
      "108-newcomers.csv 11035\n",
      "dsii.csv 11035\n",
      "107attendees.csv 11035\n",
      "tcpcrypt.csv 11035\n",
      "usefor.csv 11036\n",
      "netrqmts.csv 11036\n",
      "sidrops.csv 11046\n",
      "ghost.csv 11046\n",
      "rddp.csv 11046\n",
      "straw.csv 11052\n",
      "100attendees.csv 11052\n",
      "ila.csv 11052\n",
      "tzdist-service.csv 11052\n",
      "pmol.csv 11052\n",
      "wpkops.csv 11052\n",
      "dcrg-interest.csv 11052\n",
      "netdata.csv 11052\n",
      "88-1st-timers.csv 11052\n",
      "karp.csv 11052\n",
      "spring.csv 11058\n",
      "adslmib.csv 11058\n",
      "telnet.csv 11058\n",
      "oud.csv 11058\n",
      "speechsc.csv 11058\n",
      "ham-ag.csv 11058\n",
      "5gangip.csv 11060\n",
      "sipcore.csv 11064\n",
      "ipsec.csv 11279\n",
      "sfc.csv 11292\n",
      "mls.csv 11293\n",
      "diversity.csv 11293\n",
      "16ng.csv 11295\n",
      "carddav.csv 11295\n",
      "multimob.csv 11298\n",
      "ietf75-1st-timers.csv 11298\n",
      "dhcwg.csv 11352\n",
      "l2tpext.csv 11404\n",
      "95-1st-timers.csv 11404\n",
      "tcplw.csv 11408\n",
      "107all.csv 11408\n",
      "caldav.csv 11414\n",
      "http-devops.csv 11414\n",
      "ipfix.csv 11501\n",
      "dane.csv 11509\n",
      "pidloc.csv 11509\n",
      "abfab.csv 11509\n",
      "w3c-policy.csv 11509\n",
      "ietf-runners.csv 11509\n",
      "idmr.csv 11523\n",
      "int-area.csv 11525\n",
      "beep.csv 11525\n",
      "tools-team.csv 11525\n",
      "ietf-privacy.csv 11525\n",
      "rap.csv 11534\n",
      "webauthn-reg-review.csv 11534\n",
      "v6ops.csv 13169\n",
      "dots.csv 13184\n",
      "nmrg.csv 13187\n",
      "rtg-yang-coord.csv 13187\n",
      "covidimpacts-workshop.csv 13187\n",
      "appsdir.csv 13189\n",
      "http-grease.csv 13189\n",
      "67attendees.csv 13189\n",
      "98attendees.csv 13189\n",
      "techspec.csv 13189\n",
      "99-newcomers.csv 13189\n",
      "tools-development.csv 13191\n",
      "namedroppers.csv 13195\n",
      "its.csv 13195\n",
      "mpls-interop.csv 13198\n",
      "anima-signaling.csv 13203\n",
      "rfced-future.csv 13203\n",
      "l2vpn.csv 13205\n",
      "89companions.csv 13205\n",
      "snmpsec.csv 13205\n",
      "ion.csv 13223\n",
      "rtcweb.csv 13228\n",
      "lsd.csv 13228\n",
      "nntp.csv 13228\n",
      "http-use.csv 13228\n",
      "hubmib.csv 13234\n",
      "iucg.csv 13234\n",
      "mud.csv 13234\n",
      "91all.csv 13234\n",
      "sip-security.csv 13234\n",
      "paws.csv 13239\n",
      "netslices.csv 13239\n",
      "cna.csv 13270\n",
      "qlog.csv 13270\n",
      "ietf-sailors.csv 13270\n",
      "newtrk.csv 13420\n",
      "asrg-announce.csv 13420\n",
      "int-dir.csv 13420\n",
      "atm.csv 13424\n",
      "tls.csv 13516\n",
      "acme.csv 13525\n",
      "scim.csv 13528\n",
      "charter-tool.csv 13528\n",
      "ltru.csv 13573\n",
      "taps.csv 13577\n",
      "insipid.csv 13577\n",
      "ippm-ioam-ix-dt.csv 13577\n",
      "smds.csv 13577\n",
      "dns-privacy.csv 13580\n",
      "ccg.csv 13580\n",
      "trill.csv 13653\n",
      "strint-attendees.csv 13653\n",
      "87-1st-timers.csv 13653\n",
      "codesprints.csv 13653\n",
      "92-1st-timers.csv 13653\n",
      "rtg-dt-encap-considerations.csv 13656\n",
      "75attendees.csv 13656\n",
      "itu+ietf.csv 13657\n",
      "webpush.csv 13659\n",
      "ietf72-1st-timers.csv 13659\n",
      "icnrg.csv 13664\n",
      "ace.csv 13669\n",
      "secauth.csv 13669\n",
      "ideas.csv 13669\n",
      "hiprg.csv 13694\n",
      "92hackathon.csv 13695\n",
      "mext.csv 13713\n",
      "72attendees.csv 13714\n",
      "snanau.csv 13714\n",
      "magma.csv 13716\n",
      "nsaas.csv 13717\n",
      "manet.csv 13795\n",
      "pcn.csv 13812\n",
      "iasa20.csv 13812\n",
      "vmeet.csv 13812\n",
      "ilc.csv 13812\n",
      "spkm.csv 13812\n",
      "lsr.csv 13842\n",
      "sdwan-sec.csv 13842\n",
      "smart.csv 13842\n",
      "hiaps.csv 13842\n",
      "ietf-languages.csv 13901\n",
      "homenet-babel-sec.csv 13901\n",
      "pearg.csv 13904\n",
      "cfrg.csv 13929\n",
      "mediactrl.csv 13929\n",
      "modemmgt.csv 13929\n",
      "call-home.csv 13929\n",
      "trust-router.csv 13929\n",
      "link-relations.csv 13929\n",
      "mops.csv 13929\n",
      "87attendees.csv 13929\n",
      "78attendees.csv 13932\n",
      "97-newcomers.csv 13932\n",
      "smtpext.csv 13932\n",
      "mter.csv 13932\n",
      "tools-discuss.csv 13934\n",
      "90companions.csv 13934\n",
      "uswg.csv 13941\n",
      "isis-wg.csv 13943\n",
      "venue-selection.csv 13947\n",
      "pkix.csv 14323\n",
      "80attendees.csv 14323\n",
      "dlnex.csv 14323\n",
      "nsis-imp.csv 14323\n",
      "privacy-pass.csv 14323\n",
      "rsvp-dir.csv 14323\n",
      "opes.csv 14448\n",
      "prim.csv 14449\n",
      "yot.csv 14449\n",
      "isis.csv 14878\n",
      "port-srv-reg.csv 14878\n",
      "ecn-in-quic.csv 14878\n",
      "sip-http-events.csv 14878\n",
      "ipoib.csv 14998\n",
      "lmap.csv 14998\n",
      "ietf-mentors.csv 14998\n",
      "drums.csv 15014\n",
      "dmm.csv 15014\n",
      "mip4.csv 15025\n",
      "dna.csv 15026\n",
      "quic.csv 15036\n",
      "tcpprague.csv 15036\n",
      "103all.csv 15036\n",
      "keyassure.csv 15036\n",
      "apps-review.csv 15036\n",
      "independent.csv 15036\n",
      "ietf-cycling.csv 15036\n",
      "sigtran.csv 15043\n",
      "dcp.csv 15050\n",
      "poised.csv 15050\n",
      "ecrit.csv 15053\n",
      "95attendees.csv 15053\n",
      "grobj.csv 15053\n",
      "94companions.csv 15053\n",
      "x25mib.csv 15053\n",
      "grow.csv 15082\n",
      "74all.csv 15082\n",
      "92attendees.csv 15083\n",
      "dtn.csv 15092\n",
      "sipbrandy.csv 15093\n",
      "loops.csv 15097\n",
      "idn.csv 15308\n",
      "alto.csv 15319\n",
      "icar.csv 15319\n",
      "imap5.csv 15319\n",
      "dmsp.csv 15319\n",
      "captive-portals.csv 15319\n",
      "78all.csv 15319\n",
      "85-1st-timers.csv 15319\n",
      "90-1st-timers.csv 15319\n",
      "psamp.csv 15322\n",
      "emailcore.csv 15322\n",
      "rdma-cc-interest.csv 15322\n",
      "research-funding.csv 15552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmcat.csv 15552\n",
      "dispatch.csv 15563\n",
      "sixpac.csv 15563\n",
      "scuba-ag.csv 15563\n",
      "106-newcomers.csv 15563\n",
      "plus.csv 15563\n",
      "shim6.csv 15565\n",
      "spwg.csv 15565\n",
      "101companions.csv 15565\n",
      "xml2rfc.csv 15625\n",
      "wpack.csv 15625\n",
      "caris-attendees.csv 15625\n",
      "homenet.csv 15625\n",
      "aggsrv.csv 15625\n",
      "tcpsat.csv 15626\n",
      "ntp.csv 15638\n",
      "bfcpbis.csv 15638\n",
      "ldap-dir.csv 16112\n",
      "addr-select-dt.csv 16112\n",
      "catnip.csv 16112\n",
      "renum.csv 16112\n",
      "ipngwg.csv 16358\n",
      "ipr-announce.csv 16358\n",
      "crypto-panel.csv 16358\n",
      "ericas.csv 16358\n",
      "fax.csv 16358\n",
      "ietf80-1st-timers.csv 16358\n",
      "geopriv.csv 16374\n",
      "bcause.csv 16374\n",
      "ehip.csv 16374\n",
      "kitten.csv 16377\n",
      "oauth-ext-review.csv 16377\n",
      "udp35.csv 16377\n",
      "hash.csv 16377\n",
      "hls-interest.csv 16377\n",
      "savi.csv 16412\n",
      "vwrap.csv 16428\n",
      "95all.csv 16428\n",
      "maitai.csv 16428\n",
      "mpls-tp.csv 16435\n",
      "codec.csv 16436\n",
      "mip6.csv 16487\n",
      "add.csv 16487\n",
      "json-canon.csv 16487\n",
      "bgp-autoconf.csv 16488\n",
      "ldapbis.csv 16503\n",
      "iporpr.csv 16526\n",
      "102-newcomers.csv 16526\n",
      "curdle.csv 16532\n",
      "cso.csv 16532\n",
      "pesci-discuss.csv 16532\n",
      "sica.csv 16532\n",
      "ancp.csv 16550\n",
      "ietf-mentees.csv 16550\n",
      "87all.csv 16550\n",
      "6lowpan.csv 16559\n",
      "tn3270e.csv 16572\n",
      "xml-mime.csv 16612\n",
      "wish.csv 16612\n",
      "dmarc.csv 16630\n",
      "82-1st-timers.csv 16630\n",
      "recentattendees.csv 16635\n",
      "99all.csv 16635\n",
      "ietf77-1st-timers.csv 16635\n",
      "sframe.csv 16635\n",
      "p2pi.csv 16635\n",
      "atoca.csv 16635\n",
      "emo-dir.csv 16635\n",
      "scale.csv 16635\n",
      "rucus.csv 16635\n",
      "printmib.csv 16661\n",
      "decnetiv.csv 16661\n",
      "scap_interest.csv 16661\n",
      "mboned.csv 16662\n",
      "hokey.csv 16666\n",
      "93attendees.csv 16668\n",
      "yang-multicast.csv 16669\n",
      "6gip.csv 16669\n",
      "nat.csv 16706\n",
      "ip1394.csv 16706\n",
      "ipseckey.csv 16706\n",
      "94attendees.csv 16723\n",
      "102companions.csv 16723\n",
      "newsclips.csv 16725\n",
      "105-newcomers.csv 16725\n",
      "ppsp.csv 16736\n",
      "dtls-iot.csv 16736\n",
      "manet-dlep-rg.csv 16736\n",
      "saad.csv 16738\n",
      "ifmib.csv 16738\n",
      "ietf76-1st-timers.csv 16738\n",
      "stun.csv 16793\n",
      "krb-wg.csv 17144\n",
      "charset.csv 17144\n",
      "stdguide.csv 17144\n",
      "83-1st-timers.csv 17144\n",
      "96-1st-timers.csv 17144\n",
      "iola-wgcharter-tool.csv 17144\n",
      "stackevo.csv 17144\n",
      "cgasec.csv 17144\n",
      "sipping.csv 17155\n",
      "ipcdn.csv 17167\n",
      "diffserv-interest.csv 17168\n",
      "101-newcomers.csv 17168\n",
      "81attendees.csv 17169\n",
      "106companions.csv 17169\n",
      "ietf-announce.csv 17170\n",
      "fun.csv 17170\n",
      "vnrg.csv 17170\n",
      "pntaw.csv 17170\n",
      "rtg-bfd.csv 17175\n",
      "tlp-interest.csv 17176\n",
      "dnsext.csv 17204\n",
      "nemo.csv 17215\n",
      "anima-bootstrap.csv 17215\n",
      "netfax.csv 17215\n",
      "85all.csv 17215\n",
      "multrans.csv 17244\n",
      "policy.csv 17249\n",
      "esds.csv 17250\n",
      "79attendees.csv 17252\n",
      "86attendees.csv 17252\n",
      "srcomp.csv 17255\n",
      "rfc-dist.csv 17263\n",
      "sacm.csv 17267\n",
      "ietf-announce-old.csv 17296\n",
      "eligibility-discuss.csv 17297\n",
      "ietf-hub-bangalore.csv 17297\n",
      "96-mentors.csv 17297\n",
      "mailsec.csv 17297\n",
      "urn-nid.csv 17301\n",
      "89all.csv 17302\n",
      "tao-discuss.csv 17302\n",
      "pim.csv 17315\n",
      "privsec-discuss.csv 17315\n",
      "ietf-outcomes.csv 17315\n",
      "ire.csv 17315\n",
      "json.csv 17412\n",
      "ogpx.csv 17417\n",
      "97all.csv 17417\n",
      "osids.csv 17418\n",
      "yaco-community-tool.csv 17418\n",
      "userdoc2.csv 17418\n",
      "98reg.csv 17418\n",
      "sctp-impl.csv 17620\n",
      "v6tc.csv 17620\n",
      "lime.csv 17624\n",
      "secmech.csv 17625\n",
      "suit.csv 17625\n",
      "media-feature-tags.csv 17658\n",
      "101all.csv 17658\n",
      "homegate.csv 17658\n",
      "marf.csv 17659\n",
      "cdni.csv 17659\n",
      "v4tov6transition.csv 17659\n",
      "dnssd.csv 17659\n",
      "uta.csv 17662\n",
      "yam.csv 17662\n",
      "rrg.csv 17664\n",
      "93companions.csv 17664\n",
      "tewg.csv 17664\n",
      "conex.csv 17665\n",
      "ietf-smtp.csv 17701\n",
      "rfp-announce.csv 17701\n",
      "supa.csv 17719\n",
      "ason-routing.csv 17719\n",
      "ipv6mib.csv 17719\n",
      "saag.csv 17720\n",
      "tana.csv 17720\n",
      "eman.csv 17720\n",
      "91-1st-timers.csv 17720\n",
      "ledbat.csv 17720\n",
      "agenda-tool.csv 17720\n",
      "openv6.csv 17721\n",
      "vnfpool.csv 17721\n",
      "cacao.csv 17721\n",
      "dsfjdssdfsd.csv 17721\n",
      "manycouches.csv 17721\n",
      "danish.csv 17721\n",
      "woes.csv 17721\n",
      "tictoc.csv 17725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pkhare/anaconda3/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ietf.csv 18778\n",
      "openpgp.csv 18975\n",
      "sming.csv 18975\n",
      "snmpconf.csv 19004\n",
      "rift.csv 19004\n",
      "webtransport.csv 19004\n",
      "ietf79-1st-timers.csv 19004\n",
      "cip.csv 19004\n",
      "97companions.csv 19004\n",
      "arp222.csv 19004\n",
      "antitrust-policy.csv 19004\n",
      "mentoring-coordinators.csv 19006\n",
      "ipv6.csv 19027\n",
      "sacred.csv 19045\n",
      "pem.csv 19045\n",
      "sipping-tispan.csv 19045\n",
      "tnfs.csv 19045\n",
      "messaging.csv 19045\n",
      "time.csv 19045\n",
      "wrec.csv 21697\n",
      "spam.csv 21979\n",
      "rfc-interest.csv 21990\n",
      "76all.csv 21990\n",
      "eapext.csv 21990\n",
      "cwt-reg-review.csv 21990\n",
      "6tsch.csv 21990\n",
      "ioam.csv 21990\n",
      "hasmat.csv 21990\n",
      "media-types.csv 21991\n",
      "ltans.csv 21992\n",
      "jose.csv 22125\n"
     ]
    }
   ],
   "source": [
    "spam_messageIDs = set([])\n",
    "\n",
    "for file in os.listdir(\"../spamres/\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        fname = os.path.join(\"../spamres/\", file)\n",
    "        fdf = pd.read_csv(fname)\n",
    "        #print(file)\n",
    "        for i, r in fdf.iterrows():\n",
    "            \n",
    "            if r['header_flag'] == r['header_flag'] and 'yes' in r['header_flag'].lower():\n",
    "                spam_messageIDs.add(r['mid'])\n",
    "            elif r['SA_score'] >= 6.5:\n",
    "                spam_messageIDs.add(r['mid'])\n",
    "            \n",
    "        print(file,len(spam_messageIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "capable-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "pid_rolebased = set([])\n",
    "for eid in emailID_pid_dict:\n",
    "    if eid in role_based_emailIDs:\n",
    "        #print(eid)\n",
    "        pid_rolebased.add(int(emailID_pid_dict[eid]))\n",
    "print(len(pid_rolebased))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "controlling-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 1 1059\n",
      "2000 2 1578\n",
      "2001 3 2361\n",
      "2002 4 3469\n",
      "2003 5 4513\n",
      "2004 6 5289\n",
      "2005 7 6016\n",
      "2006 8 6514\n",
      "2007 9 6668\n",
      "2008 10 6537\n",
      "2009 11 6617\n",
      "2010 12 6650\n",
      "2011 13 6613\n",
      "2012 14 6571\n",
      "2013 15 6687\n",
      "2014 16 6661\n",
      "2015 17 6529\n",
      "2016 18 6299\n",
      "2017 19 6066\n",
      "2018 20 5701\n",
      "2019 21 5366\n",
      "2020 22 5079\n"
     ]
    }
   ],
   "source": [
    "#yearly_bwcnt_nodes_full = dict()\n",
    "#yearly_egnveccnt_nodes_full_1yr_window = dict()\n",
    "yearly_egnveccnt_nodes_full = dict()\n",
    "\n",
    "lst_spam_messageIDs = list(spam_messageIDs)\n",
    "for yr in range(1999,2021):#[2004,2009,2014,2019]:#[2000,2005,2010,2015,2019]:#range(2000, 2021):\n",
    "    for typ in ['overall']:#'wg'#['wg','rg','meeting','overall']:#,'dir','review','announcements']:\n",
    "        \n",
    "        if typ != 'overall':\n",
    "            #df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to')  & (df_mappings.Interaction_timestamp <= date(yr,12,31)) & (df_mappings.Mailinglist_type == typ) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs))]\n",
    "            #LOOKING FOR LAST 5 YEAR HISTORY\n",
    "            df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to')  & (df_mappings.Interaction_timestamp <= date(yr,12,31))  & (df_mappings.Interaction_timestamp > date(yr-5,12,31)) & (df_mappings.Mailinglist_type == typ) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs)) & (df_mappings.Mailinglist_type == \"wg\")]\n",
    "            #LOOKING FOR 1 YEAR HISTORY\n",
    "            #df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to')  & (df_mappings.Interaction_timestamp <= date(yr,12,31))  & (df_mappings.Interaction_timestamp > date(yr-1,12,31)) & (df_mappings.Mailinglist_type == typ) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs)) & (df_mappings.Mailinglist_type == \"wg\")]\n",
    "        else:\n",
    "            #df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to') & (df_mappings.Interaction_timestamp <= date(yr,12,31)) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs))]\n",
    "            #LOOKING FOR LAST 5 YEAR HISTORY\n",
    "            df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to') & (df_mappings.Interaction_timestamp <= date(yr,12,31)) & (df_mappings.Interaction_timestamp > date(yr-5,12,31)) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs))  & (df_mappings.Mailinglist_type == \"wg\")]\n",
    "            #LOOKING FOR LAST 1 YEAR HISTORY\n",
    "            #df_mappings4 = df_mappings.loc[(df_mappings.Type == 'reply_to') & (df_mappings.Interaction_timestamp <= date(yr,12,31)) & (df_mappings.Interaction_timestamp > date(yr-1,12,31)) & (~df_mappings.MessageID_A.isin(lst_spam_messageIDs)) & (~df_mappings.MessageID_B.isin(lst_spam_messageIDs))  & (df_mappings.Mailinglist_type == \"wg\")]\n",
    "        \n",
    "        G1 = nx.Graph()\n",
    "        \n",
    "        for i, r in df_mappings4.iterrows():\n",
    "            \n",
    "            if r['A_PersonID_From'] in pid_rolebased:\n",
    "                continue\n",
    "            if r['B_PersonID_To'] in pid_rolebased:\n",
    "                continue\n",
    "            #OPTIONAL   \n",
    "            #if not (r['Max_Time_A'] - r['Time_since_1st_mail_A'] + r['Interaction_timestamp'].year) >= yr:\n",
    "            #    continue\n",
    "            #if not (r['Max_Time_B'] - r['Time_since_1st_mail_B'] + r['Interaction_timestamp'].year) >= yr:\n",
    "            #    continue\n",
    "                \n",
    "            if r['A_PersonID_From'] not in G1:\n",
    "                G1.add_nodes_from([r['A_PersonID_From']])\n",
    "            if r['B_PersonID_To'] not in G1:\n",
    "                G1.add_nodes_from([r['B_PersonID_To']])\n",
    "                \n",
    "            G1.add_edges_from([(r['A_PersonID_From'], r['B_PersonID_To'])])\n",
    "            \n",
    "        if len(G1) > 0:\n",
    "          \n",
    "            d = centrality.eigenvector_centrality(G1)\n",
    "            d = dict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
    "            \n",
    "            #yearly_egnveccnt_nodes_full_1yr_window[yr] = d\n",
    "            yearly_egnveccnt_nodes_full[yr] = d\n",
    "        #print(yr,len(yearly_egnveccnt_nodes_full_1yr_window),len(G1))\n",
    "        print(yr,len(yearly_egnveccnt_nodes_full),len(G1))\n",
    "        G1.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "turned-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(yearly_egnveccnt_nodes_full[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "occupational-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_percentile = dict()\n",
    "#yr = 2019\n",
    "for yr in range(1999,2021):\n",
    "    #for pid in yearly_PIDs:\n",
    "        #d = yearly_bwcnt_nodes_full[yr]\n",
    "    d = yearly_egnveccnt_nodes_full[yr]\n",
    "    ordered_nodes = []\n",
    "\n",
    "    for k in d:\n",
    "        ordered_nodes.append(k)\n",
    "\n",
    "    #if pid not in ordered_nodes:\n",
    "    #    continue\n",
    "    \n",
    "    for pid in ordered_nodes:\n",
    "\n",
    "        percentile_position = round((ordered_nodes.index(pid)+1)*100/len(ordered_nodes))\n",
    "        if yr not in pid_percentile:\n",
    "            pid_percentile[yr] = {pid : percentile_position}\n",
    "        else:\n",
    "            pid_percentile[yr][pid] = percentile_position\n",
    "\n",
    "    #d2 = yearly_egnveccnt_nodes_full[yr]\n",
    "    #ordered_nodes2 = []\n",
    "\n",
    "    #for k in d2:\n",
    "    #    ordered_nodes2.append(k)\n",
    "\n",
    "    #if pid not in ordered_nodes2:\n",
    "    #    continue\n",
    "\n",
    "    #percentile_position2 = round((ordered_nodes2.index(pid)+1)*100/len(ordered_nodes2))\n",
    "\n",
    "    #avg_percentile = (percentile_position+percentile_position2)/2\n",
    "\n",
    "    #pid_percentile[pid] = avg_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "universal-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pid_percentile[yr][pid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-armstrong",
   "metadata": {},
   "source": [
    "To generate maillist_yearly_monthly_type_active_status.json (used below) please refer to https://github.com/sodestream/imc2021-submission/blob/main/scripts/emails/generate_maillist_yearly_monthly_type_active_status.py and https://github.com/sodestream/imc2021-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abandoned-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 1085\n"
     ]
    }
   ],
   "source": [
    "maillist_type = dict()\n",
    "f = open('../../analysis_ietf2/analysis_revision3/maillist_yearly_monthly_type_active_status.json')\n",
    "maillist_yearly_monthly_type_active_status = json.load(f)\n",
    "c = 0\n",
    "for grp in maillist_yearly_monthly_type_active_status:\n",
    "    flag = True\n",
    "    c += 1\n",
    "    for year in maillist_yearly_monthly_type_active_status[grp]:\n",
    "        if flag:\n",
    "            for month in maillist_yearly_monthly_type_active_status[grp][year]:\n",
    "                if flag:\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'wg':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'wg'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'rg':\n",
    "                        #list_RG.append(grp)\n",
    "                        maillist_type[grp] = 'rg'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'meeting':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'meeting'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'dir':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'dir'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'review':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'review'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'announcements':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'announcements'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'iab':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'iab'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'rag':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'rag'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'ag':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'ag'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'team':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'team'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'ietf@ietf.org':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'ietf@ietf.org'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'program':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'program'\n",
    "                        flag = False\n",
    "                    if maillist_yearly_monthly_type_active_status[grp][year][month]['type'] == 'nomcom':\n",
    "                        #list_WG.append(grp)\n",
    "                        maillist_type[grp] = 'nomcom'\n",
    "                        flag = False\n",
    "    \n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if flag:\n",
    "        maillist_type[grp] = 'other'\n",
    "        flag = False\n",
    "print(c, len(maillist_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlikely-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download from the repository - https://github.com/chbrown/liwc-python\n",
    "import liwc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-latin",
   "metadata": {},
   "source": [
    "The below LIWC dictionary is with postdoc team of Sodestream at QMUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "threaded-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a LIWC dictionary (to be acquired from liwc.net for research purpose)\n",
    "parse, category_names = liwc.load_token_parser('../LIWC2015_Dictionary.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threaded-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_t(text):\n",
    "    # you may want to use a smarter tokenizer\n",
    "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "        yield match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "short-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-parks",
   "metadata": {},
   "source": [
    "For email segmentation python file please contact Mladen Karan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strategic-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** Example 1 extracting unquoted parts from raw text  *********************************************************\n",
      "Segments:\n",
      "*** TYPE: quote***\n",
      "> This is\n",
      "> A quote\n",
      "*** TYPE: normal***\n",
      "And this is the reply.\n",
      "*** TYPE: signature***\n",
      "---\n",
      "Henry Jones Junior, PhD\n",
      "\n",
      "\n",
      "\n",
      " AFTER REMOVING QUOTES:\n",
      "And this is the reply.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************** Example 2 extracting unquoted parts from  EmailMessage class (old lib version)*********************************************************\n",
      "Segments:\n",
      "*** TYPE: normal***\n",
      "Section 3.10, event 16 under DTMF events.\n",
      "\n",
      "*** TYPE: quote***\n",
      "Romel Khan wrote:\n",
      "> How is it possible to pass the hook-flash over RTP?\n",
      "> I did not seem to find mention of that in RFC2833 under line events.\n",
      ">\n",
      "> Thanks.\n",
      ">\n",
      "> Romel Khan\n",
      "> Ph: (732)-363-0213, x241\n",
      ">\n",
      "> _______________________________________________\n",
      "> Audio/Video Transport Working Group\n",
      "> avt@ietf.org\n",
      "> http://www.ietf.org/mailman/listinfo/avt\n",
      "*** TYPE: signature***\n",
      "_______________________________________________\n",
      "Audio/Video Transport Working Group\n",
      "avt@ietf.org\n",
      "http://www.ietf.org/mailman/listinfo/avt\n",
      "\n",
      "\n",
      "\n",
      " AFTER REMOVING QUOTES:\n",
      "Section 3.10, event 16 under DTMF events.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************** Example 3 extracting unquoted parts from entire mailing list accounting for history (old lib version) *********************************************************\n",
      "\n",
      "First pass message 415 / 17347WARNING: message 415 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 580 / 17347WARNING: message 580 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1175 / 17347WARNING: message 1175 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1380 / 17347WARNING: message 1380 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1433 / 17347WARNING: message 1433 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1434 / 17347WARNING: message 1434 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1548 / 17347WARNING: message 1548 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1552 / 17347WARNING: message 1552 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1555 / 17347WARNING: message 1555 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 1914 / 17347WARNING: message 1914 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 2305 / 17347WARNING: message 2305 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 2530 / 17347WARNING: message 2530 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 3211 / 17347WARNING: message 3211 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 3316 / 17347WARNING: message 3316 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 3323 / 17347WARNING: message 3323 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 3529 / 17347WARNING: message 3529 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 4539 / 17347WARNING: message 4539 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 5074 / 17347WARNING: message 5074 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 6392 / 17347WARNING: message 6392 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 6790 / 17347WARNING: message 6790 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 6918 / 17347WARNING: message 6918 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 7402 / 17347WARNING: message 7402 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 8121 / 17347WARNING: message 8121 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 8125 / 17347WARNING: message 8125 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 8209 / 17347WARNING: message 8209 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 9471 / 17347WARNING: message 9471 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 10810 / 17347WARNING: message 10810 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11051 / 17347WARNING: message 11051 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11215 / 17347WARNING: message 11215 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11378 / 17347WARNING: message 11378 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11387 / 17347WARNING: message 11387 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11563 / 17347WARNING: message 11563 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 11564 / 17347WARNING: message 11564 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 12482 / 17347WARNING: message 12482 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 13213 / 17347WARNING: message 13213 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 13338 / 17347WARNING: message 13338 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 13371 / 17347WARNING: message 13371 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 13528 / 17347WARNING: message 13528 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 13758 / 17347WARNING: message 13758 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 14259 / 17347WARNING: message 14259 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15779 / 17347WARNING: message 15779 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15803 / 17347WARNING: message 15803 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15805 / 17347WARNING: message 15805 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15807 / 17347WARNING: message 15807 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15808 / 17347WARNING: message 15808 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15812 / 17347WARNING: message 15812 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 15908 / 17347WARNING: message 15908 in list avt caused an error when extracting text or initial segmentation\n",
      "First pass message 17351 / 17347\n",
      "Second pass - processing thread 14 / 7159None\n",
      "WARNING: message with id None in list avt caused an error when doing history based segmentation\n",
      "Second pass - processing thread 7158 / 7159\n",
      "How is it possible to pass the hook-flash over RTP? \n",
      "I did not seem to find mention of that in RFC2833 under line events.\n",
      "\n",
      "Thanks.\n",
      "\n",
      "Romel Khan\n",
      "Ph: (732)-363-0213, x241\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************** Example 4 extracting unquoted parts from  MailingListMessage class (new lib version) *********************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********************** Example 5 extracting unquoted parts from entire mailing list accounting for history (new lib version) *********************************************************\n"
     ]
    }
   ],
   "source": [
    "# run email_segmentation.py\n",
    "%run -i '../analysis_5/email_segmentation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spatial-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = ma.MailArchive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-limitation",
   "metadata": {},
   "source": [
    "generate msgid_messages_d dictionary that contains clean text after removing quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medieval-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#msgid_messages_d = dict()\n",
    "#for mailing_list_name in archive.mailing_list_names():\n",
    "## running only for working group (wg) type mailing list \n",
    "#    if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "#        continue\n",
    "#    print(mailing_list_name)\n",
    "#    t_d = get_unquoted_texts(archive, mailing_list_name)\n",
    "#    for key in t_d:\n",
    "#        msgid_messages_d[key] = t_d[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eleven-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.dump(msgid_messages_d, open( \"../analysis_5/msgid_messages_wg_d.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-laser",
   "metadata": {},
   "source": [
    "temporarily already loaded from a pre-curated dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "roman-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgid_messages_d = json.load(open('../analysis_5/msgid_messages_wg_d.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "after-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189236"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msgid_messages_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "administrative-collector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336\n"
     ]
    }
   ],
   "source": [
    "domain_jargon = set()\n",
    "with open('../analysis_5/internet_security_jargon.txt') as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines:\n",
    "        line = line.strip()\n",
    "        for t in line.lower().split():\n",
    "            domain_jargon.add(t.lower())\n",
    "        #print(line)\n",
    "print(len(domain_jargon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "driven-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table\n",
      "12 1506\n"
     ]
    }
   ],
   "source": [
    "abbr_set = set([])\n",
    "c = 0\n",
    "html_doc = \"../analysis_5/abbreviation_html.html\"\n",
    "with open(html_doc) as f:\n",
    "    #read File\n",
    "    content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    #print(soup.title)\n",
    "    for dobj0 in soup.find_all('div', attrs={'class':'Box mt-3 position-relative'}):\n",
    "        print('table')\n",
    "        for dobj1 in dobj0.find_all('tbody'):\n",
    "            #print('body')\n",
    "            for dobj2 in dobj1.find_all('tr'):\n",
    "                for dobj3 in dobj2.find('td'):\n",
    "                    try:\n",
    "                        #print(dobj3.text)\n",
    "                        abbr_set.add(dobj3.text.lower().strip())\n",
    "                    except:\n",
    "                        #print(dobj3)\n",
    "                        c += 1\n",
    "                        continue\n",
    "print(c, len(abbr_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "automated-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_tech_words = set(['urns','alive','kill','cryptographically','cryptographic','crypto','violating','violates','violate','violation','attacks', 'warning', 'parties', 'party', 'troubleshoot', 'troubleshooting', 'arguments','loss', 'lost', 'attacker', 'secure', 'insecure', 'vulnerability', 'vulnerable', 'threat', 'threats', 'attack', 'kill', 'argument', 'abuse', 'contradict', 'contradicts', 'loss', 'sender', 'receiver', 'receives', 'version', 'versions', 'attributes', 'attribute', 'identifier', 'identifiers', 'video', 'view', 'views', 'radio', 'telephone', 'click', 'voice', 'speaker', 'sound', 'image', 'sounds', 'loose', 'audio', 'hear', 'search', 'searching', 'fingerprints', 'fingerprint', 'banana', 'arch', 'vanilla', 'architecture', 'operates', 'operate', 'body', 'weight', 'operational', 'operation', 'bodies', 'head', 'heads', 'cookies', 'congestion', 'operator', 'operators', 'diagnostic', 'hand', 'boilerplate', 'colon', 'sleep', 'std', 'std13', 'expression', 'bar', 'parent', 'child','childern', 'request', 'requests', 'compliance', 'routers', 'router','bounce', 'bounces', 'bounced', 'connection', 'connections', 'operational','credential', 'credentials', 'gateway', 'gateways', 'tradeoff', 'killed', 'kill', 'operations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "understood-objective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catgs = []\n",
    "for i in category_names:\n",
    "    catgs.append(i)\n",
    "len(catgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-estonia",
   "metadata": {},
   "source": [
    "# RQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "burning-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "List- calsify , 1 , 42ames , 1 , 40'NoneType' object has no attribute 'replace'\n",
      "List- detnet , 1 , 66 631 , 43'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 1 , 7372 71'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 1 , 17267145 123'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 1 , 337333272'NoneType' object has no attribute 'replace'\n",
      "List- yam , 1 , 361 360, 352"
     ]
    }
   ],
   "source": [
    "usr_wg_LIWC_perc_d = dict()\n",
    "\n",
    "messageID_wg_LIWC_catg = dict()\n",
    "\n",
    "error_count = 0\n",
    "count = 0\n",
    "count2 = 1\n",
    "\n",
    "for yr1 in [2019]:#[2004, 2009, 2014, 2019]:\n",
    "    print(yr1)\n",
    "    for mailing_list_name in archive.mailing_list_names():\n",
    "        if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "            continue\n",
    "        #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "        print(\"\\rList- %s , %d , %d\" % (mailing_list_name, len(usr_wg_LIWC_perc_d), count2), end = '')\n",
    "        count2 += 1\n",
    "        ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "        if ml:\n",
    "            if ml._num_messages > 0:\n",
    "                ml_df = ml.messages_dataframe()\n",
    "                for index, row in ml_df.iterrows():\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        yr = row['Date'].year\n",
    "                        #if yr < 2015 or yr > 2019:#yr != 2014:\n",
    "                        #    continue\n",
    "                        if yr < yr1-4 or yr > yr1:\n",
    "                            continue\n",
    "\n",
    "                        if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                            continue\n",
    "\n",
    "                        e = row['From']\n",
    "\n",
    "                        e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                        x = re.findall(ren,str(e))\n",
    "\n",
    "                        if len(x) == 0:\n",
    "                            x = re.findall(ren2,str(e))\n",
    "                            if len(x) > 0:\n",
    "                                email = x[0]\n",
    "                        else:\n",
    "                            email = x[0][0]\n",
    "                        email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                        e = e.replace(email,'')\n",
    "\n",
    "                        email = email.lower()\n",
    "\n",
    "                        if '@' not in email:\n",
    "                            email = email.replace(' at ','@').lower()\n",
    "                        if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                            continue\n",
    "\n",
    "                        #eid = r['From_emailID']\n",
    "                        if email in emailID_pid_dict:\n",
    "                            pid = emailID_pid_dict[email]\n",
    "\n",
    "                            #if pid not in yearly_PIDs or pid not in pid_percentile:\n",
    "                            #    continue\n",
    "                            if pid not in pid_percentile[yr1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        #bdy = msgid_messages_d[message.message_id].lower()\n",
    "                        body_email = msgid_messages_d[index].lower()\n",
    "                        body_email = body_email.replace('\\n',' ')\n",
    "\n",
    "                        body_tokens = tokenize_t(body_email)\n",
    "\n",
    "                        #category_counts = Counter(category for token in body_tokens if token not in domain_jargon and token not in ambiguous_tech_words for category in parse(token))\n",
    "                        \n",
    "                        category_counts = dict()\n",
    "                        \n",
    "                        for token in body_tokens:\n",
    "                            if token in domain_jargon or token in abbr_set or token in ambiguous_tech_words:# or any(token in s for s in ambiguous_tech_words) or token in abbr_set:#token in ambiguous_tech_words:\n",
    "                                continue\n",
    "                            if len(token) > 3:\n",
    "                                if any(item.startswith(token) for item in ambiguous_tech_words) or any(token.startswith(item) for item in ambiguous_tech_words):\n",
    "                                    continue\n",
    "                                    \n",
    "                            for category in parse(token):\n",
    "                                category_counts[category] = category_counts.get(category,0) + 1\n",
    "                        \n",
    "                        category_counts = Counter(category_counts)\n",
    "                            \n",
    "\n",
    "                        #if pid not in usr_wg_LIWC_perc_d:\n",
    "                        #    usr_wg_LIWC_perc_d[pid] = {'Email_count':1,'Percentile':pid_percentile[pid]}\n",
    "                        #else:\n",
    "                        #    usr_wg_LIWC_perc_d[pid]['Email_count'] = usr_wg_LIWC_perc_d[pid]['Email_count'] + 1\n",
    "\n",
    "                        if yr1 not in usr_wg_LIWC_perc_d:\n",
    "                            usr_wg_LIWC_perc_d[yr1] = {pid : {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}}\n",
    "                        else:\n",
    "                            if pid not in usr_wg_LIWC_perc_d[yr1]:\n",
    "                                usr_wg_LIWC_perc_d[yr1][pid] = {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}\n",
    "                            else:\n",
    "                                usr_wg_LIWC_perc_d[yr1][pid]['Email_count'] = usr_wg_LIWC_perc_d[yr1][pid]['Email_count'] + 1\n",
    "\n",
    "                        #messageID_wg_LIWC_catg[index] = {'Percentile':pid_percentile[pid]}\n",
    "                        messageID_wg_LIWC_catg[index] = {'Percentile':pid_percentile[yr1][pid]}\n",
    "                        #for catg_ in category_counts:\n",
    "                        for catg_ in catgs:\n",
    "\n",
    "                            #usr_wg_LIWC_perc_d[pid][catg_] = usr_wg_LIWC_perc_d[pid].get(catg_,0) + category_counts[catg_]\n",
    "                            usr_wg_LIWC_perc_d[yr1][pid][catg_] = usr_wg_LIWC_perc_d[yr1][pid].get(catg_,0) + category_counts[catg_]\n",
    "\n",
    "                            messageID_wg_LIWC_catg[index][catg_] = category_counts[catg_]\n",
    "\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "confidential-lottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape- 5363 76"
     ]
    }
   ],
   "source": [
    "usr_wg_LIWC_perc_df = pd.DataFrame(columns = ['PID']+['Year']+catgs+['Percentile'])\n",
    "\n",
    "for yr in usr_wg_LIWC_perc_d:\n",
    "\n",
    "#for p in usr_wg_LIWC_perc_d:\n",
    "\n",
    "    for p in usr_wg_LIWC_perc_d[yr]:\n",
    "        lst = []\n",
    "        lst.append(p)\n",
    "        lst.append(yr)\n",
    "        for catg_ in catgs:\n",
    "            #lst.append(np.log((usr_wg_LIWC_perc_d[p][catg_]+1)/usr_wg_LIWC_perc_d[p]['Email_count']))\n",
    "            lst.append(np.log((usr_wg_LIWC_perc_d[yr][p][catg_]+1)/usr_wg_LIWC_perc_d[yr][p]['Email_count']))\n",
    "        #lst.append(usr_wg_LIWC_perc_d[p]['Percentile'])\n",
    "        lst.append(usr_wg_LIWC_perc_d[yr][p]['Percentile'])\n",
    "        usr_wg_LIWC_perc_df.loc[0 if pd.isnull(usr_wg_LIWC_perc_df.index.max()) else usr_wg_LIWC_perc_df.index.max() + 1] = lst\n",
    "        print(\"\\rShape- %d %d\" % (usr_wg_LIWC_perc_df.shape[0],usr_wg_LIWC_perc_df.shape[1]), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "written-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>...</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100889.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.234107</td>\n",
       "      <td>2.765209</td>\n",
       "      <td>1.858135</td>\n",
       "      <td>0.995428</td>\n",
       "      <td>0.648027</td>\n",
       "      <td>0.323787</td>\n",
       "      <td>-1.734601</td>\n",
       "      <td>-1.041454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.635989</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>0.211309</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-1.916923</td>\n",
       "      <td>-0.390866</td>\n",
       "      <td>-0.887303</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101304.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100149.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.155662</td>\n",
       "      <td>1.890392</td>\n",
       "      <td>1.114413</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>-0.387192</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>-3.618491</td>\n",
       "      <td>-1.708948</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.114413</td>\n",
       "      <td>-3.826130</td>\n",
       "      <td>-6.391079</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-5.292467</td>\n",
       "      <td>-2.135467</td>\n",
       "      <td>-1.633188</td>\n",
       "      <td>-2.411398</td>\n",
       "      <td>-3.500707</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101114.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.161021</td>\n",
       "      <td>2.822585</td>\n",
       "      <td>1.926067</td>\n",
       "      <td>0.879797</td>\n",
       "      <td>0.843926</td>\n",
       "      <td>0.450290</td>\n",
       "      <td>-2.790836</td>\n",
       "      <td>-0.695891</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.206716</td>\n",
       "      <td>-2.403390</td>\n",
       "      <td>-4.736747</td>\n",
       "      <td>0.290008</td>\n",
       "      <td>-3.539043</td>\n",
       "      <td>-0.790322</td>\n",
       "      <td>-0.566213</td>\n",
       "      <td>-1.363006</td>\n",
       "      <td>-2.773137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101226.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.356594</td>\n",
       "      <td>1.934039</td>\n",
       "      <td>1.070690</td>\n",
       "      <td>0.611654</td>\n",
       "      <td>-0.853112</td>\n",
       "      <td>-0.555277</td>\n",
       "      <td>-4.339467</td>\n",
       "      <td>-2.547708</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.442347</td>\n",
       "      <td>-3.828641</td>\n",
       "      <td>-4.744932</td>\n",
       "      <td>-0.737599</td>\n",
       "      <td>-5.438079</td>\n",
       "      <td>-2.393557</td>\n",
       "      <td>-1.189584</td>\n",
       "      <td>-2.347037</td>\n",
       "      <td>-4.744932</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID    Year  function   pronoun     ppron         i        we  \\\n",
       "0  100889.0  2019.0  4.234107  2.765209  1.858135  0.995428  0.648027   \n",
       "1  101304.0  2019.0  3.295837  1.945910  1.609438  1.609438  0.000000   \n",
       "2  100149.0  2019.0  3.155662  1.890392  1.114413  0.098885 -0.387192   \n",
       "3  101114.0  2019.0  4.161021  2.822585  1.926067  0.879797  0.843926   \n",
       "4  101226.0  2019.0  3.356594  1.934039  1.070690  0.611654 -0.853112   \n",
       "\n",
       "        you     shehe      they  ...     money     relig     death  informal  \\\n",
       "0  0.323787 -1.734601 -1.041454  ... -0.635989 -3.526361 -3.526361  0.211309   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.693147   \n",
       "2  0.058601 -3.618491 -1.708948  ... -2.114413 -3.826130 -6.391079 -0.865626   \n",
       "3  0.450290 -2.790836 -0.695891  ... -1.206716 -2.403390 -4.736747  0.290008   \n",
       "4 -0.555277 -4.339467 -2.547708  ... -2.442347 -3.828641 -4.744932 -0.737599   \n",
       "\n",
       "      swear  netspeak    assent    nonflu    filler  Percentile  \n",
       "0 -3.526361 -1.916923 -0.390866 -0.887303 -2.427748        18.0  \n",
       "1  0.000000  0.000000  0.693147  0.000000  0.000000        93.0  \n",
       "2 -5.292467 -2.135467 -1.633188 -2.411398 -3.500707         2.0  \n",
       "3 -3.539043 -0.790322 -0.566213 -1.363006 -2.773137         1.0  \n",
       "4 -5.438079 -2.393557 -1.189584 -2.347037 -4.744932         3.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_LIWC_perc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "moral-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "regulated-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  function   pronoun     ppron         i        we       you  \\\n",
      "0  2019.0  4.234107  2.765209  1.858135  0.995428  0.648027  0.323787   \n",
      "1  2019.0  3.295837  1.945910  1.609438  1.609438  0.000000  0.000000   \n",
      "2  2019.0  3.155662  1.890392  1.114413  0.098885 -0.387192  0.058601   \n",
      "3  2019.0  4.161021  2.822585  1.926067  0.879797  0.843926  0.450290   \n",
      "4  2019.0  3.356594  1.934039  1.070690  0.611654 -0.853112 -0.555277   \n",
      "\n",
      "      shehe      they     ipron  ...     money     relig     death  informal  \\\n",
      "0 -1.734601 -1.041454  2.238831  ... -0.635989 -3.526361 -3.526361  0.211309   \n",
      "1  0.000000  0.000000  1.098612  ...  0.000000  0.000000  0.000000  0.693147   \n",
      "2 -3.618491 -1.708948  1.272328  ... -2.114413 -3.826130 -6.391079 -0.865626   \n",
      "3 -2.790836 -0.695891  2.296374  ... -1.206716 -2.403390 -4.736747  0.290008   \n",
      "4 -4.339467 -2.547708  1.381937  ... -2.442347 -3.828641 -4.744932 -0.737599   \n",
      "\n",
      "      swear  netspeak    assent    nonflu    filler  Percentile  \n",
      "0 -3.526361 -1.916923 -0.390866 -0.887303 -2.427748        18.0  \n",
      "1  0.000000  0.000000  0.693147  0.000000  0.000000        93.0  \n",
      "2 -5.292467 -2.135467 -1.633188 -2.411398 -3.500707         2.0  \n",
      "3 -3.539043 -0.790322 -0.566213 -1.363006 -2.773137         1.0  \n",
      "4 -5.438079 -2.393557 -1.189584 -2.347037 -4.744932         3.0  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "['function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achiev', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler']\n",
      "['Percentile']\n",
      "   function   pronoun     ppron         i        we       you     shehe  \\\n",
      "0  4.234107  2.765209  1.858135  0.995428  0.648027  0.323787 -1.734601   \n",
      "1  3.295837  1.945910  1.609438  1.609438  0.000000  0.000000  0.000000   \n",
      "2  3.155662  1.890392  1.114413  0.098885 -0.387192  0.058601 -3.618491   \n",
      "3  4.161021  2.822585  1.926067  0.879797  0.843926  0.450290 -2.790836   \n",
      "4  3.356594  1.934039  1.070690  0.611654 -0.853112 -0.555277 -4.339467   \n",
      "\n",
      "       they     ipron   article  ...      home     money     relig     death  \\\n",
      "0 -1.041454  2.238831 -0.435318  ... -1.734601 -0.635989 -3.526361 -3.526361   \n",
      "1  0.000000  1.098612  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2 -1.708948  1.272328 -0.948662  ... -2.879534 -2.114413 -3.826130 -6.391079   \n",
      "3 -0.695891  2.296374  0.155481  ... -1.074789 -1.206716 -2.403390 -4.736747   \n",
      "4 -2.547708  1.381937 -0.256296  ... -3.040184 -2.442347 -3.828641 -4.744932   \n",
      "\n",
      "   informal     swear  netspeak    assent    nonflu    filler  \n",
      "0  0.211309 -3.526361 -1.916923 -0.390866 -0.887303 -2.427748  \n",
      "1  0.693147  0.000000  0.000000  0.693147  0.000000  0.000000  \n",
      "2 -0.865626 -5.292467 -2.135467 -1.633188 -2.411398 -3.500707  \n",
      "3  0.290008 -3.539043 -0.790322 -0.566213 -1.363006 -2.773137  \n",
      "4 -0.737599 -5.438079 -2.393557 -1.189584 -2.347037 -4.744932  \n",
      "\n",
      "[5 rows x 73 columns]\n",
      "(5363, 73)\n",
      "\n",
      "   centrality\n",
      "0        18.0\n",
      "1        93.0\n",
      "2         2.0\n",
      "3         1.0\n",
      "4         3.0\n",
      "(5363, 1)\n",
      "   const  function   pronoun     ppron         i        we       you  \\\n",
      "0    1.0  0.862914  0.788141  0.628303  0.438295  0.792100  0.363076   \n",
      "1    1.0 -0.070536 -0.182167  0.305656  1.267103  0.070069 -0.030260   \n",
      "2    1.0 -0.209990 -0.247919 -0.336565 -0.771884 -0.361340  0.040929   \n",
      "3    1.0  0.790204  0.856093  0.716435  0.282213  1.010371  0.516751   \n",
      "4    1.0 -0.010090 -0.196227 -0.393289 -0.079734 -0.880467 -0.704808   \n",
      "\n",
      "      shehe      they     ipron  ...      home     money     relig     death  \\\n",
      "0 -0.127825 -0.611353  0.855976  ... -0.256191  0.217509 -1.302718 -1.029733   \n",
      "1  1.220875  0.612512 -0.484224  ...  1.152386  0.852057  1.210691  1.189984   \n",
      "2 -1.592601 -1.395760 -0.280040  ... -1.185930 -1.257568 -1.516378 -2.832970   \n",
      "3 -0.949077 -0.205265  0.923612  ...  0.279608 -0.351927 -0.502322 -1.791627   \n",
      "4 -2.153180 -2.381429 -0.151207  ... -1.316385 -1.584759 -1.518168 -1.796779   \n",
      "\n",
      "   informal     swear  netspeak    assent    nonflu    filler  \n",
      "0  0.496185 -1.092949 -1.062797  0.456897  0.185885 -0.603020  \n",
      "1  1.163175  1.190107  0.899814  1.849452  1.115360  1.217201  \n",
      "2 -0.994577 -2.236372 -1.286550 -1.139025 -1.410645 -1.407479  \n",
      "3  0.605125 -1.101160  0.090655  0.231642 -0.312426 -0.861978  \n",
      "4 -0.817353 -2.330645 -1.550792 -0.569159 -1.343226 -2.340345  \n",
      "\n",
      "[5 rows x 74 columns]\n",
      "Statistical approach: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-84dec707162c>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data.columns] = scaler.fit_transform(data[data.columns])\n",
      "/Users/pkhare/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/pkhare/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             centrality   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.718\n",
      "Method:                 Least Squares   F-statistic:                     188.1\n",
      "Date:                Wed, 01 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        22:19:01   Log-Likelihood:                -22211.\n",
      "No. Observations:                5363   AIC:                         4.457e+04\n",
      "Df Residuals:                    5289   BIC:                         4.506e+04\n",
      "Df Model:                          73                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           49.9862      0.209    238.873      0.000      49.576      50.396\n",
      "function        -0.1469      2.113     -0.070      0.945      -4.288       3.994\n",
      "pronoun          1.3489      2.398      0.562      0.574      -3.352       6.050\n",
      "ppron            1.1805      1.335      0.884      0.377      -1.437       3.798\n",
      "i               -0.4531      0.495     -0.915      0.360      -1.424       0.518\n",
      "we              -2.1884      0.438     -4.997      0.000      -3.047      -1.330\n",
      "you             -0.3955      0.381     -1.039      0.299      -1.142       0.351\n",
      "shehe            1.4349      0.961      1.492      0.136      -0.450       3.320\n",
      "they            -1.7217      0.372     -4.622      0.000      -2.452      -0.991\n",
      "ipron           -1.3420      1.320     -1.016      0.310      -3.931       1.247\n",
      "article          0.8367      0.343      2.441      0.015       0.165       1.509\n",
      "prep             0.7252      1.210      0.599      0.549      -1.647       3.097\n",
      "auxverb          0.8328      0.957      0.870      0.384      -1.043       2.708\n",
      "adverb          -0.7971      0.632     -1.262      0.207      -2.036       0.442\n",
      "conj             2.0979      0.802      2.616      0.009       0.526       3.670\n",
      "negate          -0.1710      0.399     -0.429      0.668      -0.953       0.611\n",
      "verb            -1.4914      1.391     -1.072      0.284      -4.219       1.236\n",
      "adj             -1.3149      0.671     -1.961      0.050      -2.630      -0.000\n",
      "compare          0.5637      0.574      0.982      0.326      -0.562       1.689\n",
      "interrog         0.0898      0.455      0.197      0.844      -0.802       0.982\n",
      "number           0.7545      0.347      2.175      0.030       0.074       1.435\n",
      "quant           -0.0168      0.443     -0.038      0.970      -0.886       0.852\n",
      "affect           1.4273      1.455      0.981      0.327      -1.424       4.279\n",
      "posemo           0.4766      1.247      0.382      0.702      -1.968       2.921\n",
      "negemo          -1.6542      0.709     -2.335      0.020      -3.043      -0.265\n",
      "anx              1.0921      0.494      2.211      0.027       0.124       2.061\n",
      "anger           -1.5809      0.531     -2.978      0.003      -2.622      -0.540\n",
      "sad              1.0863      0.464      2.343      0.019       0.177       1.995\n",
      "social          -0.3856      0.663     -0.581      0.561      -1.686       0.915\n",
      "family          -0.3336      0.555     -0.601      0.548      -1.422       0.755\n",
      "friend           0.2304      0.386      0.597      0.550      -0.526       0.986\n",
      "female           2.3368      0.674      3.469      0.001       1.016       3.658\n",
      "male            -0.5400      0.890     -0.607      0.544      -2.285       1.205\n",
      "cogproc         -2.0908      1.425     -1.467      0.142      -4.885       0.703\n",
      "insight         -0.2271      0.560     -0.406      0.685      -1.324       0.870\n",
      "cause            0.2851      0.551      0.517      0.605      -0.796       1.366\n",
      "discrep         -1.0277      0.561     -1.833      0.067      -2.127       0.072\n",
      "tentat           0.0092      0.679      0.013      0.989      -1.321       1.339\n",
      "certain         -0.1989      0.406     -0.490      0.624      -0.996       0.598\n",
      "differ          -0.2958      0.793     -0.373      0.709      -1.850       1.259\n",
      "percept          0.3656      0.692      0.528      0.597      -0.991       1.723\n",
      "see              0.0150      0.570      0.026      0.979      -1.102       1.132\n",
      "hear            -0.5159      0.472     -1.092      0.275      -1.442       0.410\n",
      "feel             0.0769      0.491      0.157      0.875      -0.885       1.039\n",
      "bio             -5.5136      0.712     -7.739      0.000      -6.910      -4.117\n",
      "body             1.8395      0.694      2.651      0.008       0.479       3.200\n",
      "health           3.6630      0.694      5.275      0.000       2.302       5.024\n",
      "sexual           6.7608      0.924      7.316      0.000       4.949       8.572\n",
      "ingest           3.7522      0.615      6.101      0.000       2.547       4.958\n",
      "drives          -0.8579      1.044     -0.821      0.411      -2.905       1.189\n",
      "affiliation      1.3170      0.569      2.314      0.021       0.201       2.433\n",
      "achiev          -0.6506      0.489     -1.330      0.184      -1.610       0.308\n",
      "power           -0.1125      0.475     -0.237      0.813      -1.044       0.819\n",
      "reward           1.1801      0.390      3.026      0.002       0.416       1.945\n",
      "risk            -1.4911      0.415     -3.597      0.000      -2.304      -0.678\n",
      "focuspast       -0.5315      0.452     -1.177      0.239      -1.417       0.354\n",
      "focuspresent     0.6222      1.048      0.594      0.553      -1.433       2.677\n",
      "focusfuture      0.3294      0.402      0.818      0.413      -0.460       1.118\n",
      "relativ         -1.2543      1.698     -0.738      0.460      -4.584       2.075\n",
      "motion           0.3347      0.436      0.767      0.443      -0.521       1.190\n",
      "space            2.3934      1.076      2.225      0.026       0.285       4.502\n",
      "time             1.7982      0.751      2.394      0.017       0.326       3.271\n",
      "work            -0.0846      0.389     -0.217      0.828      -0.848       0.678\n",
      "leisure          0.5209      0.361      1.443      0.149      -0.187       1.228\n",
      "home             0.2425      0.433      0.560      0.575      -0.606       1.091\n",
      "money           -0.2515      0.343     -0.734      0.463      -0.924       0.421\n",
      "relig            0.9706      0.649      1.495      0.135      -0.302       2.243\n",
      "death            6.1810      0.929      6.651      0.000       4.359       8.003\n",
      "informal        -1.7437      0.535     -3.258      0.001      -2.793      -0.695\n",
      "swear            2.7861      0.830      3.357      0.001       1.159       4.413\n",
      "netspeak         1.1952      0.441      2.713      0.007       0.332       2.059\n",
      "assent           0.7092      0.429      1.652      0.099      -0.132       1.551\n",
      "nonflu           0.2421      0.483      0.501      0.616      -0.705       1.189\n",
      "filler           1.0885      0.593      1.836      0.066      -0.074       2.251\n",
      "==============================================================================\n",
      "Omnibus:                       68.275   Durbin-Watson:                   1.541\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.705\n",
      "Skew:                           0.281   Prob(JB):                     4.43e-16\n",
      "Kurtosis:                       3.000   Cond. No.                         87.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n",
      "Machine learning approach:\n",
      "Pearson correlation on test set is: (0.8444000923984019, 1.4017050504063405e-292)\n",
      "Spearman correlation on test set is: SpearmanrResult(correlation=0.8384986869168363, pvalue=1.1525498446751104e-284)\n",
      "     feature     weight\n",
      "0      const  49.977137\n",
      "1   function   0.545500\n",
      "2    pronoun  -0.240270\n",
      "3      ppron   1.905513\n",
      "4          i  -0.328567\n",
      "..       ...        ...\n",
      "69     swear   2.383036\n",
      "70  netspeak   1.365303\n",
      "71    assent   0.726734\n",
      "72    nonflu   0.526823\n",
      "73    filler   0.846216\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "\n",
      "\n",
      "Machine learning with non linear models (might take a little while):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation on test set is: (0.8269278434017171, 4.9177303510146145e-270)\n",
      "Spearman correlation on test set is: SpearmanrResult(correlation=0.810288168802157, pvalue=8.347437362191481e-251)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"./liwc_feats.csv\")\n",
    "#df = pd.read_csv(\"./user_wg_liwc_infl_features.csv\")\n",
    "#df = pd.read_csv(\"./user_wg_word_infl_features.csv\")\n",
    "#df1 = pd.read_csv(\"./user_wg_liwc_infl_features_20years.csv\")\n",
    "#df1 = pd.read_csv(\"./user_wg_WORDLEVEL_\"+catgr+\"_catg_infl_features_2015-19.csv\")\n",
    "#df1 = pd.read_csv(\"./startyear_top10year_liwc.csv\")\n",
    "df1 = usr_wg_LIWC_perc_df.copy()\n",
    "df1 = df1.drop(\"PID\", axis = 1)\n",
    "print(df1.head())\n",
    "\n",
    "for yr in [2019]:#[2004, 2009, 2014, 2019]:\n",
    "    df = df1.loc[df1.Year == yr]\n",
    "    df1 = df1.drop(\"Year\", axis = 1)\n",
    "    df = df1\n",
    "    feat_cols = [c for c in df.columns if c!=\"Percentile\" and c!=\"Year\"]\n",
    "    lab_cols = [c for c in df.columns if c==\"Percentile\"]\n",
    "\n",
    "    print(feat_cols)\n",
    "    print(lab_cols)\n",
    "    data = df[feat_cols]\n",
    "    labels = df[lab_cols]\n",
    "    labels.columns = [\"centrality\"]\n",
    "\n",
    "\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    print()\n",
    "    print(labels.head())\n",
    "    print(labels.shape)\n",
    "\n",
    "\n",
    "    # some scaling and preparation\n",
    "    scaler = StandardScaler()\n",
    "    data[data.columns] = scaler.fit_transform(data[data.columns])\n",
    "    data = sm.add_constant(data)\n",
    "    print(data.head())\n",
    "\n",
    "    # statistical approach with statsmodels\n",
    "    print(\"Statistical approach: \")\n",
    "    model = sm.OLS(labels[\"centrality\"], data)\n",
    "    res = model.fit()\n",
    "    print(res.summary())\n",
    "    text_file = open(\"Output_\"+str(yr)+\"_1.txt\", \"w\")\n",
    "\n",
    "    text_file.write(str(res.summary()))\n",
    "    text_file.close()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "\n",
    "    # machine learning approach with sklearn\n",
    "    print(\"Machine learning approach:\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels[\"centrality\"], test_size=0.20, random_state=42, shuffle = True)\n",
    "\n",
    "    model = LinearRegression(fit_intercept = False)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print( \"Pearson correlation on test set is: \" + str(pearsonr(list(preds), y_test)))\n",
    "    print( \"Spearman correlation on test set is: \" + str(spearmanr(list(preds), y_test)))\n",
    "\n",
    "    weights = pd.DataFrame()\n",
    "    weights[\"feature\"] = data.columns\n",
    "    weights[\"weight\"] = model.coef_\n",
    "    print(weights)\n",
    "    print()\n",
    "    print()\n",
    "    # nonlinear models just to see if we can get a better prediction\n",
    "    print(\"Machine learning with non linear models (might take a little while):\")\n",
    "    model = MLPRegressor(max_iter = 10000)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print( \"Pearson correlation on test set is: \" + str(pearsonr(list(preds), y_test)))\n",
    "    print( \"Spearman correlation on test set is: \" + str(spearmanr(list(preds), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "imperial-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually transform the feature correlation above to a CSV format - output_liwc_features_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "standing-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_liwc_features_2019 = pd.read_csv('../analysis_5/output_liwc_features_2019.csv',delimiter=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reverse-publication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_liwc_features_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "favorite-enforcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'they', 'adj', 'negemo', 'anger', 'bio', 'risk', 'informal']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_liwc_features_2019.loc[(usr_liwc_features_2019['P>|t|'] <= 0.05) & (usr_liwc_features_2019.coef < 0)].feature.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "experimental-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['const',\n",
       " 'article',\n",
       " 'conj',\n",
       " 'number',\n",
       " 'anx',\n",
       " 'sad',\n",
       " 'female',\n",
       " 'body',\n",
       " 'health',\n",
       " 'sexual',\n",
       " 'ingest',\n",
       " 'affiliation',\n",
       " 'reward',\n",
       " 'space',\n",
       " 'time',\n",
       " 'death',\n",
       " 'swear',\n",
       " 'netspeak']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_liwc_features_2019.loc[(usr_liwc_features_2019['P>|t|'] <= 0.05) & (usr_liwc_features_2019.coef > 0)].feature.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-radiation",
   "metadata": {},
   "source": [
    "# RQ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-recipe",
   "metadata": {},
   "source": [
    "wg_chair_history.csv is gathered from conext2021 repository (paper wasn't submitted). Please contact Stephen McQuistin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "heard-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenny Paterson</td>\n",
       "      <td>cfrg</td>\n",
       "      <td>2015-07-12 01:54:22</td>\n",
       "      <td>2020-01-14 14:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexey Melnikov</td>\n",
       "      <td>cfrg</td>\n",
       "      <td>2015-07-12 01:54:22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nick Sullivan</td>\n",
       "      <td>cfrg</td>\n",
       "      <td>2019-05-01 15:05:02</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stanislav Smyshlyaev</td>\n",
       "      <td>cfrg</td>\n",
       "      <td>2020-01-14 14:14:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joerg Ott</td>\n",
       "      <td>dtnrg</td>\n",
       "      <td>2015-01-23 04:06:57</td>\n",
       "      <td>2016-04-05 06:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  group                start                  end\n",
       "0        Kenny Paterson   cfrg  2015-07-12 01:54:22  2020-01-14 14:14:00\n",
       "1       Alexey Melnikov   cfrg  2015-07-12 01:54:22                 None\n",
       "2         Nick Sullivan   cfrg  2019-05-01 15:05:02                 None\n",
       "3  Stanislav Smyshlyaev   cfrg  2020-01-14 14:14:00                 None\n",
       "4             Joerg Ott  dtnrg  2015-01-23 04:06:57  2016-04-05 06:40:00"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_chair_history = pd.read_csv('../wg_chair_history.csv')\n",
    "wg_chair_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "central-bottle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wg_chair_history.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "significant-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niels\n",
      "NRO Chair\n",
      "Reddy K\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in wg_chair_history.name.unique():\n",
    "    #print(i)\n",
    "    if i.lower() not in name_pid_dict:\n",
    "        c += 1\n",
    "        print(i)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-helicopter",
   "metadata": {},
   "source": [
    "only 3 names not in name_pid_dictionary mapping, rest are mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "surrounded-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": [
    "wg_chair_start_dates = dict()\n",
    "\n",
    "for i,row in wg_chair_history.iterrows():\n",
    "    d = datetime.strptime(row['start'], '%Y-%m-%d %H:%M:%S').date()\n",
    "    if row['name'].lower() not in wg_chair_start_dates:\n",
    "        wg_chair_start_dates[row['name'].lower()] =  d\n",
    "    else:\n",
    "        #print('repeat record')\n",
    "        if d < wg_chair_start_dates[row['name'].lower()]:\n",
    "            wg_chair_start_dates[row['name'].lower()] = d\n",
    "            #print('update')\n",
    "        \n",
    "print(len(wg_chair_start_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "stretch-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_chair_d = dict()\n",
    "for i,row in wg_chair_history.iterrows():\n",
    "    d1 = datetime.strptime(row['start'], '%Y-%m-%d %H:%M:%S').date()\n",
    "    d2 = 'None'\n",
    "    if row['end'] != 'None':\n",
    "        d2 = datetime.strptime(row['end'], '%Y-%m-%d %H:%M:%S').date()\n",
    "    #print(row['name'],d1,d2)\n",
    "    if row['group'].lower() not in wg_chair_d:\n",
    "        wg_chair_d[row['group'].lower()] = {row['name'].lower() : [[d1, d2]]}\n",
    "    else:\n",
    "        if row['name'].lower() not in wg_chair_d[row['group'].lower()]:\n",
    "            wg_chair_d[row['group'].lower()][row['name'].lower()] = [[d1, d2]]\n",
    "        else:\n",
    "            wg_chair_d[row['group'].lower()][row['name'].lower()].append([d1,d2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-marketplace",
   "metadata": {},
   "source": [
    "converting names to PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "entertaining-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_set = set([])\n",
    "wg_chair_d2 = dict()\n",
    "for wg in wg_chair_d:\n",
    "    for p in wg_chair_d[wg]:\n",
    "        if p not in name_pid_dict:\n",
    "            c_set.add(p)\n",
    "            continue\n",
    "        if wg not in wg_chair_d2:\n",
    "            wg_chair_d2[wg] = {name_pid_dict[p] : wg_chair_d[wg][p]}\n",
    "        else:\n",
    "            wg_chair_d2[wg][name_pid_dict[p]] = wg_chair_d[wg][p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "collect-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joerg ott': [[datetime.date(2015, 1, 23), datetime.date(2016, 4, 5)]],\n",
       " 'kevin fall': [[datetime.date(2015, 1, 23), datetime.date(2016, 4, 5)]]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_chair_d['dtnrg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ruled-programmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{101048: [[datetime.date(2015, 1, 23), datetime.date(2016, 4, 5)]],\n",
       " 101140: [[datetime.date(2015, 1, 23), datetime.date(2016, 4, 5)]]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_chair_d2['dtnrg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "complex-clinic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "Shape- 52523 6 220084524034716139"
     ]
    }
   ],
   "source": [
    "usr_wg_message_perc_df = pd.DataFrame(columns = ['PID','Year','Percentile','Role','Message','Mailinglist'])\n",
    "\n",
    "error_count = 0\n",
    "count = 0\n",
    "count2 = 1\n",
    "count3 = 0\n",
    "for yr1 in [2019]:#[2018]:#[2017]:#[2004, 2009, 2014, 2019]:\n",
    "    print(yr1)\n",
    "    for mailing_list_name in archive.mailing_list_names():\n",
    "        if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "            continue\n",
    "        #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "        print(\"\\rList- %s , %d\" % (mailing_list_name, usr_wg_message_perc_df.shape[0]), end = '')\n",
    "        count2 += 1\n",
    "        ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "        if ml:\n",
    "            if ml._num_messages > 0:\n",
    "                ml_df = ml.messages_dataframe()\n",
    "                for index, row in ml_df.iterrows():\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        yr = row['Date'].year\n",
    "                        #if yr < 2015 or yr > 2019:#yr != 2014:\n",
    "                        #    continue\n",
    "                        #if yr < yr1-4 or yr > yr1:\n",
    "                        #    continue\n",
    "                        if yr != yr1:\n",
    "                            continue\n",
    "\n",
    "                        if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                            continue\n",
    "\n",
    "                        e = row['From']\n",
    "\n",
    "                        e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                        x = re.findall(ren,str(e))\n",
    "\n",
    "                        if len(x) == 0:\n",
    "                            x = re.findall(ren2,str(e))\n",
    "                            if len(x) > 0:\n",
    "                                email = x[0]\n",
    "                        else:\n",
    "                            email = x[0][0]\n",
    "                        email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                        e = e.replace(email,'')\n",
    "\n",
    "                        email = email.lower()\n",
    "\n",
    "                        if '@' not in email:\n",
    "                            email = email.replace(' at ','@').lower()\n",
    "                        if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                            continue\n",
    "\n",
    "                        #eid = r['From_emailID']\n",
    "                        if email in emailID_pid_dict:\n",
    "                            pid = emailID_pid_dict[email]\n",
    "\n",
    "                            #if pid not in yearly_PIDs or pid not in pid_percentile:\n",
    "                            #    continue\n",
    "                            if pid not in pid_percentile[yr1]:\n",
    "                                continue\n",
    "                            #if pid not in pid_percentile_1yr_window[yr1]:\n",
    "                            #    continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        #bdy = msgid_messages_d[message.message_id].lower()\n",
    "                        body_email = msgid_messages_d[index].lower()\n",
    "                        body_email = body_email.replace('\\n',' ')\n",
    "                        body_email = body_email.replace('\\t',' ')\n",
    "\n",
    "                        #body_tokens = tokenize_t(body_email)\n",
    "\n",
    "                        #category_counts = Counter(category for token in body_tokens if token not in domain_jargon for category in parse(token))\n",
    "\n",
    "                        #if pid not in usr_wg_LIWC_perc_d:\n",
    "                        #    usr_wg_LIWC_perc_d[pid] = {'Email_count':1,'Percentile':pid_percentile[pid]}\n",
    "                        #else:\n",
    "                        #    usr_wg_LIWC_perc_d[pid]['Email_count'] = usr_wg_LIWC_perc_d[pid]['Email_count'] + 1\n",
    "\n",
    "                        #role = \"None\"\n",
    "                        role = \"Non_WGC\"\n",
    "\n",
    "                        if mailing_list_name in wg_chair_d2:\n",
    "                            if pid in wg_chair_d2[mailing_list_name]:\n",
    "                                flag = False\n",
    "                                #row['Date']\n",
    "                                for dt_range in wg_chair_d2[mailing_list_name][pid]:\n",
    "                                    if flag == False:#len(wg_chair_d2[mailing_list_name][pid]) > 1 and\n",
    "                                        if row['Date'] >= dt_range[0]:\n",
    "                                            if dt_range[1] == \"None\" or row['Date'] <= dt_range[1]:\n",
    "                                                #role = \"ACT_WGC\"\n",
    "                                                role = \"CURRENT_WGC\"\n",
    "                                                flag = True\n",
    "                                                break\n",
    "                                            elif row['Date'] > dt_range[1]:\n",
    "                                                #role = \"PREV_WGC\"\n",
    "                                                role = \"PRIOR_WGC\"\n",
    "\n",
    "                            else:\n",
    "                                flag = False\n",
    "                                for ml in wg_chair_d2:\n",
    "                                    if flag:\n",
    "                                        break\n",
    "                                    if pid in wg_chair_d2[ml]:\n",
    "                                        for dt_range in wg_chair_d2[ml][pid]:\n",
    "                                            if flag == False:\n",
    "                                                if row['Date'] >= dt_range[0]:\n",
    "                                                    if dt_range[1] == \"None\" or row['Date'] <= dt_range[1]:\n",
    "                                                        #role = \"OTH_WGC\"\n",
    "                                                        role = \"ALLO_WGC\"\n",
    "                                                        flag = True\n",
    "                                                        break\n",
    "                                                    elif row['Date'] > dt_range[1]:\n",
    "                                                        #role = \"PREV_WGC\"#alt label \"PREV_OTH_WGC\"\n",
    "                                                        role = \"PRIOR_ALLO_WGC\"\n",
    "                                                        \n",
    "                        else:\n",
    "                            flag = False\n",
    "                            for ml in wg_chair_d2:\n",
    "                                if flag:\n",
    "                                    break\n",
    "                                if pid in wg_chair_d2[ml]:\n",
    "                                    for dt_range in wg_chair_d2[ml][pid]:\n",
    "                                        if flag == False:\n",
    "                                            if row['Date'] >= dt_range[0]:\n",
    "                                                if dt_range[1] == \"None\" or row['Date'] <= dt_range[1]:\n",
    "                                                    #role = \"OTH_WGC\"\n",
    "                                                    role = \"ALLO_WGC\"\n",
    "                                                    flag = True\n",
    "                                                    break\n",
    "                                                elif row['Date'] > dt_range[1]:\n",
    "                                                    #role = \"PREV_WGC\"#alt label \"PREV_OTH_WGC\"\n",
    "                                                    role = \"PRIOR_ALLO_WGC\"\n",
    "\n",
    "                        #lst = [pid,yr1, pid_percentile_1yr_window[yr1][pid], role, body_email]\n",
    "                        #lst = [pid,yr1, pid_percentile_1yr_window[yr1][pid], role, body_email, mailing_list_name]\n",
    "                        lst = [pid,yr1, pid_percentile[yr1][pid], role, body_email, mailing_list_name]\n",
    "                        if role != \"Non_WGC\": #\"None\":\n",
    "                            count3 += 1\n",
    "                        usr_wg_message_perc_df.loc[0 if pd.isnull(usr_wg_message_perc_df.index.max()) else usr_wg_message_perc_df.index.max() + 1] = lst\n",
    "                        print(\"\\rShape- %d %d %d\" % (usr_wg_message_perc_df.shape[0],usr_wg_message_perc_df.shape[1],count3), end = '')\n",
    "                        \n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "southeast-zambia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroconf\n"
     ]
    }
   ],
   "source": [
    "#checking last mailing list iterated\n",
    "print(mailing_list_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-thousand",
   "metadata": {},
   "source": [
    "zerocon is the last mailing list so all the mailing lists are iterated despite time out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "copyrighted-mattress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>Role</th>\n",
       "      <th>Message</th>\n",
       "      <th>Mailinglist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100300</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>ALLO_WGC</td>\n",
       "      <td>hi tal,  hi,  i am not a 6lo native, but i rev...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101435</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>ALLO_WGC</td>\n",
       "      <td>hi suresh, authors,  i agree that the ntp time...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101305</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>i agree with specifying time semantics with mo...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101400</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>hi tal,  thanks for your comments.  the scope ...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101430</td>\n",
       "      <td>2019</td>\n",
       "      <td>48</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>[please accept our apologies if you receive mu...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PID  Year Percentile      Role  \\\n",
       "0  100300  2019          0  ALLO_WGC   \n",
       "1  101435  2019          5  ALLO_WGC   \n",
       "2  101305  2019          5   Non_WGC   \n",
       "3  101400  2019         29   Non_WGC   \n",
       "4  101430  2019         48   Non_WGC   \n",
       "\n",
       "                                             Message Mailinglist  \n",
       "0  hi tal,  hi,  i am not a 6lo native, but i rev...         6lo  \n",
       "1  hi suresh, authors,  i agree that the ntp time...         6lo  \n",
       "2  i agree with specifying time semantics with mo...         6lo  \n",
       "3  hi tal,  thanks for your comments.  the scope ...         6lo  \n",
       "4  [please accept our apologies if you receive mu...         6lo  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_message_perc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "regional-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALLO_WGC', 'Non_WGC', 'PRIOR_ALLO_WGC', 'CURRENT_WGC',\n",
       "       'PRIOR_WGC'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_message_perc_df.Role.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "qualified-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2215 , 1"
     ]
    }
   ],
   "source": [
    "usr_wg_role_LIWC_perc_d = dict()\n",
    "roles_list = usr_wg_message_perc_df.Role.unique()\n",
    "c = 1\n",
    "for yr1 in [2019]:\n",
    "    for pid in usr_wg_message_perc_df.PID.unique():\n",
    "        print(\"\\r %d , %d\" % (c, len(usr_wg_role_LIWC_perc_d)), end = '')\n",
    "        c += 1\n",
    "        for role_ in roles_list:\n",
    "            \n",
    "            #if role_ == 'None':\n",
    "            #    role = 1\n",
    "            #elif role_ == 'ACT_WGC':\n",
    "            #    role = 0\n",
    "            #else:\n",
    "            #    continue\n",
    "            role = role_\n",
    "            #if role_ == 'Non_WGC':\n",
    "            #    role = 1\n",
    "            #elif role_ == \"CURRENT_WGC\":\n",
    "            #    role = 0\n",
    "            #else:\n",
    "            #    continue\n",
    "            \n",
    "            for i,r, in usr_wg_message_perc_df.loc[(usr_wg_message_perc_df.PID == pid) & (usr_wg_message_perc_df.Year == yr1) & (usr_wg_message_perc_df.Role == role_)].iterrows():\n",
    "\n",
    "                body_email = r['Message'].lower()#msgid_messages_d[index].lower()\n",
    "                body_email = body_email.replace('\\n',' ')\n",
    "                body_email = body_email.strip()\n",
    "                \n",
    "                if len(body_email) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                #if role_ != 'None':\n",
    "                #    role = 0\n",
    "                #else:\n",
    "                #    role = 1\n",
    "                \n",
    "\n",
    "                body_tokens = tokenize_t(body_email)\n",
    "\n",
    "                #category_counts = Counter(category for token in body_tokens if token not in domain_jargon and token not in ambiguous_tech_words for category in parse(token))\n",
    "\n",
    "                category_counts = dict()\n",
    "\n",
    "                for token in body_tokens:\n",
    "                    if token in domain_jargon or token in abbr_set or token in ambiguous_tech_words:# or any(token in s for s in ambiguous_tech_words) or token in abbr_set:#token in ambiguous_tech_words:\n",
    "                        continue\n",
    "                    if len(token) > 3:\n",
    "                        if any(item.startswith(token) for item in ambiguous_tech_words) or any(token.startswith(item) for item in ambiguous_tech_words):\n",
    "                            continue\n",
    "\n",
    "                    for category in parse(token):\n",
    "                        category_counts[category] = category_counts.get(category,0) + 1\n",
    "\n",
    "                category_counts = Counter(category_counts)\n",
    "\n",
    "\n",
    "                #if pid not in usr_wg_LIWC_perc_d:\n",
    "                #    usr_wg_LIWC_perc_d[pid] = {'Email_count':1,'Percentile':pid_percentile[pid]}\n",
    "                #else:\n",
    "                #    usr_wg_LIWC_perc_d[pid]['Email_count'] = usr_wg_LIWC_perc_d[pid]['Email_count'] + 1\n",
    "\n",
    "                if yr1 not in usr_wg_role_LIWC_perc_d:\n",
    "                    usr_wg_role_LIWC_perc_d[yr1] = {pid : {role:{'Email_count':1,'Percentile':pid_percentile[yr1][pid]}}}\n",
    "                else:\n",
    "                    if pid not in usr_wg_role_LIWC_perc_d[yr1]:\n",
    "                        usr_wg_role_LIWC_perc_d[yr1][pid] = {role: {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}}\n",
    "                    else:\n",
    "                        if role not in usr_wg_role_LIWC_perc_d[yr1][pid]:\n",
    "                            usr_wg_role_LIWC_perc_d[yr1][pid][role] = {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}\n",
    "                        else:\n",
    "                            usr_wg_role_LIWC_perc_d[yr1][pid][role]['Email_count'] = usr_wg_role_LIWC_perc_d[yr1][pid][role]['Email_count'] + 1\n",
    "\n",
    "                \n",
    "                #for catg_ in category_counts:\n",
    "                for catg_ in catgs:\n",
    "\n",
    "                    usr_wg_role_LIWC_perc_d[yr1][pid][role][catg_] = usr_wg_role_LIWC_perc_d[yr1][pid][role].get(catg_,0) + category_counts[catg_]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "tested-cambodia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2098 , 77"
     ]
    }
   ],
   "source": [
    "usr_wg_role_LIWC_perc_df = pd.DataFrame(columns=['PID','Year','Role']+catgs+['Percentile'])\n",
    "\n",
    "for yr1 in usr_wg_role_LIWC_perc_d:\n",
    "    \n",
    "    for pid in usr_wg_role_LIWC_perc_d[yr1]:\n",
    "        for role in ['CURRENT_WGC','Non_WGC']:\n",
    "        #for role in ['ACT_WGC','None']:\n",
    "        #for role in [0,1]:\n",
    "            if role not in usr_wg_role_LIWC_perc_d[yr1][pid]:\n",
    "                continue\n",
    "            #if role == \"None\":\n",
    "            if role == \"Non_WGC\":\n",
    "                r_ = 1\n",
    "            #elif role == \"ACT_WGC\":\n",
    "            elif role == \"CURRENT_WGC\":\n",
    "                r_ = 0\n",
    "            else:\n",
    "                continue\n",
    "            #lst = [pid, yr1, role]\n",
    "            lst = [pid, yr1, r_]\n",
    "            \n",
    "            for catg_ in catgs:\n",
    "                lst.append(np.log((usr_wg_role_LIWC_perc_d[yr1][pid][role][catg_]+1)/usr_wg_role_LIWC_perc_d[yr1][pid][role]['Email_count']))\n",
    "                \n",
    "            lst.append(usr_wg_role_LIWC_perc_d[yr1][pid][role]['Percentile'])\n",
    "            usr_wg_role_LIWC_perc_df.loc[0 if pd.isnull(usr_wg_role_LIWC_perc_df.index.max()) else usr_wg_role_LIWC_perc_df.index.max() + 1] = lst\n",
    "            print(\"\\r %d , %d\" % (usr_wg_role_LIWC_perc_df.shape[0], usr_wg_role_LIWC_perc_df.shape[1]), end = '')\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "little-welsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946\n",
      "152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Role</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>...</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101305.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.554934</td>\n",
       "      <td>2.332566</td>\n",
       "      <td>1.726899</td>\n",
       "      <td>0.756326</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-0.226773</td>\n",
       "      <td>-1.749200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.526056</td>\n",
       "      <td>-3.540959</td>\n",
       "      <td>-4.234107</td>\n",
       "      <td>-0.123233</td>\n",
       "      <td>-4.234107</td>\n",
       "      <td>-3.540959</td>\n",
       "      <td>-0.208755</td>\n",
       "      <td>-2.624669</td>\n",
       "      <td>-4.234107</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101400.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.193435</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.154665</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>1.056053</td>\n",
       "      <td>-2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.079442</td>\n",
       "      <td>-0.980829</td>\n",
       "      <td>-2.079442</td>\n",
       "      <td>0.559616</td>\n",
       "      <td>-2.079442</td>\n",
       "      <td>-0.287682</td>\n",
       "      <td>-0.287682</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-2.079442</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101430.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.345968</td>\n",
       "      <td>2.382628</td>\n",
       "      <td>1.871802</td>\n",
       "      <td>0.606136</td>\n",
       "      <td>0.606136</td>\n",
       "      <td>1.152680</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.427116</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>0.773190</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-1.791759</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101406.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.221511</td>\n",
       "      <td>2.819754</td>\n",
       "      <td>2.002708</td>\n",
       "      <td>1.483669</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>0.167054</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.704748</td>\n",
       "      <td>-0.788457</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-0.526093</td>\n",
       "      <td>-3.091042</td>\n",
       "      <td>-1.299283</td>\n",
       "      <td>-1.299283</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100140.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.903905</td>\n",
       "      <td>2.597158</td>\n",
       "      <td>1.856963</td>\n",
       "      <td>1.303144</td>\n",
       "      <td>0.210295</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>-3.157000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.058388</td>\n",
       "      <td>-3.850148</td>\n",
       "      <td>-2.751535</td>\n",
       "      <td>0.081678</td>\n",
       "      <td>-3.850148</td>\n",
       "      <td>-0.323787</td>\n",
       "      <td>-0.854415</td>\n",
       "      <td>-2.058388</td>\n",
       "      <td>-3.157000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID    Year  Role  function   pronoun     ppron         i        we  \\\n",
       "0  101305.0  2019.0   1.0  3.554934  2.332566  1.726899  0.756326  0.693147   \n",
       "1  101400.0  2019.0   1.0  4.193435  2.833213  2.154665  0.693147  1.321756   \n",
       "2  101430.0  2019.0   1.0  4.345968  2.382628  1.871802  0.606136  0.606136   \n",
       "3  101406.0  2019.0   1.0  4.221511  2.819754  2.002708  1.483669  0.342945   \n",
       "4  100140.0  2019.0   1.0  3.903905  2.597158  1.856963  1.303144  0.210295   \n",
       "\n",
       "        you     shehe  ...     money     relig     death  informal     swear  \\\n",
       "0 -0.226773 -1.749200  ... -1.526056 -3.540959 -4.234107 -0.123233 -4.234107   \n",
       "1  1.056053 -2.079442  ... -2.079442 -0.980829 -2.079442  0.559616 -2.079442   \n",
       "2  1.152680 -1.791759  ...  1.427116 -1.791759 -1.791759  0.916291 -1.791759   \n",
       "3  0.167054 -3.091042  ... -1.704748 -0.788457 -3.091042 -0.526093 -3.091042   \n",
       "4  0.021053 -3.157000  ... -2.058388 -3.850148 -2.751535  0.081678 -3.850148   \n",
       "\n",
       "   netspeak    assent    nonflu    filler  Percentile  \n",
       "0 -3.540959 -0.208755 -2.624669 -4.234107         5.0  \n",
       "1 -0.287682 -0.287682 -0.693147 -2.079442        29.0  \n",
       "2  0.773190 -1.791759 -0.693147 -1.791759        48.0  \n",
       "3 -1.299283 -1.299283 -2.397895 -2.397895        17.0  \n",
       "4 -0.323787 -0.854415 -2.058388 -3.157000         6.0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(usr_wg_role_LIWC_perc_df.loc[usr_wg_role_LIWC_perc_df.Role == 1].shape[0])\n",
    "print(usr_wg_role_LIWC_perc_df.loc[usr_wg_role_LIWC_perc_df.Role == 0].shape[0])\n",
    "usr_wg_role_LIWC_perc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cheap-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can rename ACT_WGC_vs_None_LIWC_scores.csv to CURRENT_WGC_vs_Non_WGC_LIWC_scores.csv\n",
    "#usr_wg_role_LIWC_perc_df.to_csv('../analysis_5/ACT_WGC_vs_None_LIWC_scores.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "orange-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.810894141829394"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_role_LIWC_perc_df.loc[usr_wg_role_LIWC_perc_df.Role==0].shape[0]*100/usr_wg_role_LIWC_perc_df.loc[usr_wg_role_LIWC_perc_df.Role==1].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "seven-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098\n",
      "308\n",
      "['function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achiev', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler']\n",
      "['Role']\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [c for c in usr_wg_role_LIWC_perc_df.columns if c!=\"Percentile\" and c!='PID' and c!='Year' and c!='Role']\n",
    "lab_cols = [c for c in usr_wg_role_LIWC_perc_df.columns if c==\"Role\"]\n",
    "\n",
    "temp_df = usr_wg_role_LIWC_perc_df.copy()\n",
    "print(temp_df.shape[0])\n",
    "temp_df = temp_df.drop(temp_df.query('Role == 1').sample(frac=.92, random_state=42).index)\n",
    "print(temp_df.shape[0])\n",
    "print(feat_cols)\n",
    "print(lab_cols)\n",
    "data = temp_df[feat_cols]\n",
    "labels = temp_df[lab_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eight-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.43589743589743"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.loc[temp_df.Role==0].shape[0]*100/temp_df.loc[temp_df.Role==1].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "foreign-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "print(temp_df.loc[temp_df.Role==0].shape[0])\n",
    "print(temp_df.loc[temp_df.Role==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "legitimate-check",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>...</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.078445</td>\n",
       "      <td>2.549724</td>\n",
       "      <td>1.779783</td>\n",
       "      <td>0.538997</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.656780</td>\n",
       "      <td>-2.233592</td>\n",
       "      <td>-0.559616</td>\n",
       "      <td>1.925291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.025352</td>\n",
       "      <td>-0.767255</td>\n",
       "      <td>-4.025352</td>\n",
       "      <td>-4.025352</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>-2.639057</td>\n",
       "      <td>-1.192138</td>\n",
       "      <td>-1.540445</td>\n",
       "      <td>-0.093526</td>\n",
       "      <td>-3.332205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.614960</td>\n",
       "      <td>1.540445</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>1.203973</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.877727</td>\n",
       "      <td>2.506886</td>\n",
       "      <td>1.639459</td>\n",
       "      <td>0.948158</td>\n",
       "      <td>0.133531</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>-3.555348</td>\n",
       "      <td>-0.847298</td>\n",
       "      <td>1.962105</td>\n",
       "      <td>-0.495077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.456736</td>\n",
       "      <td>-4.653960</td>\n",
       "      <td>-3.960813</td>\n",
       "      <td>-0.028988</td>\n",
       "      <td>-3.960813</td>\n",
       "      <td>-0.990399</td>\n",
       "      <td>-0.825319</td>\n",
       "      <td>-1.945910</td>\n",
       "      <td>-3.044522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.321645</td>\n",
       "      <td>1.991092</td>\n",
       "      <td>1.443453</td>\n",
       "      <td>-0.125163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750306</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-1.128465</td>\n",
       "      <td>1.137079</td>\n",
       "      <td>-0.818310</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.833213</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-1.329136</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-2.140066</td>\n",
       "      <td>-2.140066</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-2.427748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    function   pronoun     ppron         i        we       you     shehe  \\\n",
       "5   4.078445  2.549724  1.779783  0.538997  0.517943  0.656780 -2.233592   \n",
       "7   2.614960  1.540445  0.510826 -0.405465 -0.405465  0.000000 -1.098612   \n",
       "8   2.197225  0.916291  0.405465 -0.693147 -0.693147  0.405465 -0.693147   \n",
       "16  3.877727  2.506886  1.639459  0.948158  0.133531  0.009479 -3.555348   \n",
       "17  3.321645  1.991092  1.443453 -0.125163  0.000000  0.750306 -3.526361   \n",
       "\n",
       "        they     ipron   article  ...      home     money     relig     death  \\\n",
       "5  -0.559616  1.925291  0.000000  ... -4.025352 -0.767255 -4.025352 -4.025352   \n",
       "7  -1.098612  1.203973 -1.098612  ... -0.405465 -1.098612 -1.098612 -1.098612   \n",
       "8  -0.693147  0.405465 -0.693147  ... -0.693147 -0.693147 -0.693147 -0.693147   \n",
       "16 -0.847298  1.962105 -0.495077  ...  0.000000 -2.456736 -4.653960 -3.960813   \n",
       "17 -1.128465  1.137079 -0.818310  ... -2.833213 -2.427748 -3.526361 -3.526361   \n",
       "\n",
       "    informal     swear  netspeak    assent    nonflu    filler  \n",
       "5   0.331357 -2.639057 -1.192138 -1.540445 -0.093526 -3.332205  \n",
       "7  -0.405465 -1.098612 -1.098612 -1.098612 -0.405465 -1.098612  \n",
       "8  -0.693147 -0.693147 -0.693147 -0.693147 -0.693147 -0.693147  \n",
       "16 -0.028988 -3.960813 -0.990399 -0.825319 -1.945910 -3.044522  \n",
       "17 -1.329136 -3.526361 -2.140066 -2.140066 -3.526361 -2.427748  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "described-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.263625\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "log_reg = sm.Logit(labels, data).fit(maxiter = 100)#maxiter = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "featured-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   Role   No. Observations:                  308\n",
      "Model:                          Logit   Df Residuals:                      235\n",
      "Method:                           MLE   Df Model:                           72\n",
      "Date:                Thu, 02 Feb 2023   Pseudo R-squ.:                  0.6196\n",
      "Time:                        18:07:37   Log-Likelihood:                -81.197\n",
      "converged:                       True   LL-Null:                       -213.46\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.428e-24\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "function         3.5065      2.135      1.642      0.101      -0.678       7.691\n",
      "pronoun         -3.3153      4.030     -0.823      0.411     -11.213       4.582\n",
      "ppron            4.9085      2.842      1.727      0.084      -0.661      10.478\n",
      "i               -0.5695      0.751     -0.758      0.448      -2.042       0.903\n",
      "we              -2.1879      0.809     -2.705      0.007      -3.773      -0.602\n",
      "you             -2.9254      0.887     -3.298      0.001      -4.664      -1.187\n",
      "shehe           -1.1601      0.903     -1.285      0.199      -2.930       0.610\n",
      "they            -1.5214      0.666     -2.285      0.022      -2.826      -0.217\n",
      "ipron            2.5588      2.141      1.195      0.232      -1.637       6.754\n",
      "article         -1.0414      0.637     -1.634      0.102      -2.290       0.208\n",
      "prep            -2.7384      1.909     -1.435      0.151      -6.479       1.002\n",
      "auxverb         -1.6764      1.446     -1.160      0.246      -4.510       1.157\n",
      "adverb          -1.4811      1.115     -1.328      0.184      -3.667       0.705\n",
      "conj             3.1819      1.595      1.995      0.046       0.055       6.308\n",
      "negate           0.3455      0.616      0.560      0.575      -0.863       1.554\n",
      "verb            -1.2711      2.368     -0.537      0.591      -5.912       3.370\n",
      "adj             -2.1124      1.318     -1.603      0.109      -4.695       0.470\n",
      "compare          0.7943      1.100      0.722      0.470      -1.362       2.951\n",
      "interrog        -1.0011      0.827     -1.211      0.226      -2.621       0.619\n",
      "number           0.2653      0.610      0.435      0.663      -0.930       1.460\n",
      "quant            1.5280      0.844      1.811      0.070      -0.126       3.182\n",
      "affect          -9.8975      3.969     -2.494      0.013     -17.676      -2.119\n",
      "posemo           9.3745      3.843      2.440      0.015       1.843      16.906\n",
      "negemo           2.8408      1.203      2.361      0.018       0.483       5.199\n",
      "anx              0.0643      0.645      0.100      0.921      -1.201       1.329\n",
      "anger            0.7766      0.628      1.236      0.217      -0.455       2.008\n",
      "sad             -0.5088      0.708     -0.719      0.472      -1.896       0.878\n",
      "social          -3.4264      1.304     -2.628      0.009      -5.982      -0.871\n",
      "family           0.1008      0.440      0.229      0.819      -0.761       0.963\n",
      "friend           0.3735      0.384      0.973      0.331      -0.379       1.126\n",
      "female          -0.3302      0.700     -0.472      0.637      -1.702       1.042\n",
      "male             1.4910      0.853      1.748      0.080      -0.180       3.162\n",
      "cogproc          4.6264      2.005      2.307      0.021       0.697       8.556\n",
      "insight          0.3239      0.906      0.357      0.721      -1.452       2.100\n",
      "cause           -0.0082      0.839     -0.010      0.992      -1.652       1.636\n",
      "discrep         -0.0792      0.894     -0.089      0.929      -1.831       1.673\n",
      "tentat          -3.3251      1.464     -2.272      0.023      -6.194      -0.456\n",
      "certain         -0.0057      0.704     -0.008      0.993      -1.385       1.373\n",
      "differ          -1.1305      1.278     -0.884      0.376      -3.636       1.375\n",
      "percept          2.5438      1.372      1.854      0.064      -0.145       5.233\n",
      "see             -3.2539      1.135     -2.866      0.004      -5.479      -1.029\n",
      "hear             0.0074      0.631      0.012      0.991      -1.230       1.245\n",
      "feel            -1.0406      0.604     -1.722      0.085      -2.225       0.144\n",
      "bio              2.3620      0.888      2.660      0.008       0.621       4.103\n",
      "body            -1.3544      0.677     -2.002      0.045      -2.681      -0.028\n",
      "health          -1.5661      0.704     -2.224      0.026      -2.946      -0.186\n",
      "sexual          -0.6612      0.807     -0.819      0.413      -2.244       0.921\n",
      "ingest          -1.7424      0.586     -2.975      0.003      -2.890      -0.594\n",
      "drives          -0.4828      1.939     -0.249      0.803      -4.284       3.318\n",
      "affiliation      1.6524      1.174      1.407      0.159      -0.649       3.954\n",
      "achiev           1.3522      0.972      1.391      0.164      -0.553       3.257\n",
      "power            2.1582      0.962      2.244      0.025       0.273       4.043\n",
      "reward           0.0346      0.824      0.042      0.967      -1.580       1.649\n",
      "risk            -0.5268      0.610     -0.864      0.387      -1.722       0.668\n",
      "focuspast        1.4383      0.917      1.569      0.117      -0.359       3.236\n",
      "focuspresent     0.2833      1.975      0.143      0.886      -3.588       4.154\n",
      "focusfuture     -0.0219      0.747     -0.029      0.977      -1.487       1.443\n",
      "relativ          2.1172      2.316      0.914      0.361      -2.422       6.656\n",
      "motion           1.0459      0.850      1.231      0.218      -0.620       2.711\n",
      "space           -1.6270      1.651     -0.986      0.324      -4.862       1.608\n",
      "time            -1.8965      1.293     -1.467      0.142      -4.431       0.638\n",
      "work            -1.1697      0.691     -1.693      0.090      -2.523       0.184\n",
      "leisure          0.2762      0.427      0.647      0.518      -0.561       1.113\n",
      "home            -0.8940      0.437     -2.044      0.041      -1.751      -0.037\n",
      "money            0.8234      0.430      1.914      0.056      -0.020       1.666\n",
      "relig            0.4901      0.598      0.819      0.413      -0.683       1.663\n",
      "death            1.6223      1.021      1.588      0.112      -0.380       3.624\n",
      "informal         0.2001      1.058      0.189      0.850      -1.874       2.274\n",
      "swear            1.1303      0.871      1.297      0.195      -0.577       2.838\n",
      "netspeak         0.6385      0.606      1.053      0.292      -0.550       1.826\n",
      "assent           0.9326      0.735      1.268      0.205      -0.509       2.374\n",
      "nonflu          -0.1868      0.708     -0.264      0.792      -1.574       1.201\n",
      "filler           1.9386      0.721      2.689      0.007       0.526       3.352\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.summary())\n",
    "#text_file = open(\"../analysis_5/Output_ACTWGC_vs_None.txt\", \"w\")\n",
    "#text_file.write(str(log_reg.summary()))\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-column",
   "metadata": {},
   "source": [
    "# RQ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "representative-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done- 2020 "
     ]
    }
   ],
   "source": [
    "pid_percentile_years = dict()\n",
    "\n",
    "#for pid in pid_emailID_dict:#top_10_2019:\n",
    "\n",
    "for yr in range(1999,2021):\n",
    "\n",
    "    d = yearly_egnveccnt_nodes_full[yr]\n",
    "    #ordered_nodes = []\n",
    "\n",
    "    #for k_ in d:\n",
    "    #    ordered_nodes.append(k_)\n",
    "\n",
    "    #if pid not in ordered_nodes:\n",
    "    #    continue\n",
    "    c = 1\n",
    "    for pid in d:\n",
    "        percentile_position = round((c*100)/len(d))\n",
    "        c += 1\n",
    "\n",
    "    #percentile_position = round((ordered_nodes.index(pid)+1)*100/len(ordered_nodes))\n",
    "        k = percentile_position\n",
    "        if k/10 <= 1:\n",
    "            k_range = 0\n",
    "        elif k/10 <= 2:\n",
    "            k_range = 1\n",
    "        elif k/10 <= 3:\n",
    "            k_range = 2\n",
    "        elif k/10 <= 4:\n",
    "            k_range = 3\n",
    "        elif k/10 <= 5:\n",
    "            k_range = 4\n",
    "        elif k/10 <= 6:\n",
    "            k_range = 5\n",
    "        elif k/10 <= 7:\n",
    "            k_range = 6\n",
    "        elif k/10 <= 8:\n",
    "            k_range = 7\n",
    "        elif k/10 <= 9:\n",
    "            k_range = 8\n",
    "        elif k/10 <= 10:\n",
    "            k_range = 9\n",
    "\n",
    "        if pid not in pid_percentile_years:\n",
    "            pid_percentile_years[pid] = {k_range : [yr]}\n",
    "        else:\n",
    "            if k_range in pid_percentile_years[pid]:\n",
    "                pid_percentile_years[pid][k_range].append(yr)\n",
    "            else:\n",
    "                pid_percentile_years[pid][k_range] = [yr]\n",
    "    print(\"\\rDone- %d \" % (yr), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "acute-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_50_plus = dict()\n",
    "\n",
    "for pid in pid_percentile_years:\n",
    "    if len(set([5,6,7,8,9]).intersection(set([k for k in pid_percentile_years[pid]]))) > 0:\n",
    "        pid_50_plus[pid] = pid_percentile_years[pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "guilty-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14534 18139\n"
     ]
    }
   ],
   "source": [
    "print(len(pid_50_plus), len(pid_percentile_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "polar-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_50_plus2 = dict()\n",
    "for pid in pid_50_plus:\n",
    "    for i in [0,1,2,3,4,5,6,7,8,9]:\n",
    "        if i in pid_50_plus[pid]:\n",
    "            if pid not in pid_50_plus2:\n",
    "                pid_50_plus2[pid] = {i : min(pid_50_plus[pid][i])}\n",
    "            else:\n",
    "                pid_50_plus2[pid][i] = min(pid_50_plus[pid][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "strange-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List- abfab , 5, 0 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- bmwg , 36, 15  5   15 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- calsify , 41, 17 mes , 39, 17 'NoneType' object has no attribute 'replace'\n",
      "List- ccamp , 46, 18  , 42, 18 division by zero\n",
      "List- detnet , 65, 19 19 'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 72, 20 0 20 'NoneType' object has no attribute 'replace'\n",
      "List- ips , 139, 21 21 1  2, 21 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- ipsec , 140, 23 'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 171, 24 4 24 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- mboned , 186, 26 6 26 'NoneType' object has no attribute 'replace'\n",
      "List- midcom , 191, 27 27 'NoneType' object has no attribute 'replace'\n",
      "List- mmusic , 198, 28  'NoneType' object has no attribute 'replace'\n",
      "List- nemo , 211, 29 9 7, 29 'NoneType' object has no attribute 'replace'\n",
      "List- nsis , 220, 30   30 'NoneType' object has no attribute 'replace'\n",
      "List- ospf , 227, 31    division by zero\n",
      "List- pkix , 240, 32 32 'NoneType' object has no attribute 'replace'\n",
      "List- sipping , 294, 33 3 33 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 336, 37 7 37 'NoneType' object has no attribute 'replace'\n",
      "List- yam , 360, 38  38 , 38 "
     ]
    }
   ],
   "source": [
    "pid_liwc_changes_percntl = dict()\n",
    "error_count = 0\n",
    "count2 = 0\n",
    "\n",
    "#r_temp_list = set([\"lol\",\"death\",\"wealth\",\"love\",\"great\",\"uncle\"])\n",
    "\n",
    "for mailing_list_name in archive.mailing_list_names():\n",
    "    if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "        continue\n",
    "    #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "    print(\"\\rList- %s , %d, %d \" % (mailing_list_name, count2, error_count), end = '')\n",
    "    count2 += 1\n",
    "    ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "    if ml:\n",
    "        if ml._num_messages > 0:\n",
    "            ml_df = ml.messages_dataframe()\n",
    "            for index, row in ml_df.iterrows():\n",
    "                count += 1\n",
    "                try:\n",
    "                    yr = row['Date'].year\n",
    "                    #if yr > 2019 or yr < 2015:#yr != 2014:\n",
    "                    #    continue\n",
    "                    if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                        continue\n",
    "\n",
    "                    e = row['From']\n",
    "                    e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                    x = re.findall(ren,str(e))\n",
    "\n",
    "                    if len(x) == 0:\n",
    "                        x = re.findall(ren2,str(e))\n",
    "                        if len(x) > 0:\n",
    "                            email = x[0]\n",
    "                    else:\n",
    "                        email = x[0][0]\n",
    "                        \n",
    "                    if not email:\n",
    "                        continue\n",
    "                    email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                    e = e.replace(email,'')\n",
    "\n",
    "                    email = email.lower()\n",
    "\n",
    "                    if '@' not in email:\n",
    "                        email = email.replace(' at ','@').lower()\n",
    "                    if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                        continue\n",
    "\n",
    "                    #eid = r['From_emailID']\n",
    "                    if email in emailID_pid_dict:\n",
    "                        pid = emailID_pid_dict[email]\n",
    "                        if pid not in pid_50_plus2 or 0 not in pid_50_plus2[pid]:\n",
    "                            continue\n",
    "                        #zeroth_yr = pid_50_plus2[pid][0]#max([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        #max_perc_yr = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        \n",
    "                        #if max_perc_yr > zeroth_yr:\n",
    "                        #    continue\n",
    "                        #if yr > zeroth_yr or yr < (max_perc_yr-4):\n",
    "                        #    continue\n",
    "                        \n",
    "                        \n",
    "                            \n",
    "                        zeroth_yr = pid_50_plus2[pid][0]#max([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        #max_perc_yr = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        joining_yr = []\n",
    "                        for k in pid_50_plus[pid]:\n",
    "                            joining_yr.extend(pid_50_plus[pid][k])\n",
    "\n",
    "                        joining_yr = min(joining_yr)\n",
    "                        \n",
    "                        if joining_yr > zeroth_yr:\n",
    "                            continue\n",
    "                            \n",
    "                        if yr > zeroth_yr or yr < (joining_yr-4):\n",
    "                            continue\n",
    "                            \n",
    "                        flag = False\n",
    "                        for k in pid_50_plus[pid]:\n",
    "                            if joining_yr in pid_50_plus[pid][k]:\n",
    "                                if k < 5:\n",
    "                                    flag = True\n",
    "                                    break\n",
    "                        if flag:\n",
    "                            continue\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "                            \n",
    "                    body_email = msgid_messages_d[index].lower()\n",
    "                    if not body_email:\n",
    "                        continue\n",
    "                    body_email = body_email.replace('\\n',' ')\n",
    "\n",
    "                    body_tokens = list(tokenize_t(body_email))\n",
    "                    \n",
    "                    \n",
    "                    category_counts = dict()\n",
    "                        \n",
    "                    for token in body_tokens:\n",
    "                        if token in domain_jargon or token in abbr_set or token in ambiguous_tech_words:# or any(token in s for s in ambiguous_tech_words) or token in abbr_set:#token in ambiguous_tech_words:\n",
    "                            continue\n",
    "                        if len(token) > 3:\n",
    "                            if any(item.startswith(token) for item in ambiguous_tech_words) or any(token.startswith(item) for item in ambiguous_tech_words):\n",
    "                                continue\n",
    "\n",
    "                        for category in parse(token):\n",
    "                            category_counts[category] = category_counts.get(category,0) + 1\n",
    "\n",
    "                    category_counts = Counter(category_counts)\n",
    "                    \n",
    "                    for catg_ in catgs:\n",
    "                        \n",
    "                        if pid not in pid_liwc_changes_percntl:\n",
    "                            pid_liwc_changes_percntl[pid] = {yr : {catg_ : [category_counts[catg_]/len(body_tokens)]}}\n",
    "                        else:\n",
    "                            if yr not in pid_liwc_changes_percntl[pid]:\n",
    "                                pid_liwc_changes_percntl[pid][yr] = {catg_ : [category_counts[catg_]/len(body_tokens)]}\n",
    "                            else:\n",
    "                                if catg_ not in pid_liwc_changes_percntl[pid][yr]:\n",
    "                                    pid_liwc_changes_percntl[pid][yr][catg_] = [category_counts[catg_]/len(body_tokens)]\n",
    "                                else:\n",
    "                                    pid_liwc_changes_percntl[pid][yr][catg_].append(category_counts[catg_]/len(body_tokens))\n",
    "                                    \n",
    "                    #common_rw = 0\n",
    "                    #for token in body_tokens:\n",
    "                    #    if token in r_temp_list:\n",
    "                    #        common_rw += 1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                                    \n",
    "                except Exception as e:\n",
    "                    print(e)#, email, body_email)\n",
    "                    error_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "higher-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape- 1110 75"
     ]
    }
   ],
   "source": [
    "catg_pct_df = pd.DataFrame(columns= ['PID']+catgs+['Percentile'])\n",
    "for pid in pid_liwc_changes_percntl:\n",
    "    \n",
    "    yr_0 = pid_50_plus2[pid][0]#max([k for k in pid_liwc_changes_percntl[pid]])#\n",
    "    yr_least_pctl = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([k for k in pid_liwc_changes_percntl[pid]])#\n",
    "    \n",
    "    ##below new part                       \n",
    "    zeroth_yr = pid_50_plus2[pid][0]#max([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "    #max_perc_yr = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "    joining_yr = []\n",
    "    for k in pid_50_plus[pid]:\n",
    "        joining_yr.extend(pid_50_plus[pid][k])\n",
    "\n",
    "    joining_yr = min(joining_yr)\n",
    "\n",
    "    if joining_yr > zeroth_yr:\n",
    "        continue\n",
    "\n",
    "    #if yr > zeroth_yr or yr < (joining_yr-4):\n",
    "    #    continue\n",
    "\n",
    "    flag = False\n",
    "    for k in pid_50_plus[pid]:\n",
    "        if joining_yr in pid_50_plus[pid][k]:\n",
    "            if k < 5:\n",
    "                flag = True\n",
    "                break\n",
    "    if flag:\n",
    "        continue\n",
    "        \n",
    "    if yr_0 not in pid_liwc_changes_percntl[pid] or joining_yr not in pid_liwc_changes_percntl[pid]:\n",
    "        continue\n",
    "        \n",
    "    ##above new part\n",
    "    \n",
    "    #below line removed for changes between yr_least_pctl and joining_yr\n",
    "    #if yr_0 not in pid_liwc_changes_percntl[pid] or yr_least_pctl not in pid_liwc_changes_percntl[pid]:\n",
    "    #    continue\n",
    "        \n",
    "    lst = []\n",
    "    lst.append(pid)\n",
    "    \n",
    "    \n",
    "    for cat_ in catgs:\n",
    "        \n",
    "        l1 = []\n",
    "        \n",
    "        for y in range(joining_yr - 4,joining_yr + 1):\n",
    "            if y in pid_liwc_changes_percntl[pid]:\n",
    "                l1.extend(pid_liwc_changes_percntl[pid][y][cat_])\n",
    "        lst.append(np.log((np.sum(l1)+1)/len(l1)))\n",
    "        \n",
    "        #for y in range(yr_least_pctl - 4,yr_least_pctl + 1):\n",
    "        #    if y in pid_liwc_changes_percntl[pid]:\n",
    "        #        l1.extend(pid_liwc_changes_percntl[pid][y][cat_])\n",
    "        #lst.append(np.log((np.sum(l1)+1)/len(l1)))\n",
    "        \n",
    "        ##lst.append(np.log((np.sum(pid_liwc_changes_percntl[pid][yr_least_pctl][cat_])+1)/len(pid_liwc_changes_percntl[pid][yr_least_pctl][cat_])))\n",
    "        ##for i in pid_liwc_changes_percntl[pid][yr_least_pctl][cat_]:\n",
    "    \n",
    "    #for k in pid_50_plus2[pid]:\n",
    "    #    if pid_50_plus2[pid][k] == yr_least_pctl:\n",
    "    #        p_least = k#print(k)\n",
    "    #        break    \n",
    "    lst.append(1)\n",
    "    #d = yearly_egnveccnt_nodes_full[yr_least_pctl]\n",
    "    \n",
    "    #p_least = round(([k for k in d].index(pid)+1)*100/len(d))\n",
    "    #lst.append(p_least)\n",
    "        \n",
    "    catg_pct_df.loc[0 if pd.isnull(catg_pct_df.index.max()) else catg_pct_df.index.max() + 1] = lst\n",
    "    print(\"\\rShape- %d %d\" % (catg_pct_df.shape[0],catg_pct_df.shape[1]), end = '')\n",
    "    \n",
    "    lst = []\n",
    "    lst.append(pid)\n",
    "    \n",
    "    for cat_ in catgs:\n",
    "        \n",
    "        l1 = []\n",
    "        \n",
    "        for y in range(yr_0 - 4,yr_0 + 1):\n",
    "            if y in pid_liwc_changes_percntl[pid]:\n",
    "                l1.extend(pid_liwc_changes_percntl[pid][y][cat_])\n",
    "        lst.append(np.log((np.sum(l1)+1)/len(l1)))\n",
    "        \n",
    "        #lst.append(np.log((np.sum(pid_liwc_changes_percntl[pid][yr_0][cat_])+1)/len(pid_liwc_changes_percntl[pid][yr_0][cat_])))\n",
    "        #for i in pid_liwc_changes_percntl[pid][yr_least_pctl][cat_]:\n",
    "        \n",
    "    lst.append(0)\n",
    "    #lst.append(-1)\n",
    "    #d = yearly_egnveccnt_nodes_full[yr_0]\n",
    "    \n",
    "    #p_top10 = round(([k for k in d].index(pid)+1)*100/len(d))\n",
    "    #lst.append(p_top10)\n",
    "        \n",
    "    catg_pct_df.loc[0 if pd.isnull(catg_pct_df.index.max()) else catg_pct_df.index.max() + 1] = lst\n",
    "    print(\"\\rShape- %d %d\" % (catg_pct_df.shape[0],catg_pct_df.shape[1]), end = '')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "operational-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catg_pct_df.to_csv('../analysis_5/startyear_top10year_liwc_new.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "neural-permission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>...</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100755.0</td>\n",
       "      <td>-0.700376</td>\n",
       "      <td>-1.207475</td>\n",
       "      <td>-1.405489</td>\n",
       "      <td>-1.537992</td>\n",
       "      <td>-1.573941</td>\n",
       "      <td>-1.499650</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.371587</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.564761</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.579935</td>\n",
       "      <td>-1.602320</td>\n",
       "      <td>-1.593813</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100755.0</td>\n",
       "      <td>-1.158535</td>\n",
       "      <td>-2.254861</td>\n",
       "      <td>-2.710428</td>\n",
       "      <td>-2.979873</td>\n",
       "      <td>-3.097522</td>\n",
       "      <td>-3.117945</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>-3.285787</td>\n",
       "      <td>-2.584725</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>-3.050790</td>\n",
       "      <td>-3.274307</td>\n",
       "      <td>-3.123985</td>\n",
       "      <td>-3.218723</td>\n",
       "      <td>-3.278826</td>\n",
       "      <td>-3.295837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100785.0</td>\n",
       "      <td>-1.086618</td>\n",
       "      <td>-1.984817</td>\n",
       "      <td>-2.220003</td>\n",
       "      <td>-2.270473</td>\n",
       "      <td>-2.366518</td>\n",
       "      <td>-2.393903</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>-2.375229</td>\n",
       "      <td>-2.122716</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.285718</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>-2.313019</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>-2.387532</td>\n",
       "      <td>-2.348344</td>\n",
       "      <td>-2.370897</td>\n",
       "      <td>-2.397895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100785.0</td>\n",
       "      <td>-1.265752</td>\n",
       "      <td>-2.615516</td>\n",
       "      <td>-3.186570</td>\n",
       "      <td>-3.388317</td>\n",
       "      <td>-4.111678</td>\n",
       "      <td>-4.125301</td>\n",
       "      <td>-4.304065</td>\n",
       "      <td>-4.211184</td>\n",
       "      <td>-3.098692</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.178090</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>-3.305623</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>-3.865287</td>\n",
       "      <td>-3.613581</td>\n",
       "      <td>-4.126607</td>\n",
       "      <td>-4.272137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100036.0</td>\n",
       "      <td>-0.952080</td>\n",
       "      <td>-1.731629</td>\n",
       "      <td>-1.948808</td>\n",
       "      <td>-2.185215</td>\n",
       "      <td>-2.373650</td>\n",
       "      <td>-2.303050</td>\n",
       "      <td>-2.476149</td>\n",
       "      <td>-2.451507</td>\n",
       "      <td>-2.138042</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>-2.356929</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>-2.390950</td>\n",
       "      <td>-2.447596</td>\n",
       "      <td>-2.472443</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID  function   pronoun     ppron         i        we       you  \\\n",
       "0  100755.0 -0.700376 -1.207475 -1.405489 -1.537992 -1.573941 -1.499650   \n",
       "1  100755.0 -1.158535 -2.254861 -2.710428 -2.979873 -3.097522 -3.117945   \n",
       "2  100785.0 -1.086618 -1.984817 -2.220003 -2.270473 -2.366518 -2.393903   \n",
       "3  100785.0 -1.265752 -2.615516 -3.186570 -3.388317 -4.111678 -4.125301   \n",
       "4  100036.0 -0.952080 -1.731629 -1.948808 -2.185215 -2.373650 -2.303050   \n",
       "\n",
       "      shehe      they     ipron  ...     money     relig     death  informal  \\\n",
       "0 -1.609438 -1.609438 -1.371587  ... -1.609438 -1.609438 -1.609438 -1.564761   \n",
       "1 -3.295837 -3.285787 -2.584725  ... -3.295837 -3.295837 -3.295837 -3.050790   \n",
       "2 -2.397895 -2.375229 -2.122716  ... -2.285718 -2.397895 -2.397895 -2.313019   \n",
       "3 -4.304065 -4.211184 -3.098692  ... -4.178090 -4.317488 -4.317488 -3.305623   \n",
       "4 -2.476149 -2.451507 -2.138042  ... -2.484907 -2.484907 -2.484907 -2.356929   \n",
       "\n",
       "      swear  netspeak    assent    nonflu    filler  Percentile  \n",
       "0 -1.609438 -1.579935 -1.602320 -1.593813 -1.609438         1.0  \n",
       "1 -3.274307 -3.123985 -3.218723 -3.278826 -3.295837         0.0  \n",
       "2 -2.397895 -2.387532 -2.348344 -2.370897 -2.397895         1.0  \n",
       "3 -4.317488 -3.865287 -3.613581 -4.126607 -4.272137         0.0  \n",
       "4 -2.484907 -2.390950 -2.447596 -2.472443 -2.484907         1.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catg_pct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "through-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "1110\n",
      "['function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achiev', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler']\n",
      "['Percentile']\n"
     ]
    }
   ],
   "source": [
    "feat_cols2 = [c for c in catg_pct_df.columns if c!=\"Percentile\" and c!='PID' and c!='Year' and c!='Role']\n",
    "lab_cols2 = [c for c in catg_pct_df.columns if c==\"Percentile\"]\n",
    "\n",
    "temp_df2 = catg_pct_df.copy()\n",
    "print(temp_df2.shape[0])\n",
    "#temp_df = temp_df.drop(temp_df.query('Role == 1').sample(frac=.92, random_state=42).index)\n",
    "print(temp_df2.shape[0])\n",
    "print(feat_cols2)\n",
    "print(lab_cols2)\n",
    "data2 = temp_df2[feat_cols2]\n",
    "labels2 = temp_df2[lab_cols2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "metallic-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.254130\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             Percentile   No. Observations:                 1110\n",
      "Model:                          Logit   Df Residuals:                     1037\n",
      "Method:                           MLE   Df Model:                           72\n",
      "Date:                Thu, 02 Feb 2023   Pseudo R-squ.:                  0.6334\n",
      "Time:                        22:36:43   Log-Likelihood:                -282.08\n",
      "converged:                       True   LL-Null:                       -769.39\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.855e-158\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "function        26.1064      2.354     11.092      0.000      21.493      30.720\n",
      "pronoun        -47.1842      8.021     -5.883      0.000     -62.905     -31.463\n",
      "ppron           26.0433      7.699      3.383      0.001      10.954      41.132\n",
      "i               -1.1020      3.201     -0.344      0.731      -7.375       5.171\n",
      "we              -0.3280      2.365     -0.139      0.890      -4.963       4.307\n",
      "you             -3.2907      2.426     -1.356      0.175      -8.046       1.465\n",
      "shehe           28.1646     10.448      2.696      0.007       7.687      48.642\n",
      "they            -3.2974      2.727     -1.209      0.227      -8.642       2.048\n",
      "ipron           25.1444      5.189      4.846      0.000      14.974      35.314\n",
      "article         -5.9005      2.261     -2.610      0.009     -10.332      -1.469\n",
      "prep           -13.0019      2.119     -6.135      0.000     -17.156      -8.848\n",
      "auxverb         -8.9297      2.342     -3.812      0.000     -13.520      -4.339\n",
      "adverb          -6.1055      1.720     -3.549      0.000      -9.478      -2.733\n",
      "conj            -2.4309      2.548     -0.954      0.340      -7.424       2.563\n",
      "negate           4.6404      2.462      1.885      0.059      -0.184       9.465\n",
      "verb             5.2118      2.839      1.836      0.066      -0.353      10.777\n",
      "adj             -4.5166      2.320     -1.947      0.052      -9.064       0.031\n",
      "compare          2.4013      2.335      1.028      0.304      -2.176       6.978\n",
      "interrog         1.4062      1.840      0.764      0.445      -2.199       5.012\n",
      "number           4.9450      1.937      2.552      0.011       1.148       8.742\n",
      "quant            0.1315      1.790      0.073      0.941      -3.377       3.640\n",
      "affect          -3.1902      6.286     -0.508      0.612     -15.511       9.130\n",
      "posemo           1.9029      5.844      0.326      0.745      -9.551      13.357\n",
      "negemo           4.9274      4.418      1.115      0.265      -3.732      13.587\n",
      "anx             -0.3416      5.763     -0.059      0.953     -11.636      10.953\n",
      "anger           -4.2994      6.205     -0.693      0.488     -16.461       7.862\n",
      "sad              0.8143      3.519      0.231      0.817      -6.083       7.711\n",
      "social           3.2231      1.918      1.680      0.093      -0.536       6.982\n",
      "family          -2.4870      2.479     -1.003      0.316      -7.345       2.371\n",
      "friend           2.8368      2.673      1.061      0.288      -2.401       8.075\n",
      "female         -16.1966      8.144     -1.989      0.047     -32.159      -0.234\n",
      "male           -30.6283      9.431     -3.248      0.001     -49.113     -12.144\n",
      "cogproc         -8.2860      2.840     -2.918      0.004     -13.851      -2.721\n",
      "insight          4.0688      1.840      2.211      0.027       0.462       7.676\n",
      "cause            3.4486      1.815      1.900      0.057      -0.109       7.006\n",
      "discrep          1.7502      1.974      0.886      0.375      -2.120       5.620\n",
      "tentat          -1.0166      2.098     -0.485      0.628      -5.128       3.095\n",
      "certain          5.2270      1.788      2.923      0.003       1.722       8.732\n",
      "differ           1.8372      2.853      0.644      0.520      -3.754       7.429\n",
      "percept          0.8512      5.754      0.148      0.882     -10.426      12.128\n",
      "see             -6.6229      5.312     -1.247      0.212     -17.033       3.788\n",
      "hear             3.8783      4.899      0.792      0.429      -5.723      13.480\n",
      "feel             4.7987      6.313      0.760      0.447      -7.575      17.172\n",
      "bio             -5.1421      8.109     -0.634      0.526     -21.036      10.752\n",
      "body             3.9453     10.146      0.389      0.697     -15.940      23.830\n",
      "health           2.0627      7.469      0.276      0.782     -12.577      16.702\n",
      "sexual          37.3486     12.043      3.101      0.002      13.744      60.953\n",
      "ingest           6.2566      5.203      1.203      0.229      -3.941      16.454\n",
      "drives           2.4037      3.079      0.781      0.435      -3.632       8.439\n",
      "affiliation     -1.8842      2.288     -0.824      0.410      -6.368       2.600\n",
      "achiev          -6.2046      2.068     -3.001      0.003     -10.257      -2.152\n",
      "power            0.2042      2.098      0.097      0.922      -3.908       4.316\n",
      "reward           1.1114      1.913      0.581      0.561      -2.639       4.862\n",
      "risk            -6.9321      3.329     -2.082      0.037     -13.457      -0.407\n",
      "focuspast        1.0517      1.740      0.604      0.546      -2.358       4.462\n",
      "focuspresent    -5.5985      2.450     -2.285      0.022     -10.401      -0.796\n",
      "focusfuture      1.8674      1.999      0.934      0.350      -2.051       5.786\n",
      "relativ         -2.9481      3.982     -0.740      0.459     -10.753       4.857\n",
      "motion           2.5268      1.988      1.271      0.204      -1.370       6.424\n",
      "space            2.5180      2.885      0.873      0.383      -3.137       8.173\n",
      "time             4.3124      2.471      1.745      0.081      -0.531       9.156\n",
      "work             0.7835      1.019      0.769      0.442      -1.214       2.781\n",
      "leisure        -14.5111      3.960     -3.664      0.000     -22.273      -6.750\n",
      "home             0.8925      3.016      0.296      0.767      -5.018       6.803\n",
      "money           -5.3686      2.610     -2.057      0.040     -10.484      -0.253\n",
      "relig            3.1856      1.631      1.953      0.051      -0.011       6.383\n",
      "death          -11.4429     17.649     -0.648      0.517     -46.035      23.149\n",
      "informal         7.7769      3.721      2.090      0.037       0.483      15.071\n",
      "swear            5.6396      6.751      0.835      0.404      -7.593      18.872\n",
      "netspeak        -3.9416      2.820     -1.398      0.162      -9.468       1.585\n",
      "assent          -7.6633      3.186     -2.405      0.016     -13.908      -1.418\n",
      "nonflu          -4.0129      3.510     -1.143      0.253     -10.893       2.867\n",
      "filler          -0.6646      3.503     -0.190      0.850      -7.530       6.201\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "log_reg = sm.Logit(labels2, data2).fit()\n",
    "\n",
    "print(log_reg.summary())\n",
    "#text_file = open(\"../analysis_5/Output_startyear_top10year_new\"+\".txt\", \"w\")\n",
    "#text_file.write(str(log_reg.summary()))\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-coaching",
   "metadata": {},
   "source": [
    "# Word based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-praise",
   "metadata": {},
   "source": [
    "conducting words level correlation analysis for each LIWC category (with 30 most frequent words in each category) to analyse which words (within the LIWC category) are correlated with influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "protecting-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "List- yam , 1 , 361 360, 352123, 40"
     ]
    }
   ],
   "source": [
    "catg_wg_words_d = dict()\n",
    "ambiguous_tech_words_tuple = tuple(list(ambiguous_tech_words))\n",
    "error_count = 0\n",
    "count = 0\n",
    "count2 = 1\n",
    "for yr1 in [2019]:#][2004, 2009, 2014, 2019]:\n",
    "    print(yr1)\n",
    "    for mailing_list_name in archive.mailing_list_names():\n",
    "        if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "            continue\n",
    "        #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "        print(\"\\rList- %s , %d , %d\" % (mailing_list_name, len(catg_wg_words_d), count2), end = '')\n",
    "        count2 += 1\n",
    "        ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "        if ml:\n",
    "            if ml._num_messages > 0:\n",
    "                ml_df = ml.messages_dataframe()\n",
    "                for index, row in ml_df.iterrows():\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        yr = row['Date'].year\n",
    "                        #if yr > 2019 or yr < 2015:#yr != 2014:\n",
    "                        #    continue\n",
    "                        #if yr < yr1-4 or yr > yr1:\n",
    "                        #    continue\n",
    "                        if yr != yr1:\n",
    "                            continue\n",
    "                            \n",
    "                        if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                            continue\n",
    "\n",
    "                        e = row['From']\n",
    "                        e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                        x = re.findall(ren,str(e))\n",
    "\n",
    "                        if len(x) == 0:\n",
    "                            x = re.findall(ren2,str(e))\n",
    "                            if len(x) > 0:\n",
    "                                email = x[0]\n",
    "                        else:\n",
    "                            email = x[0][0]\n",
    "                        email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                        e = e.replace(email,'')\n",
    "\n",
    "                        email = email.lower()\n",
    "\n",
    "                        if '@' not in email:\n",
    "                            email = email.replace(' at ','@').lower()\n",
    "                        if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                            continue\n",
    "\n",
    "                        \n",
    "                        body_email = msgid_messages_d[index].lower()\n",
    "                        body_email = body_email.replace('\\n',' ')\n",
    "\n",
    "                        body_tokens = tokenize_t(body_email)\n",
    "\n",
    "                        for token in body_tokens:\n",
    "                            if token in domain_jargon or token in abbr_set or token in ambiguous_tech_words:# or any(token in s for s in ambiguous_tech_words) or token in abbr_set:#token in ambiguous_tech_words:\n",
    "                                continue\n",
    "                            if len(token) > 3:\n",
    "                                if any(item.startswith(token) for item in ambiguous_tech_words) or any(token.startswith(item) for item in ambiguous_tech_words):\n",
    "                                    continue\n",
    "                            \n",
    "                            for category in parse(token):\n",
    "                                if yr1 not in catg_wg_words_d:\n",
    "                                    catg_wg_words_d[yr1] = {category : {token : 1}}\n",
    "                                else:\n",
    "                                    if category in catg_wg_words_d[yr1]:\n",
    "                                        catg_wg_words_d[yr1][category][token] = catg_wg_words_d[yr1][category].get(token,0) + 1\n",
    "                                    else:\n",
    "                                        catg_wg_words_d[yr1][category] = {token : 1}\n",
    "\n",
    "                                #if category in catg_wg_words_d:\n",
    "                                #    catg_wg_words_d[category][token] = catg_wg_words_d[category].get(token,0) + 1\n",
    "                                #else:\n",
    "                                #    catg_wg_words_d[category] = {token : 1}\n",
    "\n",
    "                        #category_counts = Counter(category for token in body_tokens for category in parse(token))\n",
    "\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "variable-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "List- calsify , 1 , 42ames , 1 , 40'NoneType' object has no attribute 'replace'\n",
      "List- detnet , 1 , 66 631 , 43'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 1 , 7372 71'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 1 , 17267145 123'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 1 , 337'NoneType' object has no attribute 'replace'\n",
      "List- yam , 1 , 361 360, 352"
     ]
    }
   ],
   "source": [
    "usr_wg_WORDLEVEL_perc_d = dict()\n",
    "\n",
    "catg_obs = 'informal'\n",
    "#catg_obs = 'body'\n",
    "error_count = 0\n",
    "count = 0\n",
    "count2 = 1\n",
    "\n",
    "#for c in catg_wg_words_d[2019]:\n",
    "liwc_catg_word_list = set([])\n",
    "a = 0\n",
    "for k in dict(sorted(catg_wg_words_d[2019][catg_obs].items(), key=lambda x: x[1], reverse=True)):\n",
    "    if a > 29:\n",
    "        break\n",
    "    #if k.startswith(\"milford\"):\n",
    "    #    continue\n",
    "        \n",
    "    liwc_catg_word_list.add(k.lower())\n",
    "    a += 1\n",
    "\n",
    "for yr1 in [2019]:#[2004, 2009, 2014, 2019]:\n",
    "    print(yr1)\n",
    "    for mailing_list_name in archive.mailing_list_names():\n",
    "        if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "            continue\n",
    "        #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "        print(\"\\rList- %s , %d , %d\" % (mailing_list_name, len(usr_wg_WORDLEVEL_perc_d), count2), end = '')\n",
    "        count2 += 1\n",
    "        ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "        if ml:\n",
    "            if ml._num_messages > 0:\n",
    "                ml_df = ml.messages_dataframe()\n",
    "                for index, row in ml_df.iterrows():\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        yr = row['Date'].year\n",
    "                        #if yr < 2015 or yr > 2019:#yr != 2014:\n",
    "                        #    continue\n",
    "                        if yr < yr1-4 or yr > yr1:\n",
    "                            continue\n",
    "\n",
    "                        if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                            continue\n",
    "\n",
    "                        e = row['From']\n",
    "\n",
    "                        e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                        x = re.findall(ren,str(e))\n",
    "\n",
    "                        if len(x) == 0:\n",
    "                            x = re.findall(ren2,str(e))\n",
    "                            if len(x) > 0:\n",
    "                                email = x[0]\n",
    "                        else:\n",
    "                            email = x[0][0]\n",
    "                        email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                        e = e.replace(email,'')\n",
    "\n",
    "                        email = email.lower()\n",
    "\n",
    "                        if '@' not in email:\n",
    "                            email = email.replace(' at ','@').lower()\n",
    "                        if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                            continue\n",
    "\n",
    "                        #eid = r['From_emailID']\n",
    "                        if email in emailID_pid_dict:\n",
    "                            pid = emailID_pid_dict[email]\n",
    "\n",
    "                            #if pid not in yearly_PIDs or pid not in pid_percentile:\n",
    "                            #    continue\n",
    "                            if pid not in pid_percentile[yr1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        #bdy = msgid_messages_d[message.message_id].lower()\n",
    "                        body_email = msgid_messages_d[index].lower()\n",
    "                        body_email = body_email.replace('\\n',' ')\n",
    "\n",
    "                        body_tokens = tokenize_t(body_email)\n",
    "                        \n",
    "                        if yr1 not in usr_wg_WORDLEVEL_perc_d:\n",
    "                            usr_wg_WORDLEVEL_perc_d[yr1] = {pid : {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}}\n",
    "                        else:\n",
    "                            if pid not in usr_wg_WORDLEVEL_perc_d[yr1]:\n",
    "                                usr_wg_WORDLEVEL_perc_d[yr1][pid] = {'Email_count':1,'Percentile':pid_percentile[yr1][pid]}\n",
    "                            else:\n",
    "                                usr_wg_WORDLEVEL_perc_d[yr1][pid]['Email_count'] = usr_wg_WORDLEVEL_perc_d[yr1][pid]['Email_count'] + 1\n",
    "                        \n",
    "                        word_counts = Counter(body_tokens)\n",
    "                        \n",
    "                        for t in liwc_catg_word_list:\n",
    "                            \n",
    "                            usr_wg_WORDLEVEL_perc_d[yr1][pid][t] = usr_wg_WORDLEVEL_perc_d[yr1][pid].get(t,0) + word_counts[t]\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "foreign-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape- 5363 33"
     ]
    }
   ],
   "source": [
    "list_words = list(liwc_catg_word_list)\n",
    "\n",
    "usr_wg_WORDLEVEL_perc_df = pd.DataFrame(columns = ['PID']+['Year']+list_words+['Percentile'])\n",
    "\n",
    "for yr in usr_wg_WORDLEVEL_perc_d:\n",
    "\n",
    "#for p in usr_wg_LIWC_perc_d:\n",
    "\n",
    "    for p in usr_wg_WORDLEVEL_perc_d[yr]:\n",
    "        lst = []\n",
    "        lst.append(p)\n",
    "        lst.append(yr)\n",
    "        \n",
    "        for w in list_words:\n",
    "            lst.append(np.log((usr_wg_WORDLEVEL_perc_d[yr][p][w]+1)/usr_wg_WORDLEVEL_perc_d[yr][p]['Email_count']))\n",
    "            \n",
    "        #for catg_ in catgs:\n",
    "        #    #lst.append(np.log((usr_wg_LIWC_perc_d[p][catg_]+1)/usr_wg_LIWC_perc_d[p]['Email_count']))\n",
    "        #    lst.append(np.log((usr_wg_LIWC_perc_d[yr][p][catg_]+1)/usr_wg_LIWC_perc_d[yr][p]['Email_count']))\n",
    "        ##lst.append(usr_wg_LIWC_perc_d[p]['Percentile'])\n",
    "        \n",
    "        lst.append(usr_wg_WORDLEVEL_perc_d[yr][p]['Percentile'])\n",
    "        #lst.append(usr_wg_LIWC_perc_d[yr][p]['Percentile'])\n",
    "        #usr_wg_LIWC_perc_df.loc[0 if pd.isnull(usr_wg_LIWC_perc_df.index.max()) else usr_wg_LIWC_perc_df.index.max() + 1] = lst\n",
    "        \n",
    "        usr_wg_WORDLEVEL_perc_df.loc[0 if pd.isnull(usr_wg_WORDLEVEL_perc_df.index.max()) else usr_wg_WORDLEVEL_perc_df.index.max() + 1] = lst\n",
    "        \n",
    "        #print(\"\\rShape- %d %d\" % (usr_wg_LIWC_perc_df.shape[0],usr_wg_LIWC_perc_df.shape[1]), end = '')\n",
    "        print(\"\\rShape- %d %d\" % (usr_wg_WORDLEVEL_perc_df.shape[0],usr_wg_WORDLEVEL_perc_df.shape[1]), end = '')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "frequent-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>okay</th>\n",
       "      <th>yes</th>\n",
       "      <th>anyway</th>\n",
       "      <th>hey</th>\n",
       "      <th>txt</th>\n",
       "      <th>indeed</th>\n",
       "      <th>eh</th>\n",
       "      <th>u</th>\n",
       "      <th>...</th>\n",
       "      <th>zzh</th>\n",
       "      <th>o</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>op</th>\n",
       "      <th>um</th>\n",
       "      <th>app</th>\n",
       "      <th>dis</th>\n",
       "      <th>btw</th>\n",
       "      <th>agree</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100889.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-1.446919</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-3.526361</td>\n",
       "      <td>-2.427748</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101304.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100149.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>-6.391079</td>\n",
       "      <td>-2.509515</td>\n",
       "      <td>-3.500707</td>\n",
       "      <td>-7.084226</td>\n",
       "      <td>-4.599320</td>\n",
       "      <td>-3.618491</td>\n",
       "      <td>-3.865351</td>\n",
       "      <td>-4.445169</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.084226</td>\n",
       "      <td>-3.420665</td>\n",
       "      <td>-4.193855</td>\n",
       "      <td>-6.391079</td>\n",
       "      <td>-7.084226</td>\n",
       "      <td>-7.084226</td>\n",
       "      <td>-7.084226</td>\n",
       "      <td>-4.445169</td>\n",
       "      <td>-2.894572</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PID    Year      okay       yes    anyway       hey       txt  \\\n",
       "0  100889.0  2019.0 -3.526361 -1.446919 -2.427748 -3.526361 -2.427748   \n",
       "1  101304.0  2019.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  100149.0  2019.0 -6.391079 -2.509515 -3.500707 -7.084226 -4.599320   \n",
       "\n",
       "     indeed        eh         u  ...       zzh         o  absolutely  \\\n",
       "0 -2.427748 -3.526361 -2.427748  ... -3.526361 -3.526361   -3.526361   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000    0.000000   \n",
       "2 -3.618491 -3.865351 -4.445169  ... -7.084226 -3.420665   -4.193855   \n",
       "\n",
       "         op        um       app       dis       btw     agree  Percentile  \n",
       "0 -3.526361 -3.526361 -3.526361 -3.526361 -3.526361 -2.427748        18.0  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.693147        93.0  \n",
       "2 -6.391079 -7.084226 -7.084226 -7.084226 -4.445169 -2.894572         2.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_WORDLEVEL_perc_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "acoustic-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this file for later use in feature analysis or continue using dataframe\n",
    "#usr_wg_WORDLEVEL_perc_df.to_csv('../analysis_5/user_wg_WORDLEVEL_'+catg_obs+'_catg_infl_features_2015-19.csv',sep=',',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "described-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'yes', 'anyway', 'hey', 'txt', 'indeed', 'eh', 'u', 'msg', 'oh', 'hmm', 'yeah', 'ok', 'thx', 'rt', 'da', 'apps', 'cc', 'rp', 'k', 'well', 'zzh', 'o', 'absolutely', 'op', 'um', 'app', 'dis', 'btw', 'agree']\n",
      "['Percentile']\n",
      "(5363, 30)\n",
      "\n",
      "(5363, 1)\n",
      "   const      okay       yes    anyway       hey       txt    indeed  \\\n",
      "0    1.0 -0.972119 -0.148971 -0.488462 -0.911414 -0.605238 -0.472042   \n",
      "1    1.0  1.162113  1.232140  1.217971  1.149033  1.177887  1.204837   \n",
      "2    1.0 -2.705911 -1.163239 -1.242631 -2.990270 -2.200207 -1.294504   \n",
      "3    1.0 -2.717800 -0.255661 -1.182382 -2.596743 -0.940610 -1.352650   \n",
      "4    1.0 -2.129134 -1.312120 -2.604385 -2.028428 -1.202446 -2.551319   \n",
      "\n",
      "         eh         u       msg  ...      well       zzh         o  \\\n",
      "0 -0.887685 -0.349383 -1.057755  ...  0.247507 -0.835723 -1.352233   \n",
      "1  1.151386  1.151960  1.191555  ...  1.150860  1.137239  1.184793   \n",
      "2 -1.083701 -1.596975 -2.885033  ... -1.446922 -2.826312 -1.276191   \n",
      "3 -2.789984 -1.955195 -1.791137  ... -0.281363 -3.064156  0.107014   \n",
      "4 -1.993111 -2.211000 -2.277156  ... -1.335665 -1.905310 -2.228930   \n",
      "\n",
      "   absolutely        op        um       app       dis       btw     agree  \n",
      "0   -1.018558 -0.916437 -0.878854 -1.066647 -0.852234 -1.049166 -1.105977  \n",
      "1    1.193302  1.154271  1.131805  1.165284  1.139184  1.193214  1.917224  \n",
      "2   -1.437234 -2.598623 -2.907477 -3.318519 -2.861443 -1.633429 -1.558187  \n",
      "3   -2.392967 -2.203136 -1.897053 -1.285253 -0.780006 -2.117711 -0.289686  \n",
      "4   -2.217657 -2.039014 -1.968877 -1.837915 -1.931825 -1.824045 -1.120118  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Statistical approach: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-156-1727abae91dd>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_rq3[data_rq3.columns] = scaler.fit_transform(data_rq3[data_rq3.columns])\n",
      "/Users/pkhare/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/pkhare/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             centrality   R-squared:                       0.715\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                     445.1\n",
      "Date:                Fri, 03 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        12:23:28   Log-Likelihood:                -22280.\n",
      "No. Observations:                5363   AIC:                         4.462e+04\n",
      "Df Residuals:                    5332   BIC:                         4.483e+04\n",
      "Df Model:                          30                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         49.9862      0.211    236.744      0.000      49.572      50.400\n",
      "okay           1.4476      0.885      1.636      0.102      -0.287       3.182\n",
      "yes            0.5161      0.436      1.183      0.237      -0.339       1.371\n",
      "anyway        -0.0076      0.729     -0.010      0.992      -1.437       1.422\n",
      "hey            1.6987      1.321      1.286      0.199      -0.891       4.288\n",
      "txt           -0.6870      0.503     -1.365      0.172      -1.674       0.300\n",
      "indeed         0.1120      0.687      0.163      0.870      -1.235       1.459\n",
      "eh            -0.1173      1.366     -0.086      0.932      -2.795       2.560\n",
      "u              0.8727      0.700      1.247      0.212      -0.499       2.245\n",
      "msg            1.3628      0.842      1.619      0.105      -0.287       3.013\n",
      "oh             1.9158      1.362      1.407      0.160      -0.754       4.586\n",
      "hmm            1.2815      1.409      0.909      0.363      -1.481       4.044\n",
      "yeah           1.7462      1.277      1.368      0.171      -0.757       4.249\n",
      "ok             2.0222      0.545      3.713      0.000       0.955       3.090\n",
      "thx           -2.6964      1.405     -1.920      0.055      -5.450       0.057\n",
      "rt             0.5828      1.061      0.549      0.583      -1.497       2.662\n",
      "da             1.5332      1.599      0.959      0.338      -1.602       4.668\n",
      "apps           0.2497      1.111      0.225      0.822      -1.929       2.429\n",
      "cc             0.6021      0.630      0.956      0.339      -0.633       1.837\n",
      "rp             0.9808      1.159      0.846      0.398      -1.292       3.253\n",
      "k              1.6457      0.850      1.937      0.053      -0.020       3.312\n",
      "well          -1.5244      0.391     -3.896      0.000      -2.292      -0.757\n",
      "zzh           -1.2963      2.507     -0.517      0.605      -6.212       3.619\n",
      "o              1.4004      0.503      2.782      0.005       0.414       2.387\n",
      "absolutely     3.0111      1.141      2.639      0.008       0.774       5.248\n",
      "op             2.9862      1.184      2.522      0.012       0.665       5.307\n",
      "um            -0.0136      1.222     -0.011      0.991      -2.409       2.382\n",
      "app            2.6942      0.844      3.193      0.001       1.040       4.349\n",
      "dis            1.1470      1.790      0.641      0.522      -2.363       4.657\n",
      "btw            1.9266      0.971      1.985      0.047       0.024       3.829\n",
      "agree         -0.4695      0.447     -1.050      0.294      -1.346       0.407\n",
      "==============================================================================\n",
      "Omnibus:                       75.041   Durbin-Watson:                   1.498\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.004\n",
      "Skew:                           0.295   Prob(JB):                     1.15e-17\n",
      "Kurtosis:                       2.999   Cond. No.                         67.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df_rq3 = usr_wg_WORDLEVEL_perc_df.drop(\"PID\", axis = 1)\n",
    "df_rq3 = df_rq3.loc[df_rq3.Year == 2019]\n",
    "#df1 = df1.drop(\"Year\", axis = 1)\n",
    "#df = df1\n",
    "feat_cols_rq3 = [c for c in df_rq3.columns if c!=\"Percentile\" and c!=\"Year\"]\n",
    "lab_cols_rq3 = [c for c in df_rq3.columns if c==\"Percentile\"]\n",
    "\n",
    "print(feat_cols_rq3)\n",
    "print(lab_cols_rq3)\n",
    "data_rq3 = df_rq3[feat_cols_rq3]\n",
    "labels_rq3 = df_rq3[lab_cols_rq3]\n",
    "labels_rq3.columns = [\"centrality\"]\n",
    "\n",
    "print(data_rq3.shape)\n",
    "print()\n",
    "print(labels_rq3.shape)\n",
    "\n",
    "\n",
    "# some scaling and preparation\n",
    "scaler = StandardScaler()\n",
    "data_rq3[data_rq3.columns] = scaler.fit_transform(data_rq3[data_rq3.columns])\n",
    "data_rq3 = sm.add_constant(data_rq3)\n",
    "print(data_rq3.head())\n",
    "\n",
    "# statistical approach with statsmodels\n",
    "print(\"Statistical approach: \")\n",
    "model = sm.OLS(labels_rq3[\"centrality\"], data_rq3)\n",
    "res = model.fit()\n",
    "print(res.summary())\n",
    "\n",
    "#text_file = open(\"Output_wordlevel_\"+str(catg_obs)+\".txt\", \"w\")\n",
    "#e.g., Output_wordlevel_informal.txt\n",
    "#text_file.write(str(res.summary()))\n",
    "#text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-matter",
   "metadata": {},
   "source": [
    "<b>FURTEHR STEPS</b>: Repeat above steps by updating <b>catg_obs</b> to different LIWC categories such as  \"we\", \"tentat\", \"they\", \"time\", \"body\", \"health\", \"death\" and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-chart",
   "metadata": {},
   "source": [
    "# Emails for individual research questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-accordance",
   "metadata": {},
   "source": [
    "to be used in BERT vs LIWC comparison and t-snse projections, conducted by Ravi Shekhar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-original",
   "metadata": {},
   "source": [
    "## RQ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "executed-grill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "List- calsify , 29928 ames , 29657 'NoneType' object has no attribute 'replace'\n",
      "List- detnet , 47391 08 30799 'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 56921 6 77 'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 141694 5 30 145 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 285645 'NoneType' object has no attribute 'replace'\n",
      "List- yam , 300802 455 0046 "
     ]
    }
   ],
   "source": [
    "temp_usr_per_message_df_dict = {'PID':[],'MessageID':[],'Body':[],'Timestamp':[],'Percentile':[]}\n",
    "\n",
    "#top10_PID = usr_wg_LIWC_perc_df.loc[(usr_wg_LIWC_perc_df.Year == 2019) & (usr_wg_LIWC_perc_df.Percentile <= 10)].PID.unique()\n",
    "#plus50_PID = usr_wg_LIWC_perc_df.loc[(usr_wg_LIWC_perc_df.Year == 2019) & (usr_wg_LIWC_perc_df.Percentile >= 10)].PID.unique()\n",
    "\n",
    "error_count = 0\n",
    "count = 0\n",
    "count2 = 1\n",
    "\n",
    "for yr1 in [2019]:#[2004, 2009, 2014, 2019]:\n",
    "    print(yr1)\n",
    "    for mailing_list_name in archive.mailing_list_names():\n",
    "        if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "            continue\n",
    "        #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "        #print(\"\\rList- %s , %d\" % (mailing_list_name, temp_usr_per_message_df.shape[0]), end = ' ')\n",
    "        print(\"\\rList- %s , %d\" % (mailing_list_name, len(temp_usr_per_message_df_dict['PID'])), end = ' ')\n",
    "        \n",
    "        count2 += 1\n",
    "        ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "        if ml:\n",
    "            if ml._num_messages > 0:\n",
    "                ml_df = ml.messages_dataframe()\n",
    "                for index, row in ml_df.iterrows():\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        yr = row['Date'].year\n",
    "                        #if yr < 2015 or yr > 2019:#yr != 2014:\n",
    "                        #    continue\n",
    "                        if yr < yr1-4 or yr > yr1:\n",
    "                            continue\n",
    "\n",
    "                        if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                            continue\n",
    "\n",
    "                        e = row['From']\n",
    "\n",
    "                        e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                        x = re.findall(ren,str(e))\n",
    "\n",
    "                        if len(x) == 0:\n",
    "                            x = re.findall(ren2,str(e))\n",
    "                            if len(x) > 0:\n",
    "                                email = x[0]\n",
    "                        else:\n",
    "                            email = x[0][0]\n",
    "                        email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                        e = e.replace(email,'')\n",
    "\n",
    "                        email = email.lower()\n",
    "\n",
    "                        if '@' not in email:\n",
    "                            email = email.replace(' at ','@').lower()\n",
    "                        if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                            continue\n",
    "\n",
    "                        #eid = r['From_emailID']\n",
    "                        if email in emailID_pid_dict:\n",
    "                            pid = emailID_pid_dict[email]\n",
    "\n",
    "                            #if pid not in yearly_PIDs or pid not in pid_percentile:\n",
    "                            #    continue\n",
    "                            if pid not in pid_percentile[yr1]:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "                        #if pid in top10_PID:\n",
    "                        #    perc_cat = 0\n",
    "                        #elif pid in plus50_PID:\n",
    "                        #    perc_cat = 1\n",
    "                        #else:\n",
    "                        #    continue\n",
    "                        \n",
    "                        ##Now also generating 50 emails max for each PID in 2015-2019, and using actual percentile\n",
    "                        ## value instead of two categories\n",
    "                        \n",
    "                        #if pid_percentile[yr1][pid] <= 10:\n",
    "                        #    perc_cat = 0\n",
    "                        #elif pid_percentile[yr1][pid] >= 50:\n",
    "                        #    perc_cat = 1\n",
    "                        #else:\n",
    "                        #    continue\n",
    "                            \n",
    "                        #if temp_usr_per_message_df.loc[temp_usr_per_message_df.PID == pid].shape[0] > 50:#20:\n",
    "                        #    continue\n",
    "\n",
    "                        #bdy = msgid_messages_d[message.message_id].lower()\n",
    "                        body_email = msgid_messages_d[index].lower()\n",
    "                        body_email = body_email.replace('\\n',' ')\n",
    "                        body_email = body_email.replace('\\t',' ')\n",
    "                        \n",
    "                        #lst = [pid, index, body_email, row['Date'],perc_cat]#pid_messageID_d[pid][msgid]]\n",
    "                        \n",
    "                        #lst = [pid, index, body_email, row['Date'],pid_percentile[yr1][pid]]\n",
    "                        #['PID','MessageID','Body','Timestamp','Percentile']\n",
    "                        temp_usr_per_message_df_dict['PID'].append(pid)\n",
    "                        temp_usr_per_message_df_dict['MessageID'].append(index)\n",
    "                        temp_usr_per_message_df_dict['Body'].append(body_email)\n",
    "                        temp_usr_per_message_df_dict['Timestamp'].append(row['Date'])\n",
    "                        temp_usr_per_message_df_dict['Percentile'].append(pid_percentile[yr1][pid])\n",
    "                        \n",
    "                        #temp_usr_per_message_df.loc[0 if pd.isnull(temp_usr_per_message_df.index.max()) else temp_usr_per_message_df.index.max() + 1] = lst\n",
    "                        \n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "committed-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300806\n",
      "300806\n",
      "300806\n",
      "300806\n",
      "300806\n"
     ]
    }
   ],
   "source": [
    "print(len(temp_usr_per_message_df_dict['PID']))\n",
    "print(len(temp_usr_per_message_df_dict['MessageID']))\n",
    "print(len(temp_usr_per_message_df_dict['Body']))\n",
    "print(len(temp_usr_per_message_df_dict['Timestamp']))\n",
    "print(len(temp_usr_per_message_df_dict['Percentile']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dutch-probability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300806, 5)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_usr_per_message_df = pd.DataFrame(temp_usr_per_message_df_dict)\n",
    "\n",
    "temp_usr_per_message_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ignored-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_usr_per_message_df.to_csv('../analysis_5/2015-19_asperinfluence_Totalemails.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-overview",
   "metadata": {},
   "source": [
    "### vocabulary comparison - overall vs 2015-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "annual-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List- abfab , 25445 , 16369 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- bmwg , 101678 , 50932    823 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- calsify , 107193 , 52311 6884 , 51934 'NoneType' object has no attribute 'replace'\n",
      "List- detnet , 150056 , 70352 99 53417 'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 184211 , 81708 5 50 'NoneType' object has no attribute 'replace'\n",
      "List- ips , 318660 , 122190 90 2  17380 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- ipsec , 325191 , 122192 'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 378088 , 136035 2 66 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- mboned , 453373 , 140094 5 50 'NoneType' object has no attribute 'replace'\n",
      "List- midcom , 462294 , 140893 41 'NoneType' object has no attribute 'replace'\n",
      "List- mmusic , 470443 , 142417  'NoneType' object has no attribute 'replace'\n",
      "List- nemo , 489402 , 146745 2 46265 'NoneType' object has no attribute 'replace'\n",
      "List- nsis , 511544 , 155233   34 'NoneType' object has no attribute 'replace'\n",
      "List- pkix , 557257 , 168097 86 'NoneType' object has no attribute 'replace'\n",
      "List- sipping , 652879 , 184575 3 83 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 717021 , 205585 7 97 'NoneType' object has no attribute 'replace'\n",
      "List- yam , 735538 , 212252 135 1885 "
     ]
    }
   ],
   "source": [
    "total_vocab = set([])\n",
    "vocab_2019 = set([])\n",
    "for mailing_list_name in archive.mailing_list_names():\n",
    "    if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "        continue\n",
    "    #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "    #print(\"\\rList- %s , %d\" % (mailing_list_name, temp_usr_per_message_df.shape[0]), end = ' ')\n",
    "    print(\"\\rList- %s , %d , %d\" % (mailing_list_name, len(total_vocab), len(vocab_2019)), end = ' ')\n",
    "    \n",
    "    ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "    if ml:\n",
    "        if ml._num_messages > 0:\n",
    "            ml_df = ml.messages_dataframe()\n",
    "            for index, row in ml_df.iterrows():\n",
    "                count += 1\n",
    "                try:\n",
    "                    yr = row['Date'].year\n",
    "                    #if yr < 2015 or yr > 2019:#yr != 2014:\n",
    "                    #    continue\n",
    "                    \n",
    "                    #if yr < yr1-4 or yr > yr1:\n",
    "                    #    continue\n",
    "\n",
    "                    if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                        continue\n",
    "\n",
    "                    e = row['From']\n",
    "\n",
    "                    e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                    x = re.findall(ren,str(e))\n",
    "\n",
    "                    if len(x) == 0:\n",
    "                        x = re.findall(ren2,str(e))\n",
    "                        if len(x) > 0:\n",
    "                            email = x[0]\n",
    "                    else:\n",
    "                        email = x[0][0]\n",
    "                    email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                    e = e.replace(email,'')\n",
    "\n",
    "                    email = email.lower()\n",
    "\n",
    "                    if '@' not in email:\n",
    "                        email = email.replace(' at ','@').lower()\n",
    "                    if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                        continue\n",
    "\n",
    "                    #eid = r['From_emailID']\n",
    "                    if email in emailID_pid_dict:\n",
    "                        pid = emailID_pid_dict[email]\n",
    "\n",
    "                        #if pid not in yearly_PIDs or pid not in pid_percentile:\n",
    "                        #    continue\n",
    "                        #\n",
    "                        #if pid not in pid_percentile[yr1]:\n",
    "                        #    continue\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    body_email = msgid_messages_d[index].lower()\n",
    "                    body_email = body_email.replace('\\n',' ')\n",
    "                    body_email = body_email.replace('\\t',' ')\n",
    "                    \n",
    "                    if len(body_email) > 0:\n",
    "                        \n",
    "                        body_tokens = tokenize_t(body_email)\n",
    "                        \n",
    "                        for token in body_tokens:\n",
    "                            if token in domain_jargon or token in abbr_set or token in ambiguous_tech_words:\n",
    "                                continue\n",
    "                            \n",
    "                            total_vocab.add(token)\n",
    "                            if yr >= 2015 and yr <= 2019:#yr1-4 or yr > yr1:\n",
    "                                vocab_2019.add(token)\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "scientific-minister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735605 212253\n"
     ]
    }
   ],
   "source": [
    "print(len(total_vocab),len(vocab_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "legendary-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_length_list = []\n",
    "\n",
    "for i,r in temp_usr_per_message_df.iterrows():\n",
    "    if pd.notna(r['Body']):\n",
    "        email_length_list.append(len(r['Body']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fourth-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300806 958.7520494936936 499.0\n"
     ]
    }
   ],
   "source": [
    "print(len(email_length_list), np.mean(email_length_list), np.median(email_length_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-preview",
   "metadata": {},
   "source": [
    "## RQ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "intimate-event",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>Role</th>\n",
       "      <th>Message</th>\n",
       "      <th>Mailinglist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100300</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>ALLO_WGC</td>\n",
       "      <td>hi tal,  hi,  i am not a 6lo native, but i rev...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101435</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>ALLO_WGC</td>\n",
       "      <td>hi suresh, authors,  i agree that the ntp time...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101305</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>i agree with specifying time semantics with mo...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101400</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>hi tal,  thanks for your comments.  the scope ...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101430</td>\n",
       "      <td>2019</td>\n",
       "      <td>48</td>\n",
       "      <td>Non_WGC</td>\n",
       "      <td>[please accept our apologies if you receive mu...</td>\n",
       "      <td>6lo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PID  Year Percentile      Role  \\\n",
       "0  100300  2019          0  ALLO_WGC   \n",
       "1  101435  2019          5  ALLO_WGC   \n",
       "2  101305  2019          5   Non_WGC   \n",
       "3  101400  2019         29   Non_WGC   \n",
       "4  101430  2019         48   Non_WGC   \n",
       "\n",
       "                                             Message Mailinglist  \n",
       "0  hi tal,  hi,  i am not a 6lo native, but i rev...         6lo  \n",
       "1  hi suresh, authors,  i agree that the ntp time...         6lo  \n",
       "2  i agree with specifying time semantics with mo...         6lo  \n",
       "3  hi tal,  thanks for your comments.  the scope ...         6lo  \n",
       "4  [please accept our apologies if you receive mu...         6lo  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_wg_message_perc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "mounted-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_df = pd.DataFrame(columns = [\"PID\",\"Year\",\"Percentile\",\"Role\",\"Body\"])\n",
    "x_df_dict = {\"PID\":[],\"Year\":[],\"Percentile\":[],\"Role\":[],\"Body\":[]}\n",
    "for i,r in usr_wg_message_perc_df.loc[usr_wg_message_perc_df.Role.isin(['CURRENT_WGC','Non_WGC'])].iterrows():#(['ACT_WGC','None'])].iterrows():\n",
    "    if r['Role'] == \"CURRENT_WGC\":#\"ACT_WGC\":\n",
    "        p = 0\n",
    "    elif r['Role'] == \"Non_WGC\":#\"None\":\n",
    "        p= 1\n",
    "    else:\n",
    "        continue\n",
    "    #lst = [r['PID'],r['Year'],p,r['Role'],r['Message']]\n",
    "    #x_df.loc[0 if pd.isnull(x_df.index.max()) else x_df.index.max() + 1] = lst\n",
    "    x_df_dict[\"PID\"].append(r['PID'])\n",
    "    x_df_dict[\"Year\"].append(r['Year'])\n",
    "    x_df_dict[\"Percentile\"].append(r['Percentile'])\n",
    "    x_df_dict[\"Role\"].append(p)\n",
    "    x_df_dict[\"Body\"].append(r['Message'])\n",
    "\n",
    "x_df = pd.DataFrame(x_df_dict)\n",
    "#save the dataframe\n",
    "#x_df.to_csv('../analysis_5/ACT_WGC_emails_2019.csv',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "level-talent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Percentile</th>\n",
       "      <th>Role</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101305</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>i agree with specifying time semantics with mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101400</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>hi tal,  thanks for your comments.  the scope ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101430</td>\n",
       "      <td>2019</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>[please accept our apologies if you receive mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101406</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>hi authors of \"draft-ietf-6lo-fragment-recover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101406</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>hi pascal  the limit of 2k datagram doesn't hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PID  Year  Percentile  Role  \\\n",
       "0  101305  2019           5     1   \n",
       "1  101400  2019          29     1   \n",
       "2  101430  2019          48     1   \n",
       "3  101406  2019          17     1   \n",
       "4  101406  2019          17     1   \n",
       "\n",
       "                                                Body  \n",
       "0  i agree with specifying time semantics with mo...  \n",
       "1  hi tal,  thanks for your comments.  the scope ...  \n",
       "2  [please accept our apologies if you receive mu...  \n",
       "3  hi authors of \"draft-ietf-6lo-fragment-recover...  \n",
       "4  hi pascal  the limit of 2k datagram doesn't hu...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-parking",
   "metadata": {},
   "source": [
    "## RQ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "better-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List- abfab , 5, 0 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- bmwg , 36, 15  5   15 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- calsify , 41, 17 mes , 39, 17 'NoneType' object has no attribute 'replace'\n",
      "List- detnet , 65, 18 18 2, 18 'NoneType' object has no attribute 'replace'\n",
      "List- dmm , 72, 19 9 19 'NoneType' object has no attribute 'replace'\n",
      "List- ips , 139, 20 20 0  2, 20 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- ipsec , 140, 22 'NoneType' object has no attribute 'replace'\n",
      "List- lp-wan , 171, 23 3 23 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- mboned , 186, 25 5 25 'NoneType' object has no attribute 'replace'\n",
      "List- midcom , 191, 26 26 'NoneType' object has no attribute 'replace'\n",
      "List- mmusic , 198, 27  'NoneType' object has no attribute 'replace'\n",
      "List- nemo , 211, 28 8 7, 28 'NoneType' object has no attribute 'replace'\n",
      "List- nsis , 220, 29   29 'NoneType' object has no attribute 'replace'\n",
      "List- pkix , 240, 30 30 'NoneType' object has no attribute 'replace'\n",
      "List- sipping , 294, 31 1 31 'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'NoneType' object has no attribute 'replace'\n",
      "List- tzdist , 336, 35 5 35 'NoneType' object has no attribute 'replace'\n",
      "List- yam , 360, 36  36 , 36 "
     ]
    }
   ],
   "source": [
    "pid_messages_changes_percntl = dict()\n",
    "error_count = 0\n",
    "count2 = 0\n",
    "\n",
    "for mailing_list_name in archive.mailing_list_names():\n",
    "    if mailing_list_name not in maillist_type or maillist_type[mailing_list_name] != 'wg':\n",
    "        continue\n",
    "    #if mailing_list_name in ['opsawg','rtgwg','int-area','tsvwg','dispatch','gendispatch','ops-area','secdispatch','tsv-area']:\n",
    "    print(\"\\rList- %s , %d, %d \" % (mailing_list_name, count2, error_count), end = '')\n",
    "    count2 += 1\n",
    "    ml = archive.mailing_list(mailing_list_name)\n",
    "\n",
    "    if ml:\n",
    "        if ml._num_messages > 0:\n",
    "            ml_df = ml.messages_dataframe()\n",
    "            for index, row in ml_df.iterrows():\n",
    "                count += 1\n",
    "                try:\n",
    "                    yr = row['Date'].year\n",
    "                    #if yr > 2019 or yr < 2015:#yr != 2014:\n",
    "                    #    continue\n",
    "                    if index in spam_messageIDs or index not in msgid_messages_d:\n",
    "                        continue\n",
    "\n",
    "                    e = row['From']\n",
    "                    e = e.replace(\"'\",\"__apostrophe__\")\n",
    "                    x = re.findall(ren,str(e))\n",
    "\n",
    "                    if len(x) == 0:\n",
    "                        x = re.findall(ren2,str(e))\n",
    "                        if len(x) > 0:\n",
    "                            email = x[0]\n",
    "                    else:\n",
    "                        email = x[0][0]\n",
    "                        \n",
    "                    if not email:\n",
    "                        continue\n",
    "                    email = email.replace(\"__apostrophe__\",\"'\")#.lower()\n",
    "\n",
    "                    e = e.replace(email,'')\n",
    "\n",
    "                    email = email.lower()\n",
    "\n",
    "                    if '@' not in email:\n",
    "                        email = email.replace(' at ','@').lower()\n",
    "                    if email in role_based_emailIDs or email in automated_list or email not in emailID_pid_dict:\n",
    "                        continue\n",
    "\n",
    "                    #eid = r['From_emailID']\n",
    "                    if email in emailID_pid_dict:\n",
    "                        pid = emailID_pid_dict[email]\n",
    "                        if pid not in pid_50_plus2 or 0 not in pid_50_plus2[pid]:\n",
    "                            continue\n",
    "                                                \n",
    "                            \n",
    "                        zeroth_yr = pid_50_plus2[pid][0]#max([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        #max_perc_yr = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "                        joining_yr = []\n",
    "                        for k in pid_50_plus[pid]:\n",
    "                            joining_yr.extend(pid_50_plus[pid][k])\n",
    "\n",
    "                        joining_yr = min(joining_yr)\n",
    "                        \n",
    "                        if joining_yr > zeroth_yr:\n",
    "                            continue\n",
    "                            \n",
    "                        if yr > zeroth_yr or yr < (joining_yr-4):\n",
    "                            continue\n",
    "                            \n",
    "                        flag = False\n",
    "                        for k in pid_50_plus[pid]:\n",
    "                            if joining_yr in pid_50_plus[pid][k]:\n",
    "                                if k < 5:\n",
    "                                    flag = True\n",
    "                                    break\n",
    "                        if flag:\n",
    "                            continue\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "                            \n",
    "                    body_email = msgid_messages_d[index].lower()\n",
    "                    if not body_email:\n",
    "                        continue\n",
    "                        \n",
    "                    if pid not in pid_messages_changes_percntl:\n",
    "                            pid_messages_changes_percntl[pid] = {yr:[index]}#{yr : {catg_ : [category_counts[catg_]/len(body_tokens)]}}\n",
    "                    else:\n",
    "                        if yr not in pid_messages_changes_percntl[pid]:\n",
    "                            pid_messages_changes_percntl[pid][yr] = [index]#{catg_ : [category_counts[catg_]/len(body_tokens)]}\n",
    "                        else:\n",
    "                            pid_messages_changes_percntl[pid][yr].append(index)\n",
    "                            #if catg_ not in pid_liwc_changes_percntl[pid][yr]:\n",
    "                            #    pid_liwc_changes_percntl[pid][yr][catg_] = [category_counts[catg_]/len(body_tokens)]\n",
    "                            #else:\n",
    "                            #    pid_liwc_changes_percntl[pid][yr][catg_].append(category_counts[catg_]/len(body_tokens))\n",
    "\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(e)#, email, body_email)\n",
    "                    error_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "indian-alpha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape- 74463 74463(74463, 3)\n"
     ]
    }
   ],
   "source": [
    "#catg_pct_df = pd.DataFrame(columns= ['PID']+catgs+['Percentile'])\n",
    "messages_pct_df_dict = {\"PID\":[],\"Body\":[],\"Percentile\":[]}\n",
    "for pid in pid_messages_changes_percntl:\n",
    "    \n",
    "    yr_0 = pid_50_plus2[pid][0]#max([k for k in pid_liwc_changes_percntl[pid]])#\n",
    "    yr_least_pctl = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([k for k in pid_liwc_changes_percntl[pid]])#\n",
    "    \n",
    "    ##below new part                       \n",
    "    zeroth_yr = pid_50_plus2[pid][0]#max([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "    #max_perc_yr = pid_50_plus2[pid][max([k for k in pid_50_plus2[pid]])]#min([pid_50_plus[pid][krange] for krange in pid_50_plus[pid]])\n",
    "    joining_yr = []\n",
    "    for k in pid_50_plus[pid]:\n",
    "        joining_yr.extend(pid_50_plus[pid][k])\n",
    "\n",
    "    joining_yr = min(joining_yr)\n",
    "\n",
    "    if joining_yr > zeroth_yr:\n",
    "        continue\n",
    "\n",
    "    #if yr > zeroth_yr or yr < (joining_yr-4):\n",
    "    #    continue\n",
    "\n",
    "    flag = False\n",
    "    for k in pid_50_plus[pid]:\n",
    "        if joining_yr in pid_50_plus[pid][k]:\n",
    "            if k < 5:\n",
    "                flag = True\n",
    "                break\n",
    "    if flag:\n",
    "        continue\n",
    "        \n",
    "    if yr_0 not in pid_messages_changes_percntl[pid] or joining_yr not in pid_messages_changes_percntl[pid]:\n",
    "        continue\n",
    "        \n",
    "    ##above new part\n",
    "    \n",
    "    #below line removed for changes between yr_least_pctl and joining_yr\n",
    "    #if yr_0 not in pid_liwc_changes_percntl[pid] or yr_least_pctl not in pid_liwc_changes_percntl[pid]:\n",
    "    #    continue\n",
    "        \n",
    "    #lst = []\n",
    "    #lst.append(pid)\n",
    "    \n",
    "    for y in range(joining_yr - 4,joining_yr + 1):\n",
    "        if y in pid_messages_changes_percntl[pid]:\n",
    "            for msg_index in pid_messages_changes_percntl[pid][y]:\n",
    "                lst = []\n",
    "                \n",
    "                body_email = msgid_messages_d[msg_index].lower()\n",
    "                if not body_email:\n",
    "                    continue\n",
    "                body_email = body_email.replace('\\n',' ')\n",
    "                body_email = body_email.replace('\\t',' ')\n",
    "                \n",
    "                messages_pct_df_dict['PID'].append(pid)\n",
    "                messages_pct_df_dict['Body'].append(body_email)\n",
    "                messages_pct_df_dict['Percentile'].append(1)\n",
    "                \n",
    "    for y in range(yr_0 - 4,yr_0 + 1):\n",
    "        if y in pid_messages_changes_percntl[pid]:\n",
    "            for msg_index in pid_messages_changes_percntl[pid][y]:\n",
    "                lst = []\n",
    "                \n",
    "                body_email = msgid_messages_d[msg_index].lower()\n",
    "                if not body_email:\n",
    "                    continue\n",
    "                body_email = body_email.replace('\\n',' ')\n",
    "                body_email = body_email.replace('\\t',' ')\n",
    "\n",
    "                messages_pct_df_dict['PID'].append(pid)\n",
    "                messages_pct_df_dict['Body'].append(body_email)\n",
    "                messages_pct_df_dict['Percentile'].append(0)\n",
    "    \n",
    "    \n",
    "        \n",
    "    #catg_pct_df.loc[0 if pd.isnull(catg_pct_df.index.max()) else catg_pct_df.index.max() + 1] = lst\n",
    "    #print(\"\\rShape- %d %d\" % (catg_pct_df.shape[0],catg_pct_df.shape[1]), end = '')\n",
    "    print(\"\\rShape- %d %d\" % (len(messages_pct_df_dict['PID']),len(messages_pct_df_dict['Percentile'])), end = '')\n",
    "    \n",
    "    #lst = []\n",
    "    #lst.append(pid)\n",
    "    \n",
    "    #for cat_ in catgs:\n",
    "        \n",
    "    #    l1 = []\n",
    "        \n",
    "    #    for y in range(yr_0 - 4,yr_0 + 1):\n",
    "    #        if y in pid_liwc_changes_percntl[pid]:\n",
    "    #            l1.extend(pid_liwc_changes_percntl[pid][y][cat_])\n",
    "    #    lst.append(np.log((np.sum(l1)+1)/len(l1)))\n",
    "        \n",
    "    #    #lst.append(np.log((np.sum(pid_liwc_changes_percntl[pid][yr_0][cat_])+1)/len(pid_liwc_changes_percntl[pid][yr_0][cat_])))\n",
    "    #    #for i in pid_liwc_changes_percntl[pid][yr_least_pctl][cat_]:\n",
    "        \n",
    "    #lst.append(0)\n",
    "\n",
    "        \n",
    "    #catg_pct_df.loc[0 if pd.isnull(catg_pct_df.index.max()) else catg_pct_df.index.max() + 1] = lst\n",
    "    #print(\"\\rShape- %d %d\" % (catg_pct_df.shape[0],catg_pct_df.shape[1]), end = '')\n",
    "messages_pct_df = pd.DataFrame(messages_pct_df_dict)\n",
    "print(messages_pct_df.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "outer-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages_pct_df.to_csv('../analysis_5/startyear_top10year_emails.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-laptop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39]",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
